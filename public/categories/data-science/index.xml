<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data science on Bryan Shalloway&#39;s Blog</title>
    <link>/categories/data-science/</link>
    <description>Recent content in data science on Bryan Shalloway&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Influencing Distributions with Tiered Incentives</title>
      <link>/2020/11/02/influencing-distributions/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/11/02/influencing-distributions/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simple-example&#34;&gt;Simple Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#applying-incentives&#34;&gt;Applying Incentives&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#takeaways-of-resulting-distribution&#34;&gt;Takeaways of Resulting Distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#think-carefully-about-assumptions&#34;&gt;Think Carefully About Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-set-assumptions&#34;&gt;How to Set Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simple-assumptions&#34;&gt;Simple Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trade-offs&#34;&gt;Trade-offs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;In this post I will use incentives for sales representatives in pricing to provide examples of factors to consider when attempting to influence an existing distribution.&lt;/p&gt;
&lt;p&gt;For instance, if you have a lever that pushes prices from low to high, using the lever to influence the prices adjacent to the right of the largest parts of the distribution will (likely, though contingent on a variety of factors) make the biggest impact on raising the average price attained. If the starting distribution is normal, this means incentives applied near the lower prices (the tail of the distribution) may have the smallest impact.&lt;/p&gt;
&lt;p&gt;All figures in this post are created using the R programming language (see &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-11-02-influencing-distributions.Rmd&#34;&gt;Rmarkdown document&lt;/a&gt; on github for code).&lt;/p&gt;
&lt;div id=&#34;simple-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple Example&lt;/h1&gt;
&lt;p&gt;Imagine you have a product that can be sold anywhere from $100 to $150. Sales reps want to sell for as high of a price as possible and customers want to purchase for as low of a price as possible. In this tension your product ends-up selling, on average, for $125 and follows a truncated normal distribution with standard deviation of $10&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;applying-incentives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Applying Incentives&lt;/h2&gt;
&lt;p&gt;Executive leadership wants to apply additional incentives on sales reps to keep prices high&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. They task you with setting-up a tiered compensation scheme whereby deals at the top-end of the distribution get a higher compensation rate compared to deals at the bottom end of the distribution.&lt;/p&gt;
&lt;p&gt;Applying such an additional incentive on sales teams has the potential advantage of pushing some proportion of deals to a higher price&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. There are also &lt;a href=&#34;#trade-offs&#34;&gt;Trade-offs&lt;/a&gt; associated with such an initiative (indicated in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;), these will be ignored for the purposes of this exercise.&lt;/p&gt;
&lt;p&gt;Say you decide to set cut-points to split the distribution into quartiles such that sales reps get larger bonuses if their deals fall into higher quartiles.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Applying incentives is likely to lead to a different distribution for future deals.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Consider what the relevant factors and assumptions are in influencing the existing distribution. &lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Take a moment to hypothesize what the new distribution will look like after incentives are applied&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After applying incentives the resulting distribution is likely to depend on:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The starting distribution&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; of deals.&lt;/li&gt;
&lt;li&gt;What the incentives are and &lt;em&gt;how&lt;/em&gt; they influence the initial distribution.&lt;/li&gt;
&lt;li&gt;How this influence degrades the farther away the starting position of a deal is from the next tier up in incentives.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You could paramaterize this problem and model the expected distribution. Making some &lt;a href=&#34;#simple-assumptions&#34;&gt;Simple Assumptions&lt;/a&gt; (described in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;), the chart below shows a (potential) resulting distribution after applying the incentives.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gray bars in the chart below indicate where (on the original distribution) movement to a higher tier will occur.
&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;takeaways-of-resulting-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Takeaways of Resulting Distribution&lt;/h3&gt;
&lt;p&gt;The greatest proportion of deals were moved from orange to yellow and from yellow to blue. Pink to orange had the least amount of movement (due to the first quartile being spread across a wider range).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;incentive&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;density_converted&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;pink to orange&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.068&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;orange to yellow&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.099&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;yellow to blue&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.095&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;stayed blue&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Incentives Make the Biggest Difference When Nearer to the Largest Parts of the Distribution Susceptible to Change&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because these incentives slide deals from lower prices to higher prices, those cut-points that are &lt;em&gt;just above&lt;/em&gt; the most dense parts of the distribution have the biggest impacts on the post-incentivized distribution. For a normal distribution, such as this one, that means incentives just to the right of the first quartile have the smallest impact. (Importantly, this assumes susceptibility to rightward mobility is evenly distributed across the starting distribution.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How Many Thresholds&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For many reasonable assumptions&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;, having more thresholds will lead to greater movement upwards in the distribution. Similarly, a continuous application of incentives (i.e. sales reps get higher compensation for every point they move up on the distribution) can be optimal under certain assumptions as well&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quartiles change&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After applying the incentives, the cut-points for segmenting the distribution into quartiles on future deals will be different. Given your assumptions, you could try forecasting where the new quartiles will exist (after applying the incentives) and adjust the bonus thresholds proactively.&lt;/p&gt;
&lt;p&gt;Thresholds for incentives could also be adjusted dynamically. For example based on a rolling average of the quartiles of recent deals. In this approach, you apply initial incentives and then allow them to change dynamically depending on the resulting distribution of deals – setting guard rails where appropriate. An advantage to this dynamic approach is that the compensation rates gets set based on behavior&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; – which is helpful in cases where you may not trust your ability to set appropriate thresholds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;think-carefully-about-assumptions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Think Carefully About Assumptions&lt;/h3&gt;
&lt;p&gt;Simulating the expected outcome based on assumptions such as the ones described in this post are helpful in thoughtfully elucidating the problem for yourself or for others. Assumptions do not need to be &lt;em&gt;perfect&lt;/em&gt; to be useful for thinking through the problem but they should lean towards the &lt;em&gt;actual&lt;/em&gt; patterns in your example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do Incentives Aggregate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this case, we are assuming incentives aggregate in a linear way. This means that five 1 ppt incentives have the same amount of influence as one 5 ppt incentive. It could be that the former is more influential (people prefer many small bonuses) or the latter is more influential (people prefer one large bonuses)&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It could also be that there is a ‘correct’ size of incentive and that too small an incentive makes no difference but a large incentive has diminishing returns. If this is the case a logistic function or other ‘S’ shaped function may be more reasonable for modeling the influence of incentives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does Influence Degrade With Distance From Incentives?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this case, we are assuming the influence of an incentive exponential decays (the influence decreases by 25% for every point we move from the cut-point). Hence being only a few points away from a cut-point has a big impact, but the degradation is less with each point we move away.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How is Slack Distributed&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I assumed slack (i.e. the possibility of deals being influenced by incentives) was equally distributed. (It could be that slack is distributed disproportionally towards the lower ends of the distribution for example.)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-set-assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to Set Assumptions&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Start with what makes sense (e.g. normal distributions are often good starting places)&lt;/li&gt;
&lt;li&gt;Review historical data&lt;/li&gt;
&lt;li&gt;Set-up formal tests (e.g. create hypotheses and see how behavior adjusts as you change incentives on random subsets of your sales representatives)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;simple-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple Assumptions&lt;/h2&gt;
&lt;p&gt;For this example, we will say the incentives you established are higher compensation rates depending on which quartile the deal falls in. If the deal falls in the lowest quartile they get no increase, in the 2nd quartile they get a 5 percentage point (ppt) increase in pay, the 3rd a 10 ppt increase, the 4th a 15 ppt increase&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For now I’ll pick some overly simple but sensible values for each question:&lt;/em&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;As indicated, we are assuming the ‘natural’ distribution of prices is roughly normal&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We will assume that for every 1 ppt change in incentive that 15% of the deals immediately to the right of the cut-off will be moved up to the cut-off value.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We will assume that this influence degrades by 25% for every dollar you move from the cut-point&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;. I am ignoring the possibility of deals jumping more than on level (e.g. deals moving from the 1st quartile to the 3rd quartile)&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;trade-offs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Trade-offs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A sales rep may have been able to sell more product at a lower price.
&lt;ul&gt;
&lt;li&gt;The additional incentive causes some deals (those selling for lower prices) to be passed on because the incentive to close on the deal for reps has been lowered (this may be intentional in that the impact on price erosion of these deals is worth the decrease in sales…).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;You may have to pay your sales reps more&lt;/li&gt;
&lt;li&gt;Applying such incentives may create additional bureaucratic hurdles in closing deals that increase the friction of closing deals, causing some percentage of deals to be lost
&lt;ul&gt;
&lt;li&gt;It could be that deals don’t have slack in them and are already optimal…&lt;/li&gt;
&lt;li&gt;Any change in pricing behavior has the risk of upsetting customers or having downstream affects.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Ideally&lt;/em&gt; the organization is able to take into account risks and advantages in pricing and set-up incentives that are focused on overall profitability and firm growth (not &lt;em&gt;just&lt;/em&gt; in terms of a single factor).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Limits for Y axis appear too large for this chart but are set from 0 to 0.15 so as to be consistent with similar figures later in post.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;E.g. to prevent brand erosion, improve margins, etc.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;This assumes that there is some slack in the existing deals and that representatives are in a position to impact this and will do so if provided higher incentives.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;or potentially a ‘natural’ distribution that would exist in the absence of incentives&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Key to this assumption is how incentives degrade as you move farther from a cut-point.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;These do not consider potential psychological impacts or difficulty of implementation.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Similar to in a market.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Research into psychological biases suggests the former may be true.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;You could also construct this such that lower quartiles have negative incentives and higher quartiles have positive incentives.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;The functions governing these behaviors are almost certainly more sophisticated.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Factoring this possibility in would likely lead to incentives at the higher quartiles making a slightly larger impact.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Feature Engineering with Sliding Windows and Lagged Inputs</title>
      <link>/2020/10/12/window-functions-for-resampling/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/10/12/window-functions-for-resampling/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#load-data&#34;&gt;Load data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering-data-splits&#34;&gt;Feature Engineering &amp;amp; Data Splits&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lag-based-features-before-split-use-dplyr-or-similar&#34;&gt;Lag Based Features (Before Split, use &lt;code&gt;dplyr&lt;/code&gt; or similar)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-splits&#34;&gt;Data Splits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-features-after-split-use-recipes&#34;&gt;Other Features (After Split, use &lt;code&gt;recipes&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-specification-and-training&#34;&gt;Model Specification and Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-evaluation&#34;&gt;Model Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#model-building-with-hyperparameter-tuning&#34;&gt;Model Building with Hyperparameter Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;The new &lt;code&gt;rsample::sliding_*()&lt;/code&gt; functions bring the windowing approaches used in &lt;a href=&#34;https://github.com/DavisVaughan/slider&#34;&gt;slider&lt;/a&gt; to the sampling procedures used in the &lt;a href=&#34;https://github.com/tidymodels&#34;&gt;tidymodels&lt;/a&gt; framework&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. These functions make evaluation of models with time-dependent variables easier&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For some problems you may want to take a traditional regression or classification based approach&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; while still accounting for the date/time-sensitive components of your data. In this post I will use the &lt;code&gt;tidymodels&lt;/code&gt; suite of packages to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build lag based and non-lag based features&lt;/li&gt;
&lt;li&gt;set-up appropriate time series cross-validation windows&lt;/li&gt;
&lt;li&gt;evaluate performance of linear regression and random forest models on a regression problem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For my example I will use data from Wake County food inspections. I will try to predict the &lt;code&gt;SCORE&lt;/code&gt; for upcoming restaurant food inspections.&lt;/p&gt;
&lt;div id=&#34;load-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Load data&lt;/h1&gt;
&lt;p&gt;You can use Wake County’s open API (does not require a login/account) and the &lt;a href=&#34;https://github.com/r-lib/httr&#34;&gt;httr&lt;/a&gt; and &lt;a href=&#34;https://github.com/jeroen/jsonlite&#34;&gt;jsonlite&lt;/a&gt; packages to load in the data. You can also download the data directly from the Wake County &lt;a href=&#34;https://data.wakegov.com/datasets/1b08c4eb32f44a198277c418b71b3a48_2&#34;&gt;website&lt;/a&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(httr)
library(jsonlite)
library(tidymodels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Get food inspections data:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_insp &amp;lt;- GET(&amp;quot;https://opendata.arcgis.com/datasets/ebe3ae7f76954fad81411612d7c4fb17_1.geojson&amp;quot;)

inspections &amp;lt;- content(r_insp, &amp;quot;text&amp;quot;) %&amp;gt;% 
  fromJSON() %&amp;gt;% 
  .$features %&amp;gt;%
  .$properties %&amp;gt;% 
  as_tibble()

inspections_clean &amp;lt;- inspections %&amp;gt;% 
  mutate(date = ymd_hms(DATE_) %&amp;gt;% as.Date()) %&amp;gt;% 
  select(-c(DATE_, DESCRIPTION, OBJECTID))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Get food locations data:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_rest &amp;lt;- GET(&amp;quot;https://opendata.arcgis.com/datasets/124c2187da8c41c59bde04fa67eb2872_0.geojson&amp;quot;) #json

restauraunts &amp;lt;- content(r_rest, &amp;quot;text&amp;quot;) %&amp;gt;% 
  fromJSON() %&amp;gt;% 
  .$features %&amp;gt;%
  .$properties %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  select(-OBJECTID)

restauraunts &amp;lt;- restauraunts %&amp;gt;% 
  mutate(RESTAURANTOPENDATE = ymd_hms(RESTAURANTOPENDATE) %&amp;gt;% as.Date())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Further prep:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Join the &lt;code&gt;inspections&lt;/code&gt; and &lt;code&gt;restaurants&lt;/code&gt; datasets&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Filter out extreme outliers in &lt;code&gt;SCORE&lt;/code&gt; (likely data entry errors)&lt;/li&gt;
&lt;li&gt;Filter to only locations of &lt;code&gt;TYPE&lt;/code&gt; restaurant&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Filter out potential duplicate entries&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;It’s important to consider which fields should be excluded for ethical reasons. For our problem, we will say that any restaurant name or location information must be excluded&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspections_restaurants &amp;lt;- inspections_clean %&amp;gt;% 
  left_join(restauraunts, by = c(&amp;quot;HSISID&amp;quot;, &amp;quot;PERMITID&amp;quot;)) %&amp;gt;% 
  filter(SCORE &amp;gt; 50, FACILITYTYPE == &amp;quot;Restaurant&amp;quot;) %&amp;gt;% 
  distinct(HSISID, date, .keep_all = TRUE) %&amp;gt;% 
  select(-c(FACILITYTYPE, PERMITID)) %&amp;gt;% 
  select(-c(NAME, contains(&amp;quot;ADDRESS&amp;quot;), CITY, STATE, POSTALCODE, PHONENUMBER, X, Y, GEOCODESTATUS))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspections_restaurants %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 24,294
## Columns: 6
## $ HSISID             &amp;lt;chr&amp;gt; &amp;quot;04092017542&amp;quot;, &amp;quot;04092017542&amp;quot;, &amp;quot;04092017542&amp;quot;, &amp;quot;04...
## $ SCORE              &amp;lt;dbl&amp;gt; 94.5, 92.0, 95.0, 93.5, 93.0, 93.5, 92.5, 94.0, ...
## $ TYPE               &amp;lt;chr&amp;gt; &amp;quot;Inspection&amp;quot;, &amp;quot;Inspection&amp;quot;, &amp;quot;Inspection&amp;quot;, &amp;quot;Inspe...
## $ INSPECTOR          &amp;lt;chr&amp;gt; &amp;quot;Anne-Kathrin Bartoli&amp;quot;, &amp;quot;Laura McNeill&amp;quot;, &amp;quot;Laura ...
## $ date               &amp;lt;date&amp;gt; 2017-04-07, 2017-11-08, 2018-03-23, 2018-09-07,...
## $ RESTAURANTOPENDATE &amp;lt;date&amp;gt; 2017-03-01, 2017-03-01, 2017-03-01, 2017-03-01,...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;feature-engineering-data-splits&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Feature Engineering &amp;amp; Data Splits&lt;/h1&gt;
&lt;p&gt;Discussion on issue &lt;a href=&#34;https://github.com/tidymodels/rsample/pull/168&#34;&gt;#168&lt;/a&gt; suggests that some features (those depending on prior observations) should be created before the data is split&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. The first and last sub-sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lag-based-features-before-split-use-dplyr-or-similar&#34;&gt;Lag Based Features (Before Split, use &lt;code&gt;dplyr&lt;/code&gt; or similar)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-features-after-split-use-recipes&#34;&gt;Other Features (After Split, use &lt;code&gt;recipes&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;provide examples of the types of features that should be created before and after splitting your data respectively. Lag based features can, in some ways, be thought of as ‘raw inputs’ as they should be created prior to building a &lt;code&gt;recipe&lt;/code&gt;&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;lag-based-features-before-split-use-dplyr-or-similar&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lag Based Features (Before Split, use &lt;code&gt;dplyr&lt;/code&gt; or similar)&lt;/h2&gt;
&lt;p&gt;Lag based features should generally be computed prior to splitting your data into “training” / “testing” (or “analysis” / “assessment”&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;) sets. This is because calculation of these features may depend on observations in prior splits&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;. Let’s build a few features where this is the case:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prior &lt;code&gt;SCORE&lt;/code&gt; for &lt;code&gt;HSISID&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Average of prior 3 years of &lt;code&gt;SCORE&lt;/code&gt; for &lt;code&gt;HSISISD&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overall recent (year) prior average &lt;code&gt;SCORE&lt;/code&gt; (across &lt;code&gt;HSISISD&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Days since &lt;code&gt;RESTAURANTOPENDATE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Days since last inspection &lt;code&gt;date&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_time_feats &amp;lt;- inspections_restaurants %&amp;gt;% 
  arrange(date) %&amp;gt;% 
  mutate(SCORE_yr_overall = slider::slide_index_dbl(SCORE, 
                                                    .i = date, 
                                                    .f = mean, 
                                                    na.rm = TRUE, 
                                                    .before = lubridate::days(365), 
                                                    .after = -lubridate::days(1))
         ) %&amp;gt;% 
  group_by(HSISID) %&amp;gt;% 
  mutate(SCORE_lag = lag(SCORE),
         SCORE_recent = slider::slide_index_dbl(SCORE, 
                                                date, 
                                                mean, 
                                                na.rm = TRUE, 
                                                .before = lubridate::days(365*3), 
                                                .after = -lubridate::days(1), 
                                                .complete = FALSE),
         days_since_open = (date - RESTAURANTOPENDATE) / ddays(1),
         days_since_last = (date - lag(date)) / ddays(1)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  arrange(date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The use of &lt;code&gt;.after = -lubridate::days(1)&lt;/code&gt; prevents data leakage by ensuring that this feature does not include information from the current day in its calculation&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-splits&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Splits&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Additional Filtering:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We will presume that the model is only intended for restaurants that have previous inspections on record&lt;a href=&#34;#fn15&#34; class=&#34;footnote-ref&#34; id=&#34;fnref15&#34;&gt;&lt;sup&gt;15&lt;/sup&gt;&lt;/a&gt; and will use only the most recent seven years of data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_time_feats &amp;lt;- data_time_feats %&amp;gt;% 
  filter(date &amp;gt;= (max(date) - years(7)), !is.na(SCORE_lag))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Initial Split:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After creating our lag based features, we can split our data into training and testing splits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;initial_split &amp;lt;- rsample::initial_time_split(data_time_feats, prop = .8)
train &amp;lt;- rsample::training(initial_split)
test &amp;lt;- rsample::testing(initial_split)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Resampling (Time Series Cross-Validation):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For this problem we should evaluate our models using time series cross-validation&lt;a href=&#34;#fn16&#34; class=&#34;footnote-ref&#34; id=&#34;fnref16&#34;&gt;&lt;sup&gt;16&lt;/sup&gt;&lt;/a&gt;. This entails creating multiple ordered subsets of the training data where each set has a different assignment of observations into “analysis” or “assessment” data&lt;a href=&#34;#fn17&#34; class=&#34;footnote-ref&#34; id=&#34;fnref17&#34;&gt;&lt;sup&gt;17&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ideally the resampling scheme used for model evaluation mirrors how the model will be built and evaluated in production. For example, if the production model will be updated once every three months it makes sense that the “assessment” sets be this length. We can use &lt;code&gt;rsample::sliding_period()&lt;/code&gt; to set things up.&lt;/p&gt;
&lt;p&gt;For each set, we will use three years of “analysis” data for training a model and then three months of “assessment” data for evaluation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resamples &amp;lt;- rsample::sliding_period(train, 
                                     index = date, 
                                     period = &amp;quot;month&amp;quot;, 
                                     lookback = 36, 
                                     assess_stop = 3, 
                                     step = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will load in some helper functions I created for reviewing the dates of our resampling windows&lt;a href=&#34;#fn18&#34; class=&#34;footnote-ref&#34; id=&#34;fnref18&#34;&gt;&lt;sup&gt;18&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(&amp;quot;https://gist.github.com/brshallo/7d180bde932628a151a4d935ffa586a5&amp;quot;)

resamples  %&amp;gt;% 
  extract_dates_rset() %&amp;gt;% 
  print() %&amp;gt;% 
  plot_dates_rset() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 6
##    splits         id     analysis_min analysis_max assessment_min assessment_max
##    &amp;lt;list&amp;gt;         &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;       &amp;lt;date&amp;gt;       &amp;lt;date&amp;gt;         &amp;lt;date&amp;gt;        
##  1 &amp;lt;split [6.2K/~ Slice~ 2013-10-09   2016-10-31   2016-11-01     2017-01-31    
##  2 &amp;lt;split [6.3K/~ Slice~ 2014-01-02   2017-01-31   2017-02-01     2017-04-28    
##  3 &amp;lt;split [6.6K/~ Slice~ 2014-04-01   2017-04-28   2017-05-01     2017-07-31    
##  4 &amp;lt;split [7.1K/~ Slice~ 2014-07-01   2017-07-31   2017-08-01     2017-10-31    
##  5 &amp;lt;split [7.5K/~ Slice~ 2014-10-01   2017-10-31   2017-11-01     2018-01-31    
##  6 &amp;lt;split [7.9K/~ Slice~ 2015-01-02   2018-01-31   2018-02-01     2018-04-30    
##  7 &amp;lt;split [8.3K/~ Slice~ 2015-04-01   2018-04-30   2018-05-01     2018-07-31    
##  8 &amp;lt;split [8.6K/~ Slice~ 2015-07-01   2018-07-31   2018-08-01     2018-10-31    
##  9 &amp;lt;split [9K/1K~ Slice~ 2015-10-01   2018-10-31   2018-11-01     2019-01-31    
## 10 &amp;lt;split [9.5K/~ Slice~ 2016-01-04   2019-01-31   2019-02-01     2019-04-30    
## 11 &amp;lt;split [9.9K/~ Slice~ 2016-04-01   2019-04-30   2019-05-01     2019-07-31    
## 12 &amp;lt;split [10.4K~ Slice~ 2016-07-01   2019-07-31   2019-08-01     2019-10-31&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-12-window-functions-for-resampling_files/figure-html/check-resampling-splits-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For purposes of overall &lt;a href=&#34;#model-evaluation&#34;&gt;Model Evaluation&lt;/a&gt;, performance across each period will be weighted equally (regardless of number of observations in a period)&lt;a href=&#34;#fn19&#34; class=&#34;footnote-ref&#34; id=&#34;fnref19&#34;&gt;&lt;sup&gt;19&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn20&#34; class=&#34;footnote-ref&#34; id=&#34;fnref20&#34;&gt;&lt;sup&gt;20&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-features-after-split-use-recipes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other Features (After Split, use &lt;code&gt;recipes&lt;/code&gt;)&lt;/h2&gt;
&lt;p&gt;Where possible, features should be created using the &lt;a href=&#34;https://github.com/tidymodels/recipes&#34;&gt;recipes&lt;/a&gt; package&lt;a href=&#34;#fn21&#34; class=&#34;footnote-ref&#34; id=&#34;fnref21&#34;&gt;&lt;sup&gt;21&lt;/sup&gt;&lt;/a&gt;. &lt;code&gt;recipes&lt;/code&gt; makes pre-processing convenient and helps prevent data leakage.&lt;/p&gt;
&lt;p&gt;It is OK to modify or transform a previously created lag based feature in a &lt;code&gt;recipes&lt;/code&gt; step. Assuming that you created the lag based input as well as your resampling windows in an appropriate manner, you should be safe from data leakage issues when modifying the variables during later feature engineering steps&lt;a href=&#34;#fn22&#34; class=&#34;footnote-ref&#34; id=&#34;fnref22&#34;&gt;&lt;sup&gt;22&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Some features / transformations I’ll make with &lt;code&gt;recipes&lt;/code&gt;:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;collapse rare values for &lt;code&gt;INSPECTOR&lt;/code&gt; and &lt;code&gt;TYPE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log transform &lt;code&gt;days_since_open&lt;/code&gt; and &lt;code&gt;days_since_last&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;add calendar based features&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rec_general &amp;lt;- recipes::recipe(SCORE ~ ., data = train) %&amp;gt;% 
  step_rm(RESTAURANTOPENDATE) %&amp;gt;% 
  update_role(HSISID, new_role = &amp;quot;ID&amp;quot;) %&amp;gt;% 
  step_other(INSPECTOR, TYPE, threshold = 50) %&amp;gt;% 
  step_string2factor(one_of(&amp;quot;TYPE&amp;quot;, &amp;quot;INSPECTOR&amp;quot;)) %&amp;gt;%
  step_novel(one_of(&amp;quot;TYPE&amp;quot;, &amp;quot;INSPECTOR&amp;quot;)) %&amp;gt;%
  step_log(days_since_open, days_since_last) %&amp;gt;% 
  step_date(date, features = c(&amp;quot;dow&amp;quot;, &amp;quot;month&amp;quot;)) %&amp;gt;% 
  update_role(date, new_role = &amp;quot;ID&amp;quot;) %&amp;gt;% 
  step_zv(all_predictors()) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s peak at the features we will be passing into the model building step:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prep(rec_general, data = train) %&amp;gt;% 
  juice() %&amp;gt;% 
  glimpse() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 17,048
## Columns: 12
## $ HSISID           &amp;lt;fct&amp;gt; 04092016152, 04092014520, 04092014483, 04092012102...
## $ TYPE             &amp;lt;fct&amp;gt; Inspection, Inspection, Inspection, Inspection, In...
## $ INSPECTOR        &amp;lt;fct&amp;gt; David Adcock, Naterra McQueen, Andrea Anover, othe...
## $ date             &amp;lt;date&amp;gt; 2013-10-09, 2013-10-09, 2013-10-09, 2013-10-09, 2...
## $ SCORE_yr_overall &amp;lt;dbl&amp;gt; 96.22766, 96.22766, 96.22766, 96.22766, 96.22766, ...
## $ SCORE_lag        &amp;lt;dbl&amp;gt; 96.0, 95.5, 97.0, 94.5, 97.5, 99.0, 96.0, 96.0, 10...
## $ SCORE_recent     &amp;lt;dbl&amp;gt; 96.75000, 95.75000, 97.50000, 95.25000, 96.75000, ...
## $ days_since_open  &amp;lt;dbl&amp;gt; 6.410175, 7.926964, 7.959276, 8.682029, 8.970432, ...
## $ days_since_last  &amp;lt;dbl&amp;gt; 4.709530, 4.941642, 4.934474, 4.875197, 5.117994, ...
## $ SCORE            &amp;lt;dbl&amp;gt; 98.5, 96.0, 96.0, 93.0, 95.0, 93.5, 95.0, 92.0, 98...
## $ date_dow         &amp;lt;fct&amp;gt; Wed, Wed, Wed, Wed, Wed, Wed, Wed, Wed, Wed, Thu, ...
## $ date_month       &amp;lt;fct&amp;gt; Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-specification-and-training&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model Specification and Training&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Simple linear regression model:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_mod &amp;lt;- parsnip::linear_reg() %&amp;gt;% 
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)

lm_workflow_rs &amp;lt;- workflows::workflow() %&amp;gt;% 
  add_model(lm_mod) %&amp;gt;% 
  add_recipe(rec_general) %&amp;gt;% 
  fit_resamples(resamples,
                control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;ranger&lt;/code&gt; Random Forest model (using defaults):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rand_mod &amp;lt;- parsnip::rand_forest() %&amp;gt;% 
  set_engine(&amp;quot;ranger&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)
  
set.seed(1234)
rf_workflow_rs &amp;lt;- workflow() %&amp;gt;% 
  add_model(rand_mod) %&amp;gt;% 
  add_recipe(rec_general) %&amp;gt;% 
  fit_resamples(resamples,
                control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;parsnip::null_model&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The NULL model will be helpful as a baseline Root Mean Square Error (RMSE) comparison.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null_mod &amp;lt;- parsnip::null_model(mode = &amp;quot;regression&amp;quot;) %&amp;gt;% 
  set_engine(&amp;quot;parsnip&amp;quot;)

null_workflow_rs &amp;lt;- workflow() %&amp;gt;% 
  add_model(null_mod) %&amp;gt;% 
  add_formula(SCORE ~ NULL) %&amp;gt;%
  fit_resamples(resamples,
                control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See code in &lt;a href=&#34;#model-building-with-hyperparameter-tuning&#34;&gt;Model Building with Hyperparameter Tuning&lt;/a&gt; for more sophisticated examples that include hyperparameter tuning for &lt;code&gt;glmnet&lt;/code&gt;&lt;a href=&#34;#fn23&#34; class=&#34;footnote-ref&#34; id=&#34;fnref23&#34;&gt;&lt;sup&gt;23&lt;/sup&gt;&lt;/a&gt; and &lt;code&gt;ranger&lt;/code&gt; models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model Evaluation&lt;/h1&gt;
&lt;p&gt;The next several code chunks extract the &lt;em&gt;average&lt;/em&gt; performance across “assessment” sets&lt;a href=&#34;#fn24&#34; class=&#34;footnote-ref&#34; id=&#34;fnref24&#34;&gt;&lt;sup&gt;24&lt;/sup&gt;&lt;/a&gt; or extract the performance across each of the individual “assessment” sets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod_types &amp;lt;- list(&amp;quot;lm&amp;quot;, &amp;quot;rf&amp;quot;, &amp;quot;null&amp;quot;)

avg_perf &amp;lt;- map(list(lm_workflow_rs, rf_workflow_rs, null_workflow_rs), 
                collect_metrics) %&amp;gt;% 
  map2(mod_types, ~mutate(.x, source = .y)) %&amp;gt;% 
  bind_rows() &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_splits_metrics &amp;lt;- function(rs_obj, name){
  
  rs_obj %&amp;gt;% 
    select(id, .metrics) %&amp;gt;% 
    unnest(.metrics) %&amp;gt;% 
    mutate(source = name)
}

splits_perf &amp;lt;- map2(list(lm_workflow_rs, rf_workflow_rs, null_workflow_rs), 
     mod_types, 
     extract_splits_metrics) %&amp;gt;% 
  bind_rows()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The overall performance as well as the performance across splits suggests that both models were better than the baseline (the mean within the analysis set)&lt;a href=&#34;#fn25&#34; class=&#34;footnote-ref&#34; id=&#34;fnref25&#34;&gt;&lt;sup&gt;25&lt;/sup&gt;&lt;/a&gt; and that the linear model outperformed the random forest model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;splits_perf %&amp;gt;% 
  mutate(id = forcats::fct_rev(id)) %&amp;gt;% 
  ggplot(aes(x = .estimate, y = id, colour = source))+
  geom_vline(aes(xintercept = mean, colour = fct_relevel(source, c(&amp;quot;lm&amp;quot;, &amp;quot;rf&amp;quot;, &amp;quot;null&amp;quot;))), 
           alpha = 0.4,
           data = avg_perf)+
  geom_point()+
  facet_wrap(~.metric, scales = &amp;quot;free_x&amp;quot;)+
  xlim(c(0, NA))+
  theme_bw()+
  labs(caption = &amp;quot;Vertical lines are average performance as captured by `tune::collect_metrics()`&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-12-window-functions-for-resampling_files/figure-html/plot-performance-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We could use a paired sample t-test to formally compare the random forest and linear models’ out-of-sample RMSE performance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(
  filter(splits_perf, source == &amp;quot;lm&amp;quot;, .metric == &amp;quot;rmse&amp;quot;) %&amp;gt;% pull(.estimate),
  filter(splits_perf, source == &amp;quot;rf&amp;quot;, .metric == &amp;quot;rmse&amp;quot;) %&amp;gt;% pull(.estimate),
  paired = TRUE
) %&amp;gt;% 
  broom::tidy() %&amp;gt;% 
  mutate(across(where(is.numeric), round, 4)) %&amp;gt;% 
  knitr::kable() &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;conf.low&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;conf.high&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;method&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;alternative&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.0839&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.7277&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0033&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1334&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0343&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paired t-test&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;two.sided&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This suggests the better performance by the linear model &lt;em&gt;is&lt;/em&gt; statistically significant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other potential steps:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is lots more we could do from here&lt;a href=&#34;#fn26&#34; class=&#34;footnote-ref&#34; id=&#34;fnref26&#34;&gt;&lt;sup&gt;26&lt;/sup&gt;&lt;/a&gt;. However the purpose of this post was to provide a short &lt;code&gt;tidymodels&lt;/code&gt; example that incorporates window functions from &lt;code&gt;rsample&lt;/code&gt; and &lt;code&gt;slider&lt;/code&gt; on a regression problem. For more resources on modeling and the &lt;code&gt;tidymodels&lt;/code&gt; framework, see &lt;a href=&#34;https://www.tidymodels.org/&#34;&gt;tidymodels.org&lt;/a&gt; or &lt;a href=&#34;https://www.tmwr.org/&#34;&gt;Tidy Modeling with R&lt;/a&gt;&lt;a href=&#34;#fn27&#34; class=&#34;footnote-ref&#34; id=&#34;fnref27&#34;&gt;&lt;sup&gt;27&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;model-building-with-hyperparameter-tuning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model Building with Hyperparameter Tuning&lt;/h2&gt;
&lt;p&gt;Below is code for tuning a &lt;code&gt;glmnet&lt;/code&gt; linear regression model (use &lt;code&gt;tune&lt;/code&gt; to optimize the L1/L2 penalty)&lt;a href=&#34;#fn28&#34; class=&#34;footnote-ref&#34; id=&#34;fnref28&#34;&gt;&lt;sup&gt;28&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rec_glmnet &amp;lt;- rec_general %&amp;gt;% 
  step_dummy(all_predictors(), -all_numeric()) %&amp;gt;%
  step_normalize(all_predictors(), -all_nominal()) %&amp;gt;% 
  step_zv(all_predictors())

glmnet_mod &amp;lt;- parsnip::linear_reg(penalty = tune(), mixture = tune()) %&amp;gt;% 
  set_engine(&amp;quot;glmnet&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)

glmnet_workflow &amp;lt;- workflow::workflow() %&amp;gt;% 
  add_model(glmnet_mod) %&amp;gt;% 
  add_recipe(rec_glmnet)

glmnet_grid &amp;lt;- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20), mixture = c(0.05, 
    0.2, 0.4, 0.6, 0.8, 1))

glmnet_tune &amp;lt;- tune::tune_grid(glmnet_workflow, 
                         resamples = resamples, 
                         control = control_grid(save_pred = TRUE), 
                         grid = glmnet_grid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And code to tune a &lt;code&gt;ranger&lt;/code&gt; Random Forest model, tuning the &lt;code&gt;mtry&lt;/code&gt; and &lt;code&gt;min_n&lt;/code&gt; parameters&lt;a href=&#34;#fn29&#34; class=&#34;footnote-ref&#34; id=&#34;fnref29&#34;&gt;&lt;sup&gt;29&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rand_mod &amp;lt;- parsnip::rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&amp;gt;% 
  set_engine(&amp;quot;ranger&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)
  
rf_workflow &amp;lt;- workflow() %&amp;gt;% 
  add_model(rand_mod) %&amp;gt;% 
  add_recipe(rec_general)

cores &amp;lt;- parallel::detectCores()

set.seed(1234)
rf_tune &amp;lt;- tune_grid(rf_workflow, 
                         resamples = resamples, 
                         control = control_grid(save_pred = TRUE), 
                         grid = 25)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Link on doing regressions in slider: &lt;a href=&#34;https://twitter.com/dvaughan32/status/1247270052782637056?s=20&#34; class=&#34;uri&#34;&gt;https://twitter.com/dvaughan32/status/1247270052782637056?s=20&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rstudio lightning talk on &lt;code&gt;slider&lt;/code&gt;: &lt;a href=&#34;https://rstudio.com/resources/rstudioconf-2020/sliding-windows-and-calendars-davis-vaughan/&#34; class=&#34;uri&#34;&gt;https://rstudio.com/resources/rstudioconf-2020/sliding-windows-and-calendars-davis-vaughan/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;modeltime&lt;/code&gt; package that applies &lt;code&gt;tidymodels&lt;/code&gt; suite to time series and forecasting problems: &lt;a href=&#34;https://business-science.github.io/modeltime/&#34; class=&#34;uri&#34;&gt;https://business-science.github.io/modeltime/&lt;/a&gt; (business-science course has more fully developed training materials on this topic as well)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;These were announced with version &lt;a href=&#34;https://github.com/tidymodels/rsample/blob/master/NEWS.md&#34;&gt;0.0.8&lt;/a&gt;. The help pages for &lt;code&gt;rsample&lt;/code&gt; (as well as the &lt;code&gt;slider&lt;/code&gt; package) are helpful resources for understanding the three types of sliding you can use, briefly these are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sliding_window()&lt;/code&gt;: only takes into account order / position of dates&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sliding_index()&lt;/code&gt;: slide according to an index&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sliding_period()&lt;/code&gt;: slide according to an index and set k split points based on period (and other function arguments)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;rsample::sliding_index()&lt;/code&gt; and &lt;code&gt;rsample::sliding_period()&lt;/code&gt; are maybe the most useful additions as they allow you to do resampling based on a date/time index. For &lt;code&gt;sliding_index()&lt;/code&gt;, you usually want to make use of the &lt;code&gt;step&lt;/code&gt; argument (otherwise it defaults to having a split for every observation).&lt;/p&gt;
&lt;p&gt;I found &lt;code&gt;rsample::sliding_period()&lt;/code&gt; easier to get acquantied with than &lt;code&gt;rsample::sliding_index()&lt;/code&gt;. However within the &lt;code&gt;slider&lt;/code&gt; package I found &lt;code&gt;slider::sliding_index()&lt;/code&gt; easier to use than &lt;code&gt;slider::sliding_period()&lt;/code&gt;. Perhaps this makes sense as when setting sampling windows you are usually trying to return an object with far fewer rows, that is, collapsed to k number of rows (unless you are doing Leave-One-Out cross-validation). On the other hand, the &lt;code&gt;slider&lt;/code&gt; package is often used in a &lt;code&gt;mutate()&lt;/code&gt; step where you often want to output the same number of observations as are inputted. Perhaps then it is unsurprising the different scenarios when the &lt;code&gt;index&lt;/code&gt; vs &lt;code&gt;period&lt;/code&gt; approach feels more intuitive.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Previously users would have needed to use &lt;code&gt;rsample::rolling_origin()&lt;/code&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;As opposed to a more specialized time-series modeling approach.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;This dataset is updated on an ongoing basis as Food Inspections are conducted. This makes it a poor choice as an example dataset (because results will vary if running in the future when more data has been collected). I used it because I am familiar with the dataset, it made for a good example, and because I wanted a publicly documented example of pulling in data using an API (even a simple one).&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;There is also “violations” dataset available, which may have additional useful features, but which I will ignore for this example.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;For this example I’m pretending that we only care about predicting &lt;code&gt;SCORE&lt;/code&gt; for restaurants… as opposed to food trucks or other entities that may receive inspections.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Or at least cases where historical data is claiming there were multiple inspections on the same day.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;In some cases you may need to be more careful than this and exclude information that are proxies for inappropriate fields as well. For example, pretend that the &lt;code&gt;INSPECTOR&lt;/code&gt;s are assigned based on region. In this case, &lt;code&gt;INSPECTOR&lt;/code&gt; would be a proxy for geographic information and perhaps warranting exclusion as well (in certain cases).&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;Into training / testing sets or analysis / assessment sets.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;As discussed by Davis Vaughn at the end of this &lt;a href=&#34;https://gist.github.com/DavisVaughan/433dbdceb439c9be30ddcc78d836450d&#34;&gt;gist&lt;/a&gt;.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;An “Analysis” / “Assessment” split is similar to a “training” / “testing” split but within the training dataset (and typically multiple of these are created on the same training dataset). See section 3.4 of &lt;a href=&#34;http://www.feat.engineering/resampling.html&#34;&gt;Feature Engineering and Selection…&lt;/a&gt; for further explanation.]&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;It is important that these features be created in a way that does not cause data leakage.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Which would not be available at the time of prediction.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;I’m a fan of the ability to use negative values in the &lt;code&gt;.after&lt;/code&gt; argument:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
This is a fairly obscure feature in {slider}, but I love it. Don’t want the current day in your rolling window? Set a negative &lt;code&gt;.after&lt;/code&gt; value to shift the end of the window backwards. For example:&lt;br&gt;&lt;br&gt;On day 5&lt;br&gt;.before = days(3)&lt;br&gt;.after = -days(1)&lt;br&gt;&lt;br&gt;Includes days:&lt;br&gt;[2, 4] &lt;a href=&#34;https://t.co/rG0IGuTj1c&#34;&gt;https://t.co/rG0IGuTj1c&lt;/a&gt;
&lt;/p&gt;
— Davis Vaughan (&lt;span class=&#34;citation&#34;&gt;@dvaughan32&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/dvaughan32/status/1233116713010573312?ref_src=twsrc%5Etfw&#34;&gt;February 27, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn15&#34;&gt;&lt;p&gt;If I did not make this assumption, I would need to impute the time based features at this point.&lt;a href=&#34;#fnref15&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn16&#34;&gt;&lt;p&gt;Two helpful resources for understanding time series cross-validation:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;From &lt;a href=&#34;https://eng.uber.com/forecasting-introduction/&#34;&gt;uber engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;From &lt;a href=&#34;https://otexts.com/fpp3/tscv.html&#34;&gt;Forecasting Principles and Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;a href=&#34;#fnref16&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn17&#34;&gt;&lt;p&gt;An “Analysis” / “Assessment” split is similar to a “training” / “testing” split but within the training dataset (and typically multiple of these are created on the same training dataset). See section 3.4 of &lt;a href=&#34;http://www.feat.engineering/resampling.html&#34;&gt;Feature Engineering and Selection…&lt;/a&gt; for further explanation.]&lt;a href=&#34;#fnref17&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn18&#34;&gt;&lt;p&gt;I’ve tweeted previously about helper functions for reviewing your resampling scheme:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
❤️new &lt;code&gt;rsample::sliding_*()&lt;/code&gt; funs by &lt;a href=&#34;https://twitter.com/dvaughan32?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@dvaughan32&lt;/span&gt;&lt;/a&gt;. It can take a minute to check that all arguments are set correctly. Here are helper funs I&#39;ve used to check that my resampling windows are constructed as intended: &lt;a href=&#34;https://t.co/HhSjuRzAsB&#34;&gt;https://t.co/HhSjuRzAsB&lt;/a&gt; may make into an &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/shiny?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#shiny&lt;/a&gt; dashboard. &lt;a href=&#34;https://t.co/sNloHfkh4a&#34;&gt;pic.twitter.com/sNloHfkh4a&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1314720234373287937?ref_src=twsrc%5Etfw&#34;&gt;October 10, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;a href=&#34;#fnref18&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn19&#34;&gt;&lt;p&gt;Note that using &lt;code&gt;rsample::sliding_period()&lt;/code&gt; is likely to produce different numbers of observations between splits.&lt;a href=&#34;#fnref19&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn20&#34;&gt;&lt;p&gt;It could also make sense to weight performance metrics by number of observations. One way to do this, would be to use a control function to extract the predictions, and then evaluate the performance across the predictions. In my examples below I do keep the predictions, but end-up not doing anything with them. Alternatively you could weight the performance metric by number of observations. The justification for weighting periods of different number of observations equally is that noise may vary consistently across time windows – weighting by observations may allow an individual time period too much influence (simply because it happened to be that there were a greater proportion of inspections at that period).&lt;a href=&#34;#fnref20&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn21&#34;&gt;&lt;p&gt;For each split, this will then build the features for the assessment set based on each analysis set.&lt;a href=&#34;#fnref21&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn22&#34;&gt;&lt;p&gt;Although I just do a simple &lt;code&gt;step_log()&lt;/code&gt; transform below, more sophisticated steps on lag based inputs would also be kosher, e.g. &lt;code&gt;step_pca()&lt;/code&gt;. However there is a good argument that many of these should be done prior to a &lt;code&gt;recipes&lt;/code&gt; step. For example, say you have missing values for some of the lag based inputs – in that case it may make sense to use a lag based method for imputation, which may work better than say a mean imputation using the training set. So, like many things, just be thoughtful and constantly ask youself what will be the ideal method while &lt;em&gt;being careful&lt;/em&gt; that, to the question of “will this data be available prior to the prediction?” that you can answer in the affirmitive.&lt;a href=&#34;#fnref22&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn23&#34;&gt;&lt;p&gt;Our number of observations is relatively high compared to the number of features, so there is a good chance we will have relatively low penalties. While working interactively, I did not see any substantive difference in performance.&lt;a href=&#34;#fnref23&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn24&#34;&gt;&lt;p&gt;Remember that this is not weighted by observations, so each assessment set impacts the overall performance equally, regardless of small differences in number of observations.&lt;a href=&#34;#fnref24&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn25&#34;&gt;&lt;p&gt;There is no baseline performance for Rsquared because the metric itself is based off amount of variance that is explained compared to the baseline (i.e. the mean).&lt;a href=&#34;#fnref25&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn26&#34;&gt;&lt;p&gt;You would likely iterate on the model building process (e.g. perform exploratory data analysis, review outliers in initial models, etc.) and eventually get to a final set of models to evaluate on the test set.&lt;a href=&#34;#fnref26&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn27&#34;&gt;&lt;p&gt;I added a few other links to the &lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt; section in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;a href=&#34;#fnref27&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn28&#34;&gt;&lt;p&gt;Our number of observations is relatively high compared to the number of features, so there is a good chance we will have relatively low penalties.&lt;a href=&#34;#fnref28&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn29&#34;&gt;&lt;p&gt;This was taking a &lt;em&gt;long&lt;/em&gt; time and is part of why I decided to move the tuned examples to the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;.&lt;a href=&#34;#fnref29&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>animation on Bryan Shalloway&#39;s Blog</title>
    <link>/tags/animation/</link>
    <description>Recent content in animation on Bryan Shalloway&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/animation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Animate interactive objects with Face Detection, JavaScript and Chrome Browser</title>
      <link>/2020/07/20/animate-interactive-objects-with-face-detection-javascript-and-chrome-browser/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/20/animate-interactive-objects-with-face-detection-javascript-and-chrome-browser/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#things-following-you&#34;&gt;Things following you&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#codepen-example&#34;&gt;Codepen example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-i-made-it&#34;&gt;How I made it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#next-steps&#34;&gt;Next steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learning-path-and-resources&#34;&gt;Learning path and resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#closing-thoughts&#34;&gt;Closing thoughts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#additional-actions&#34;&gt;Additional actions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;We spend the majority of our time in front of screens. It‚Äôs mostly one of computer/tablet/phone/tv&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. These are largely platforms the user owns or controls. I‚Äôm surprised we don‚Äôt yet have more interactions with screens &lt;em&gt;out in the world&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Face detection and object recognition technologies are now highly accessible, making it easy to use a camera to make a display interactive. In this post I‚Äôll describe my starting place on a small project using this technology to create an animation designed to unnerve the user.&lt;/p&gt;
&lt;div id=&#34;things-following-you&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Things following you&lt;/h1&gt;
&lt;p&gt;Try to recall that creepy sensation you get when someone or something is looking at you. Now imagine having that all of the time. That is the unsettled feeling I want to evoke. A few ideas:&lt;/p&gt;
Poster for a new Lord of the Rings movie that has an Eye of Sauron that follows you as you walk into the cinema&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.
&lt;center&gt;
&lt;img src=&#34;https://i.insider.com/5aec114a19ee861f008b4855?width=1200&amp;amp;format=jpeg&amp;amp;auto=webp&#34; title=&#34;fig:&#34; alt=&#34;Eye of Sauron&#34; style=&#34;width:50.0%&#34; /&gt;
&lt;/center&gt;
An army recruiter with an ‚ÄúI want you‚Äù Uncle Sam poster behind him whose finger points at you as you walk by.
&lt;center&gt;
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Unclesamwantyou.jpg/440px-Unclesamwantyou.jpg&#34; title=&#34;fig:&#34; alt=&#34;Uncle Sam&#34; style=&#34;width:50.0%&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Someone at the grocery store (during COVID19) whose shirt beeps and flashes red if you get within 6 feet of them.&lt;/p&gt;
&lt;p&gt;I intentionally made these examples somewhat dystopian. There is an important societal reckoning taking place right now regarding tracking technologies (particularly in regard to its impacts on communities of color). I wanted to work on something that, while playful, would call to mind concerns of a ‚ÄòBig Brother‚Äô or ‚Äòwatchful eye‚Äô like figure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;codepen-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Codepen example&lt;/h1&gt;
&lt;p&gt;As a starting place, I focused on animating an eye that would track a user that looked at it&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;strong&gt;Here is my first draft:&lt;/strong&gt;
&lt;div class=&#34;iframe-container&#34;&gt;
&lt;p&gt;&lt;iframe width=&#34;100%&#34; src=&#34;https://www.youtube.com/embed/UPAgQxaDDCo&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;If you want to set it up:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a Chrome browser and enable &lt;a href=&#34;chrome://flags/#enable-experimental-web-platform-features&#34;&gt;experimental web platform features&lt;/a&gt; (currently only works on Chrome and does not yet work on Android, iOS, or Linux)&lt;/li&gt;
&lt;li&gt;Go to my &lt;a href=&#34;https://codepen.io/brshallo/full/qBbyrLg&#34;&gt;codepen&lt;/a&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Allow use of webcam when prompted&lt;/li&gt;
&lt;li&gt;For a better view, ensure you are on the ‚ÄòResults‚Äô tab and press the F11 key to hide the browser bar&lt;/li&gt;
&lt;li&gt;You will likely need to refresh when opening or when resizing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you want to use it to creep out the family members you are locked at home with, see the &lt;a href=&#34;#additional-actions&#34;&gt;Additional actions&lt;/a&gt; section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-i-made-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How I made it&lt;/h1&gt;
&lt;p&gt;To get the video and initial face detection set-up, I copied code from &lt;a href=&#34;https://github.com/wesbos/beginner-javascript/tree/764f0d589e6affeda2c0b6f17874311188de0d57/exercises/55%20-%20Face%20Detection%20Censorship&#34;&gt;this github repo&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/wesbos&#34;&gt;Wes Bos&lt;/a&gt;. To animate the eye I used an html5 canvas element and JavaScript. The eye simply follows your position in the video. Though I did a few things to make the eye movement look more interesting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rather than updating with every frame, it estimates your position based on the moving average of 10 frames, this makes the movement appear more smooth and softens the jitters of the algorithm constantly updating its estimate of your position.&lt;/li&gt;
&lt;li&gt;I used some trigonometry to soften the tracking so that the pupil‚Äôs movement would look more realistic at a distance.&lt;/li&gt;
&lt;li&gt;I also have the components of the eye slightly change shape and turn in or out depending on your position.&lt;/li&gt;
&lt;li&gt;However this is very much still a work in progress&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; ‚Äì fixing the eye tracking is the major focus area for &lt;a href=&#34;#next-steps&#34;&gt;Next steps&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next steps&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Improve position mapping:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using estimates of the length of facial landmarks, you can estimate the distance someone is from the screen. See relevant project on &lt;a href=&#34;https://github.com/philiiiiiipp/Android-Screen-to-Face-Distance-Measurement&#34;&gt;github&lt;/a&gt;&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;. Once you have an estimate of someone‚Äôs position, you can more accurately adjust the animation so that the eye looks like it is following the user through space&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. Here is a ‚Äòback of the napkin‚Äô sketch of my mental model for the problem:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-07-20-animate-interactive-objects-with-face-detection-javascript-and-chrome-browser_files/back-of-napkin-eyeball.jpg&#34; alt=&#34;Diagram of key location points for animating eyeball with reference to a user.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Diagram of key location points for animating eyeball with reference to a user.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Once you have an estimate of the distance a face is from the camera, the important points for the projection of the eye to a 2d animation can be filled-in (with just a little bit of trigonometry). Ultimately I‚Äôd love to do something like can be found at this &lt;a href=&#34;https://github.com/evermeer/EVFaceTracker&#34;&gt;github repo&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/evermeer/EVFaceTracker/raw/master/EVFaceTracker.gif?raw=true&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
Or picture a digital version of the creepy t-rex meme that was going around:
&lt;div class=&#34;iframe-container&#34;&gt;
&lt;p&gt;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/A4QcyW-qTUg?start=9&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;but tailored to where the user is standing. However this may be limited&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;, also the view would be tailored to a single user&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Improve everything else:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The above improvements would require a great deal more sophistication in the animation. I‚Äôd also like to improve the code quality. All of these &lt;a href=&#34;#next-steps&#34;&gt;Next steps&lt;/a&gt; are largely aspirational ‚Äì this project is &lt;em&gt;far removed&lt;/em&gt; from my day job and I am inexperienced in much of the underlying technologies / software. Hence I‚Äôm unsure when I‚Äôll pick this back-up&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-path-and-resources&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Learning path and resources&lt;/h1&gt;
&lt;p&gt;My initial plan (for building the eye tracking component) was to use the python bindings for OpenCV&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt; for the face detection. I would then use the open source video editing software, &lt;em&gt;Blender&lt;/em&gt; (which can also run python scripts) to overlay an animation&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;. See &lt;a href=&#34;https://www.youtube.com/watch?v=O7nNO3FLkLU&#34;&gt;example&lt;/a&gt; where someone uses webcam and Blender to demo their face animations on a character. A problem with this approach is that Blender is not a light-weight application. Hence I wasn‚Äôt sure how I would easily deploy it‚Ä¶ so I investigated alternative approaches.&lt;/p&gt;
&lt;p&gt;Near the end of &lt;a href=&#34;https://www.youtube.com/watch?v=8p5SDI4TNDc&#34;&gt;this presentation&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/cassiecodes?lang=en&#34;&gt;Cassie Evans&lt;/a&gt; on making interactive SVG images is where I learned about Google Chrome‚Äôs experimental shape detection API. I then found Wes Bos‚Äôs tweet on the subject.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
üòÆ Did you know Chrome has a FaceDetector API? &lt;a href=&#34;https://t.co/wSwDdI8p1u&#34;&gt;pic.twitter.com/wSwDdI8p1u&lt;/a&gt;
&lt;/p&gt;
‚Äî Wes Bos (&lt;span class=&#34;citation&#34;&gt;@wesbos&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/wesbos/status/976097163834019842?ref_src=twsrc%5Etfw&#34;&gt;March 20, 2018&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;I decided to go this route because of the relative simplicity of the shape detection API and the ease with which I could then deploy a first draft through a Chrome browser. &lt;em&gt;A problem&lt;/em&gt; was that I needed to learn some web development (or at least JavaScript) basics.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Preliminary learning resources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;About 40% of the videos/exercises from the first three courses of &lt;a href=&#34;https://www.coursera.org/specializations/web-design#courses&#34;&gt;University of Michigan‚Äôs Web Design series on coursera&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/ColleenAtUMSI&#34;&gt;Colleen van Lent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The first few chapters of &lt;a href=&#34;https://learn.shayhowe.com/html-css/building-your-first-web-page/&#34;&gt;Learn to Code HTML &amp;amp; CSS&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/shayhowe&#34;&gt;Shay Howe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Most of the &lt;a href=&#34;https://www.youtube.com/watch?v=EO6OkltgudE&amp;amp;list=PLpPnRKq7eNW3We9VdCfx9fprhqXHwTPXL&#34;&gt;tutorials on HTML5 canvas&lt;/a&gt; elements by &lt;a href=&#34;https://twitter.com/chriscourses?lang=en&#34;&gt;Chris Courses&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rather than using SVG‚Äôs, I ended-up just using a canvas element and JavaScript&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Closing thoughts&lt;/h1&gt;
&lt;p&gt;Try it out or consider ways you can make something engaging or surprising for users. If you do, please let me know at &lt;a href=&#34;https://twitter.com/brshallo&#34;&gt;brshallo&lt;/a&gt; on Twitter üòÑ.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;p&gt;Associated Twitter post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
New addition to the livingroom, giant eyeball that follows you around when you look at it.&lt;br&gt;&lt;br&gt;See blog on how I made it using &lt;a href=&#34;https://twitter.com/chrome?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@chrome&lt;/span&gt;&lt;/a&gt; browser&#39;s &lt;a href=&#34;https://twitter.com/hashtag/FaceDetection?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FaceDetection&lt;/a&gt; api and &lt;a href=&#34;https://twitter.com/hashtag/JavaScript?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#JavaScript&lt;/a&gt; : &lt;a href=&#34;https://t.co/S993yWZEpn&#34;&gt;https://t.co/S993yWZEpn&lt;/a&gt; &lt;a href=&#34;https://t.co/1ebjaGmPzC&#34;&gt;pic.twitter.com/1ebjaGmPzC&lt;/a&gt;
&lt;/p&gt;
‚Äî Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1285394365855211520?ref_src=twsrc%5Etfw&#34;&gt;July 21, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;additional-actions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional actions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ensure there is &lt;em&gt;good&lt;/em&gt; lighting, tracking tends to get jumpy at a distance (honestly only works so-so at this point)&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Plug device into a TV or larger display&lt;/li&gt;
&lt;li&gt;Get the camera lined-up (ideally is close to eye-level)&lt;/li&gt;
&lt;li&gt;Call your loved one into the room and wait for them to notice and start interacting with the giant eye ball that is following them&lt;/li&gt;
&lt;li&gt;For &lt;em&gt;bonus&lt;/em&gt; points capture it on video and tweet it at me or with an appropriate hashtag (e.g.¬†#eyeseeyou)&lt;/li&gt;
&lt;li&gt;For &lt;em&gt;bonus&lt;/em&gt; bonus points, edit (or improve) the code and make some fun new animation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Maybe also Peloton, car display, watch, Mirror‚Ä¶ (if you‚Äôre fancy).&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Similarly, picture a portrait whose eyes follow you as you walk-by ‚Äì similar to Mark Rober‚Äôs [video] (&lt;a href=&#34;https://www.youtube.com/watch?v=sPgKu2E-jdw&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=sPgKu2E-jdw&lt;/a&gt;), but tracking you automatically.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;And that could be easily shared across devices.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;This is my first project using JavaScript (don‚Äôt expect much when it comes to code quality).&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;There are errors and most of the math here is almost nonsensical.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;For my use-case though I may use face height rather than (or in addition to) face width ‚Äì as cannot trust that people will be turned towards my camera and figure it is less likely they will tilt their head.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Though may be somewhat limited as a user has two eyes, not just one, so depth illusion might not work perfectly.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Afterall, we‚Äôre not working with holograms or special glasses.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;The animation would become distorted for users other than the individual the animation is tracking.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;But wanted to at least post this first draft&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Open Computer Vision&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;Or some python animation library I might be able to find.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Again, don‚Äôt expect much when it comes to code quality.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;Perhaps will fix / improve in future.&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Use Flipbooks to Explain Your Code and Thought Process</title>
      <link>/2020/06/24/use-flipbooks-to-explain-your-code-and-thought-process/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/24/use-flipbooks-to-explain-your-code-and-thought-process/</guid>
      <description>


&lt;div id=&#34;learning-rs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Learning R‚Äôs &lt;code&gt;%&amp;gt;%&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Using the pipe operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) is one of my favorite things about coding in R and the &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt;. However when it was first shown to me, I couldn‚Äôt understand what the &lt;a href=&#34;https://twitter.com/search?q=%23rstats&amp;amp;src=typed_query&#34;&gt;#rstats&lt;/a&gt; nut describing it was &lt;em&gt;so enthusiastic&lt;/em&gt; about. They tried to explain, ‚ÄúIt means &lt;em&gt;and then&lt;/em&gt; do the next operation.‚Äù When that didn‚Äôt click for me, they continued (while becoming ever more excited) ‚ÄúIt &lt;em&gt;passes the previous steps output into the first argument&lt;/em&gt; of the next function,‚Äù still‚Ä¶ üòêüòêüòï.
Self-evident verbs in their code like &lt;code&gt;select()&lt;/code&gt;, &lt;code&gt;filter()&lt;/code&gt;, &lt;code&gt;summarise()&lt;/code&gt; helped me nod along, partly following the operations. Though it wasn‚Äôt until I evaluated the code &lt;em&gt;line-by-line&lt;/em&gt; that I recognized the pipe‚Äôs elegance, power, beauty, simplicity üòÑ!&lt;/p&gt;
&lt;p&gt;Now, a few years and reads through &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt; later&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, I will often share my work by keeping the code and output together and showing, line-by-line, what I am building towards. For example when‚Ä¶&lt;/p&gt;
&lt;p&gt;‚Ä¶ giving a 2019 talk on &lt;em&gt;‚ÄúManaging objects in analytics workflows, using lists as columns in dataframes‚Äù&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/gme4Fb9JVjk?start=258&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/blockquote&gt;
&lt;p&gt;‚Ä¶ giving a 2017 talk on &lt;em&gt;‚ÄúGetting started with ‚Äòtidy‚Äô data science in R‚Äù&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/eeCELJNWEuw?start=474&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/blockquote&gt;
&lt;p&gt;‚Ä¶ promoting a recent blog post on &lt;em&gt;‚ÄúTidy pairwise operations‚Äù&lt;/em&gt; (though in this case I removed the code):&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
What is your &lt;a href=&#34;https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#tidyverse&lt;/a&gt; (or other &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; ) approach for doing arbitrary pairwise operations across variables? Mine is frequently something like:&lt;br&gt;&lt;br&gt;I. nest‚Ä¶&lt;br&gt;II. expand combos‚Ä¶ &lt;br&gt;III. filter‚Ä¶&lt;br&gt;IV. map fun(s)‚Ä¶&lt;br&gt;‚Ä¶&lt;br&gt;&lt;br&gt;I wrote a post walking through this: &lt;a href=&#34;https://t.co/xRnRf5yh3m&#34;&gt;https://t.co/xRnRf5yh3m&lt;/a&gt; &lt;a href=&#34;https://t.co/Zvxey2gm3H&#34;&gt;pic.twitter.com/Zvxey2gm3H&lt;/a&gt;
&lt;/p&gt;
‚Äî Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1271194908477591553?ref_src=twsrc%5Etfw&#34;&gt;June 11, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;p&gt;However each of these examples were built using PowerPoint (and a lot of copy and pasting of code + output). The series of images cannot be easily reproduced. In this post I‚Äôll point to resources on how to create these sorts of code communication materials in ways that &lt;em&gt;are reproducible&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;flipbooks&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Flipbooks&lt;/h1&gt;
&lt;p&gt;When I started writing this post, I planned to call this type of output a ‚Äú&lt;strong&gt;LEXPREX&lt;/strong&gt;‚Äù for ‚Äú&lt;strong&gt;L&lt;/strong&gt;ine-by-line &lt;strong&gt;EX&lt;/strong&gt;ecution with &lt;strong&gt;PR&lt;/strong&gt;inted &lt;strong&gt;EX&lt;/strong&gt;amples‚Äù (and a name evocative of the inspiring &lt;a href=&#34;https://github.com/tidyverse/reprex&#34;&gt;reprex&lt;/a&gt; package by &lt;a href=&#34;https://twitter.com/JennyBryan%5D&#34;&gt;Jenny Bryan&lt;/a&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;). But, thankfully, an excellent solution containing thorough explanations (and a much better name) already existed, &lt;em&gt;flipbooks&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As described in the &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;flipbookr documentation&lt;/a&gt;, ‚Äúflipbooks are tools that present side-by-side, aligned, incremental code-output.‚Äù&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://github.com/brshallo/flipbookr-gifs-examples/raw/master/example-r4ds.gif?raw=true&#34; alt=&#34;(Example inspired by ‚ÄòMany Models‚Äô chapter of ‚ÄòR For Data Science‚Äô by Grolemund &amp;amp; Wickham.)&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;(Example inspired by ‚ÄòMany Models‚Äô chapter of ‚ÄòR For Data Science‚Äô by Grolemund &amp;amp; Wickham.)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;At this point you should stop reading this blog and instead go learn about &lt;a href=&#34;https://github.com/EvaMaeRey/flipbookr&#34;&gt;flipbookr&lt;/a&gt;. My post was largely written before I learned about this package. Hence, starting at &lt;a href=&#34;https://rstudio.com/resources/rstudioconf-2020/flipbooks-evangeline-reynolds/&#34;&gt;this presentation&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/EvaMaeRey&#34;&gt;Gina Reynolds&lt;/a&gt; or &lt;code&gt;flipbookr&lt;/code&gt;‚Äôs &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;about page&lt;/a&gt; will generally be a more productive use of your time. The remainder of this post discusses either tools adjacent to flipbooks or describes workflows that can also be found within &lt;code&gt;flipbookr&lt;/code&gt; documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-with-xaringan&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example with xaringan&lt;/h1&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/yihui/xaringan&#34;&gt;xaringan&lt;/a&gt; package for making slideshows contains highlighting features (and is what &lt;code&gt;flipbookr&lt;/code&gt; is built-on). For highlighting &lt;em&gt;code&lt;/em&gt; you can use the trailing comment &lt;code&gt;#&amp;lt;&amp;lt;&lt;/code&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. For highlighting &lt;em&gt;output&lt;/em&gt; there is the &lt;code&gt;highlight.output&lt;/code&gt; code chunk option.&lt;/p&gt;
&lt;blockquote&gt;
&lt;iframe src=&#34;https://slides.yihui.org/xaringan/#31&#34; style=&#34;width: 560px; height: 315px;&#34;&gt;
&lt;/iframe&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/mitchoharawild&#34;&gt;Mitchell O‚ÄôHara-Wild&lt;/a&gt;‚Äôs 2019 presentation on &lt;em&gt;‚ÄúFlexible futures for &lt;a href=&#34;https://github.com/tidyverts/fable&#34;&gt;fable&lt;/a&gt; functionality‚Äù&lt;/em&gt; contains a helpful example where he uses these features to walk-through &lt;a href=&#34;https://github.com/mitchelloharawild/fable-combinations-2019/blob/6a55628e1ad156c0040676b7881a799f7f75370a/user2019/index.Rmd&#34;&gt;his code&lt;/a&gt;.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/DhDOTxojQ3k?start=554&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;See &lt;a href=&#34;#more-sophisticated-highlighting&#34;&gt;More sophisticated highlighting&lt;/a&gt; if your use-case requires more than line-level highlighting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animating-a-flipbook&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Animating a flipbook&lt;/h1&gt;
&lt;p&gt;I sometimes want to convert a flipbook into a gif, e.g.¬†when sharing an example in a README or a snippet of a concept on social media. If you ignored my prior entreaty, this is a second reminder to stop and go read about &lt;code&gt;flipbookr&lt;/code&gt;. The &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;template file&lt;/a&gt; now shows how to create gifs using &lt;code&gt;flipbookr&lt;/code&gt; (html) ‚Äì&amp;gt; &lt;code&gt;pagedown&lt;/code&gt; (pdf) ‚Äì&amp;gt; &lt;code&gt;magick&lt;/code&gt; (gif). I also describe this workflow and provide examples &lt;a href=&#34;https://github.com/brshallo/flipbookr-gifs-examples&#34;&gt;here&lt;/a&gt;, e.g.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://github.com/brshallo/flipbookr-gifs-examples/raw/master/example-riddler-solution.gif&#34; alt=&#34;(Example from a prior blog post, ‚ÄúRiddler Solutions: Pedestrian Puzzles‚Äù)&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;(Example from a prior blog post, ‚ÄúRiddler Solutions: Pedestrian Puzzles‚Äù)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-note&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Closing note&lt;/h1&gt;
&lt;p&gt;I recommend exploring the &lt;a href=&#34;https://education.rstudio.com/blog/&#34;&gt;Rstudio Education blog&lt;/a&gt;. The site contains helpful resources for improving your technical communication. It was here that I stumbled on the post &lt;a href=&#34;https://education.rstudio.com/blog/2020/05/flair/&#34;&gt;Decorate your R code with flair&lt;/a&gt;. Reading this inspired me to make a first attempt at building a reproducible animation of line-by-line execution of R code (something I‚Äôd been wanting to do for ages). The positive response &amp;amp; feedback to my initial tweet led me to learn about &lt;code&gt;flipbookr&lt;/code&gt; and motivated additional actions (described in &lt;a href=&#34;#engagement-contributions&#34;&gt;Engagement &amp;amp; contributions&lt;/a&gt;) including the review and completion of this blog post.&lt;/p&gt;
&lt;p&gt;Finally, please go enjoy the beautiful examples you can find at the &lt;code&gt;flipbookr&lt;/code&gt; &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;about page&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;&lt;img src=&#34;/post/2020-06-16-use-flipbooks-to-explain-your-code-and-thought-process_files/flipbookr-example.gif&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;more-sophisticated-highlighting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More sophisticated highlighting&lt;/h2&gt;
&lt;p&gt;For more sophisticated highlighting of &lt;em&gt;code&lt;/em&gt;, use the &lt;a href=&#34;https://github.com/kbodwin/flair&#34;&gt;flair package&lt;/a&gt;. I‚Äôm not sure what to recommend for highlighting changes in &lt;em&gt;output&lt;/em&gt; to the console‚Ä¶ perhaps &lt;a href=&#34;https://github.com/brodieG/diffobj&#34;&gt;diffobj&lt;/a&gt; would be an option. You could also just explicitly format the output, e.g.¬†using &lt;a href=&#34;https://github.com/rstudio/gt&#34;&gt;gt&lt;/a&gt; or &lt;a href=&#34;https://github.com/haozhu233/kableExtra&#34;&gt;kableExtra&lt;/a&gt; for tabular outputs, or using geoms, annotations, etc. in &lt;a href=&#34;https://github.com/tidyverse/ggplot2&#34;&gt;ggplot&lt;/a&gt;s. And, of course, you can always dive into the html.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;engagement-contributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Engagement &amp;amp; contributions&lt;/h2&gt;
&lt;p&gt;Blogging is time consuming. Reaching out to package maintainers or making contributions (even small ones) on open-source software projects can be intimidating. As a &lt;em&gt;tiny&lt;/em&gt; success story, I documented actions that stemmed (in some part) from engaging with the #rstats online communities while working on this blog post topic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;While this post was in draft form, I tweeted out my initial approach (that used the &lt;a href=&#34;https://github.com/kbodwin/flair&#34;&gt;flair&lt;/a&gt; package).
&lt;ul&gt;
&lt;li&gt;The next step might have been trying to improve upon this. Thankfully, instead, &lt;a href=&#34;https://twitter.com/KellyBodwin&#34;&gt;Kelly Bodwin&lt;/a&gt; pointed me to &lt;code&gt;flipbookr&lt;/code&gt;!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
P.S. &lt;br&gt;&lt;br&gt;The &lt;code&gt;flair_lines()&lt;/code&gt; function lets you highlight whole line(s) if you want! &lt;br&gt;&lt;br&gt;{flipbookr} is a better option for making gifs/slides like this, but {flair} + {pagedown} + {magick} might help if you want specialty or layered highlighting.
&lt;/p&gt;
‚Äî Kelly Bodwin (&lt;span class=&#34;citation&#34;&gt;@KellyBodwin&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/KellyBodwin/status/1272741205365764097?ref_src=twsrc%5Etfw&#34;&gt;June 16, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Kelly also created an &lt;a href=&#34;https://github.com/kbodwin/flair/issues/15&#34;&gt;issue&lt;/a&gt; to further discuss possible integrations between &lt;code&gt;flair&lt;/code&gt; and &lt;code&gt;flipbookr&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I remade my initial example using &lt;code&gt;flipbookr&lt;/code&gt; (&lt;a href=&#34;https://github.com/EvaMaeRey/flipbookr/issues/22&#34;&gt;see issue&lt;/a&gt;).
&lt;ul&gt;
&lt;li&gt;I first created an &lt;a href=&#34;https://github.com/EvaMaeRey/flipbookr/issues/21&#34;&gt;issue&lt;/a&gt; showing how to print &lt;code&gt;xaringan&lt;/code&gt; slides incrementally using &lt;code&gt;pagedown::chrome_print()&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;Which helped to close a related &lt;a href=&#34;https://github.com/rstudio/pagedown/issues/110&#34;&gt;issue&lt;/a&gt; on &lt;code&gt;xaringan&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Gina Reynolds made a variety of updates to &lt;code&gt;flipbookr&lt;/code&gt;, one of which included adding the html ‚Äì&amp;gt; pdf ‚Äì&amp;gt; gif workflow to the template üòÑ.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Big thanks to &lt;a href=&#34;https://twitter.com/grrrck?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@grrrck&lt;/span&gt;&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/statsgen?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@statsgen&lt;/span&gt;&lt;/a&gt; for helps and &lt;a href=&#34;https://twitter.com/xieyihui?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@xieyihui&lt;/span&gt;&lt;/a&gt; because {xaringan}! And to &lt;a href=&#34;https://twitter.com/brshallo?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/KellyBodwin?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@KellyBodwin&lt;/span&gt;&lt;/a&gt; for new ideas about how to share flipbooks, html -&amp;gt; pdf -&amp;gt; gif. Guidance now included in template update on this - this gif created w/ that workflow!üôèü§©
&lt;/p&gt;
‚Äî Gina Reynolds (&lt;span class=&#34;citation&#34;&gt;@EvaMaeRey&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/EvaMaeRey/status/1274837474460626945?ref_src=twsrc%5Etfw&#34;&gt;June 21, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;See my notes and solutions &lt;a href=&#34;https://brshallo.github.io/r4ds_solutions/&#34;&gt;here&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I also considered names such as &lt;code&gt;pexprex&lt;/code&gt;, &lt;code&gt;sexprex&lt;/code&gt;, &lt;code&gt;pripex&lt;/code&gt;, ‚Ä¶ I‚Äôll let the reader guess at the acronyms.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Which I prefer over the alternatives of using the leading &lt;code&gt;*&lt;/code&gt; or wrapping the message in&lt;code&gt;{{}}&lt;/code&gt;.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
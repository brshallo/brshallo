<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Bryan Shalloway&#39;s Blog</title>
    <link>/post/</link>
    <description>Recent content in Posts on Bryan Shalloway&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Influencing Distributions with Discrete Incentives</title>
      <link>/2020/11/02/influencing-distributions/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/11/02/influencing-distributions/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simple-example&#34;&gt;Simple Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#applying-incentives&#34;&gt;Applying Incentives&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#takeaways-of-resulting-distribution&#34;&gt;Takeaways of Resulting Distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#think-carefully-about-assumptions&#34;&gt;Think Carefully About Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-set-assumptions&#34;&gt;How to Set Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simple-assumptions&#34;&gt;Simple Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#trade-offs&#34;&gt;Trade-offs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;In this post I will use incentives for sales representatives in pricing to provide examples of factors to consider when attempting to influence an existing distribution.&lt;/p&gt;
&lt;p&gt;For instance, if you have a lever that pushes prices from low to high, using the lever to influence the prices adjacent to the right of the largest parts of the distribution will (likely, though contingent on a variety of factors) make the biggest impact on raising the average price attained. If the starting distribution is normal, this means incentives applied near the lower prices (the tail of the distribution) may have the smallest impact.&lt;/p&gt;
&lt;p&gt;All figures in this post are created using the R programming language (see &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-11-02-influencing-distributions.Rmd&#34;&gt;Rmarkdown document&lt;/a&gt; on github for code).&lt;/p&gt;
&lt;div id=&#34;simple-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple Example&lt;/h1&gt;
&lt;p&gt;Imagine you have a product that can be sold anywhere from $100 to $150. Sales reps want to sell for as high of a price as possible and customers want to purchase for as low of a price as possible. In this tension your product ends-up selling, on average, for $125 and follows a truncated normal distribution with standard deviation of $10&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;applying-incentives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Applying Incentives&lt;/h2&gt;
&lt;p&gt;Executive leadership wants to apply additional incentives on sales reps to keep prices high&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. They task you with setting-up a tiered compensation scheme whereby deals at the top-end of the distribution get a higher compensation rate compared to deals at the bottom end of the distribution.&lt;/p&gt;
&lt;p&gt;Applying such an additional incentive on sales teams has the potential advantage of pushing some proportion of deals to a higher price&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. There are also &lt;a href=&#34;#trade-offs&#34;&gt;Trade-offs&lt;/a&gt; associated with such an initiative (indicated in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;), these will be ignored for the purposes of this exercise.&lt;/p&gt;
&lt;p&gt;Say you decide to set cut-points to split the distribution into quartiles such that sales reps get larger bonuses if their deals fall into higher quartiles.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Applying incentives is likely to lead to a different distribution for future deals.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Consider what the relevant factors and assumptions are in influencing the existing distribution. &lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Take a moment to hypotheisze what the new distribution will look like after incentives are applied&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After applying incentives the resulting distribution is likely to depend on:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The starting distribution&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; of deals.&lt;/li&gt;
&lt;li&gt;What the incentives are and &lt;em&gt;how&lt;/em&gt; they influence the initial distribution.&lt;/li&gt;
&lt;li&gt;How this influence degrades the farther away the starting position of a deal is from the next tier up in incentives.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You could paramaterize this problem and model the expected distribution. Making some &lt;a href=&#34;#simple-assumptions&#34;&gt;Simple Assumptions&lt;/a&gt; (described in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;), the chart below shows a (potential) resulting distribution after applying the incentives.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gray bars in the chart below indicate where (on the original distribution) movement to a higher tier will occur.
&lt;img src=&#34;/post/2020-11-02-influencing-distributions_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;takeaways-of-resulting-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Takeaways of Resulting Distribution&lt;/h3&gt;
&lt;p&gt;The greatest proportion of deals were moved from orange to yellow and from yellow to blue. Pink to orange had the least amount of movement (due to the first quartile being spread across a wider range).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;incentive&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;density_converted&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;pink to orange&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.068&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;orange to yellow&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.099&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;yellow to blue&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.095&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;stayed blue&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Incentives Make the Biggest Difference When Nearer to the Largest Parts of the Distribution Suseptible to Change&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because these incentives slide deals from lower prices to higher prices, those cut-points that are &lt;em&gt;just above&lt;/em&gt; the most dense parts of the distribution have the biggest impacts on the post-incentivized distribution. For a normal distribution, such as this one, that means incentives just to the right of the first quartile have the smallest impact. (Importantly, this assumes suseptibility to rightward mobility is evenly distributed across the starting distribution.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How Many Thresholds&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For many reasonable assumptions&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;, having more thresholds will lead to greater movement upwards in the distribution. Similarly, a continuous application of incentives (i.e. sales reps get higher compensation for every point they move up on the distribution) can be optimal under certain assumptions as well&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quartiles change&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After applying the incentives, the cut-points for segmenting the distribution into quartiles on future deals will be different. Given your assumptions, you could try forecasting where the new quartiles will exist (after applying the incentives) and adjust the bonus thresholds proactively.&lt;/p&gt;
&lt;p&gt;Thresholds for incentives could also be adjusted dynamically. For example based on a rolling average of the quartiles of recent deals. In this approach, you apply initial incentives and then allow them to change dynamically depending on the resulting distribution of deals – setting guard rails where appropriate. An advantage to this dynamic approach is that the compensation rates gets set based on behavior&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; – which is helpful in cases where you may not trust your ability to set appropriate thresholds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;think-carefully-about-assumptions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Think Carefully About Assumptions&lt;/h3&gt;
&lt;p&gt;Simulating the expected outcome based on assumptions such as the ones described in this post are helpful in thoughtfully elucidating the problem for yourself or for others. Assumptions do not need to be &lt;em&gt;perfect&lt;/em&gt; to be useful for thinking through the problem but they should lean towards the &lt;em&gt;actual&lt;/em&gt; patterns in your example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do Incentives Aggregate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this case, we are assuming incentives aggregate in a linear way. This means that five 1 ppt incentives have the same amount of influence as one 5 ppt incentive. It could be that the former is more influential (people prefer many small bonuses) or the latter is more influential (people prefer one large bonuses)&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It could also be that there is a ‘correct’ size of incentive and that too small an incentive makes no difference but a large incentive has diminishing returns. If this is the case a logistic function or other ‘S’ shaped function may be more reasonable for modeling the influence of incentives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does Influence Degrade With Distance From Incentives?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In this case, we are assuming the influence of an incentive exponential decays (the influence decreases by 25% for every point we move from the cut-point). Hence being only a few points away from a cut-point has a big impact, but the degradation is less with each point we move away.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How is Slack Distributed&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I assumed slack (i.e. the possibility of deals being influenced by incentives) was equally distributed. (It could be that slack is distributed disproportionally towards the lower ends of the distribution for example.)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-set-assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to Set Assumptions&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Start with what makes sense (e.g. normal distributions are often good starting places)&lt;/li&gt;
&lt;li&gt;Review historical data&lt;/li&gt;
&lt;li&gt;Set-up formal tests (e.g. create hypotheses and see how behavior adjusts as you change incentives on random subsets of your sales representatives)&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;simple-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple Assumptions&lt;/h2&gt;
&lt;p&gt;For this example, we will say the incentives you established are higher compensation rates depending on which quartile the deal falls in. If the deal falls in the lowest quartile they get no increase, in the 2nd quartile they get a 5 percentage point (ppt) increase in pay, the 3rd a 10 ppt increase, the 4th a 15 ppt increase&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For now I’ll pick some overly simple but sensible values for each question:&lt;/em&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;As indicated, we are assuming the ‘natural’ distribution of prices is roughly normal&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We will assume that for every 1 ppt change in incentive that 15% of the deals immediately to the right of the cut-off will be moved up to the cut-off value.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We will assume that this influence degrades by 25% for every dollar you move from the cut-point&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;. I am ignoring the possibility of deals jumping more than on level (e.g. deals moving from the 1st quartile to the 3rd quartile)&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;trade-offs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Trade-offs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A sales rep may have been able to sell more product at a lower price.
&lt;ul&gt;
&lt;li&gt;The additional incentive causes some deals (those selling for lower prices) to be passed on because the incentive to close on the deal for reps has been lowered (this may be intentional in that the impact on price erosion of these deals is worth the decrease in sales…).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;You may have to pay your sales reps more&lt;/li&gt;
&lt;li&gt;Applying such incentives may create additional bureaucratic hurdles in closing deals that increase the friction of closing deals, causing some percentage of deals to be lost
&lt;ul&gt;
&lt;li&gt;It could be that deals don’t have slack in them and are already optimal…&lt;/li&gt;
&lt;li&gt;Any change in pricing behavior has the risk of upsetting customers or having downstream affects.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Ideally&lt;/em&gt; the organization is able to take into account risks and advantages in pricing and set-up incentives that are focused on overall profitability and firm growth (not &lt;em&gt;just&lt;/em&gt; in terms of a single factor).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Limits for Y axis appear too large for this chart but are set from 0 to 0.15 so as to be consistent with similar figures later in post.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;E.g. to prevent brand erosion, improve margins, etc.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;This assumes that there is some slack in the existing deals and that representatives are in a position to impact this and will do so if provided higher incentives.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;or potentially a ‘natural’ distribution that would exist in the absence of incentives&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Key to this assumption is how incentives degrade as you move farther from a cut-point.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;These do not consider potential psychological impacts or difficulty of implementation.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Similar to in a market.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Research into psychological biases suggests the former may be true.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;You could also construct this such that lower quartiles have negative incentives and higher quartiles have positive incentives.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;The functions governing these behaviors are almost certainly more sophisticated.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Factoring this possibility in would likely lead to incentives at the higher quartiles making a slightly larger impact.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Gambling Where the House Almost Always Loses... but Still Wins</title>
      <link>/2020/10/28/idea-for-casino-games-where-the-player-almost-always-win/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/10/28/idea-for-casino-games-where-the-player-almost-always-win/</guid>
      <description>


&lt;p&gt;&lt;em&gt;In this post, I will describe an example of a game that produces many small wins for the player and occasional large wins for the house. Such a game (theoretically) takes advantage of psychological biases of individuals to prefer gains to be disaggregated and losses to be aggregated as well as a general disposition for accepting small sure-things when it comes to gains and a willingness to chance higher-risk scenarios in order to avoid paying losses.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;All ideas described in this post are theoretical and would need to be tested in a gambling / gaming environment. The ideas described are very much in a draft form&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On Wednesday’s I co-lead an internal study group on Pricing Strategy. We just finished week four of &lt;a href=&#34;https://www.coursera.org/learn/uva-darden-bcg-pricing-strategy-customer-value/home/week/4&#34;&gt;Customer Value in Pricing Strategy&lt;/a&gt;. The material in this section is devoted almost entirely to the various conditions under which people behave ‘irrationally’&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; and how / when a firm can manipulate the psychology of customers to demand a higher price for their products. The subject matter is rife with ethical dilemmas; setting these aside, the material sparked an idea for a new spin on games and gambling.&lt;/p&gt;
&lt;p&gt;There are a few psychological phenomena from the course that are important primers.&lt;/p&gt;
&lt;p&gt;I. People tend to be &lt;em&gt;risk seeking&lt;/em&gt; when facing &lt;strong&gt;losses&lt;/strong&gt; but &lt;em&gt;risk averse&lt;/em&gt; when facing &lt;strong&gt;gains&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;An example in the course is that, faced with the scenario below, people will tend to go for the sure thing and win $50 rather than the chance at gaining $100 (even though each option has the same expected value).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-29-idea-for-casino-games-where-the-player-almost-always-win_files/gain-example.PNG&#34; /&gt;
&lt;em&gt;(all images in this post are screenshotted from the &lt;a href=&#34;https://www.coursera.org/learn/uva-darden-bcg-pricing-strategy-customer-value/home/week/4&#34;&gt;coursera materials&lt;/a&gt; created by the University of Virginia and Boston Consulting Group)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;However when facing potential losses, people prefer taking their chances and will tend to select the option with the risk of a greater loss (for the possibility of avoiding the loss entirely). They will choose a 50% chance of losing $100 (to avoid a guaranteed loss of $50).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-29-idea-for-casino-games-where-the-player-almost-always-win_files/loss-example.PNG&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: upper-roman&#34;&gt;
&lt;li&gt;People tend to prefer &lt;em&gt;disaggregated&lt;/em&gt; &lt;strong&gt;gains&lt;/strong&gt; but &lt;em&gt;aggregated&lt;/em&gt; &lt;strong&gt;losses&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;People prefer multiple small good events over a single (larger) good event (even if the total value is equal). For example, people will prefer winning two low value scratch cards over winning a single higher value scratch card:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-29-idea-for-casino-games-where-the-player-almost-always-win_files/aggregated-gains.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;However people prefer taking losses in aggregated forms. As described in the course, they usually prefer receiving one large bill over multiple smaller bills:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-29-idea-for-casino-games-where-the-player-almost-always-win_files/aggregated-loss.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Even though, as with the previous examples, the value of the events are equal&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;implications-for-gambling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Implications for Gambling&lt;/h1&gt;
&lt;p&gt;Many lotteries, slots, and other forms of gambling run counter to these particular psychological phenomena&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. They offer repeated guaranteed initial losses (the quarter you put into the machine, the scratch ticket you buy from the counter, etc.) for the chance at a large payoff (winning the jackpot).&lt;/p&gt;
&lt;p&gt;I thought an interesting set-up for a game would be one that flipped this and made the player very likely to win a small amount each time they played but that always carried the risk of a single large loss&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As an example, imagine a roulette-like wheel numbered from 1 to 10. You are instructed to pick a number. As long as you &lt;em&gt;don’t&lt;/em&gt; land on that number you will win $5. If you &lt;em&gt;do&lt;/em&gt; land on it you will lose $50 (or something along those lines for whatever size of bet&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;). This particular bet would yield the casino an expected value of 50 cents&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. It also yields the player the excitement of an expected nine wins in a row&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;. The advert for the game might focus on the idea of “Tempting Fate&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;.”&lt;/p&gt;
&lt;p&gt;You could blend these ideas with other common gaming features. For example, you might have a mix of ‘big losses’ and ‘big wins’. Carrying on from the previous example, the wheel (numbered 1:10) could be set-up where the player selects a number for a ‘big win’ ($50 gain), and two ‘big losers’ ($50 loss for either), and the rest resulting in small wins ($5). The expected value for the casino on this set-up is now $1.50&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are a variety of forms this game could be tested in – it doesn’t have to be a roulette-like wheel in a casino (I actually think an app or more gamefied environment may work better&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;). &lt;em&gt;The novel feature is ensuring players get repeated high-likelihood small wins while having them pay their losses in one-off large losses (rather than small incremental payments).&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;There is a decent chance I misapplied some concepts – particularly regarding the idea of risk seeking when it comes to losses (e.g. if it’s more about seeking uncertainty vs seeking riskiness…). What I describe also seems to run counter to the idea that sporadic positive events help drive repeat behaviors whereas sporadic negative shocks drive avoidance of the activity. Generally I would need to think about and read a little more…&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I am also in the middle of reading Khaneman’s highly related seminal book “Thinking Fast and Slow”.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Ignore the particularities in the examples and focus on what they are designed to illustrate…&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;However they play at others. Casinos are master psychological manipulators. I imagine they have thoroughly tested the ideas discussed in this post.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Picture a group of friends playing credit card roulette at the end of the night.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;one can of course edit the odds to set things appropriately&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;I imagine casinos have considered setting games like this up and that there are good reasons they don’t exist. For example, players have to put up a lot of money to win anything, so the dollars that go to the house per dollar bet is going to be much lower than other games that they could fill their floor space with.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;See &lt;a href=&#34;https://math.stackexchange.com/questions/1119872/on-average-how-many-times-must-i-roll-a-dice-until-i-get-a-6#:~:text=About%2014%20times%20it%20will,100%20and%20get%20%E2%89%886.&#34;&gt;thread&lt;/a&gt; for explanation.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;Many casino games could be redesigned in this manner – where you are likely to win but always face the risk of a large loss. You might picture a room in the casino that had an ‘Upside Down’ style feel where all the slots and similar games there were reconstructed accordingly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.thesun.co.uk/wp-content/uploads/2017/11/tmp_6e95hn_8581834aa802f9b6_wv_publicity_post_launch_still_10-0000011.jpg&#34; /&gt;&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;It also could make sense to have bets be placed &lt;em&gt;across&lt;/em&gt; the number – this resemble a ‘place bet’ being made across multiple numbers in craps (where the player is crossing their fingers hoping against a seven being rolled).&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;As an example imagine a facsimile of a game where you search fantastical caves for treasure – you usually find small bits, but occasionally stumble upon a pack of dwarves that rob you. If the game points are translatable into money this represents the same thing. An app environment also helps to divorce the user from the sting of the extreme losses (that come from the design of this type of game).&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Should You Use an Assignment as Part of Your Hiring Process for a Data Scientist?</title>
      <link>/2020/10/27/should-you-use-an-assignment-or-exercise-as-part-of-your-hiring-process-for-a-data-scientist/</link>
      <pubDate>Tue, 27 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/10/27/should-you-use-an-assignment-or-exercise-as-part-of-your-hiring-process-for-a-data-scientist/</guid>
      <description>


&lt;p&gt;A version of this question was asked on my alumni Slack channel. There were some excellent points brought up by those answering the question in the negative, including that…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the practice is exploitative (or at least inconsiderate) of the interviewee’s time.&lt;/li&gt;
&lt;li&gt;it is not useful for the interviewing team (as the questions / scenarios are often so contrived as to be useless towards evaluating candidates’ future job performance)&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;doing so will turn-off candidates or many of them will simply not complete the activity. Hence the damage done to your applicant pool will be greater than the value you gain from additional information on your existing applicants&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think each of these points is in some cases true. However I answered the question in the positive. I pasted my answer below (making minor edits for clarity) &lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;blockquote&gt;
&lt;p&gt;I’m in favor of using an activity as part of the hiring process for data scientists (at least in part). Though I believe they should be used more for evaluating the hard skills (compared to others who preferred using them for evaluating soft skills) and more as a pass / fail exercise.&lt;/p&gt;
&lt;p&gt;I think they are best given as an intermediate step in the application process (e.g. after an initial interview or phone screen). They can serve as a useful filter of if the applicant has some baseline technical competencies / skills you view as prerequisites for the role.&lt;/p&gt;
&lt;p&gt;I agree with others regarding the importance of being straight forward regarding what candidates will be expected to do in the activity ahead of time. We send an email beforehand that spells out &lt;em&gt;explicitly&lt;/em&gt; what they will be asked to do several days before the activity (e.g. “You will be asked to use a statistical test to measure the relationship between two variables,” “You will be asked to join data between tables,” etc)&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;In contrast to those who were opposed to the idea of giving a limited time to complete the activity, I actually think setting rigid time constraints is helpful for several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It prevents the “who has more free time” problem from influencing results.&lt;/li&gt;
&lt;li&gt;It also prevents candidates from spending a bunch of time on the task unnecessarily.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We evaluate the task more from the lens of being primarily a pass / fail activity (so just being fast and over achieving on the the activity doesn’t get a ton of extra credit). We let the candidates pick their date / time to receive the assignment and then expect them to complete (and submit their work) within the time frame.&lt;/p&gt;
&lt;p&gt;We’ve shortened the number of questions we ask. Making it as short as possible is considerate to the applicant&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;. As an example, we may give three hours with the hope that a skilled (highly focused) candidate could complete it in 1 - 1.5 hours. We do not pay candidates for their time completing the exercise. We do provide feedback on the activity (usually either as part of the interview process or immediately afterwards – including to applicants that ‘fail’ the activity).&lt;/p&gt;
&lt;p&gt;We have (often) used presentations as part of the interview process as well (which are typically extensions upon the technical activity). I’m more ambivalent on the usefulness of these in terms of how clearly they differentiate candidates. Preparing for a presentation also means asking the candidates to invest substantially more time.&lt;/p&gt;
&lt;p&gt;Hiring is a highly noisy activity&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; with lots of risks for substitution errors and other biases. You’re probably not going to know who the “ideal candidate” is (even if you convince yourself that you do). What you (hopefully) can do is set some broadly useful (and ethical) filters that give you a good pool to select from&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. For this I think a (relatively) short, well constructed technical activity can be helpful. However, for any individual position you also have to hope you get lucky…&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;p&gt;Another approach brought up was the idea of doing an assignment onsite. I’m also in favor of these. They make controlling for additional factors easier. With onsite evaluations (of any kind) the balance is between on the one hand not wanting to rush the applicant (as you don’t want to measure &lt;em&gt;just&lt;/em&gt; speed or penalize them for not remembering everything on the fly) and on the other hand wanting to make for a fair evaluation space (i.e. everyone gets the same time and types of questions). I think there are good ways of doing this. I still think doing a technical assignment ahead of time can make sense (if they don’t pass this, no point in forcing both parties to spend a full day onsite unnecessarily).&lt;/p&gt;
&lt;p&gt;The idea I would push back against the most is that a technical assessment (of at least some form) is not necessary and the notion that “if you’re smart, you can learn the skills.” This is true in the specific sense, but it also begs the question, “Why didn’t you learn at least some of this already?” Unless your organization has really strong onboarding &lt;em&gt;designed&lt;/em&gt; to bring people up to speed from near zero, you probably want people coming in with some baseline or to have demonstrated their interest by learning some things already. I’ve expressed this sentiment previously:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
…(even in high-level languages like &lt;a href=&#34;https://twitter.com/hashtag/python?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#python&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt;). Data science, etc require skill and sweat to be effective. This idea that you should just try to hire the “smartest” person possible for any role and hope they turn into a unicorn is a destructive myth that needs to end. …
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1197234570011299843?ref_src=twsrc%5Etfw&#34;&gt;November 20, 2019&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;div id=&#34;twitter-survey&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Twitter Survey&lt;/h2&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
(+ &lt;a href=&#34;https://twitter.com/hashtag/python?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#python&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/julia?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#julia&lt;/a&gt; and others)
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1321166916304670720?ref_src=twsrc%5Etfw&#34;&gt;October 27, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;This applies to almost every part of an application process; it’s about where you can gather small pieces of useful information at minimal time / expense.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;However, candidates who remain (and invest their time completing the exercise) may be more likely to accept an offer (falling to some extent for the sunk cost fallacy). Though this reasoning is dubious ethically and should be avoided in decision making.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Note that while I have participated in the hiring of a few data science roles I am by no means &lt;em&gt;seasoned&lt;/em&gt; in hiring data scientists.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;RTI has some good examples of data science activities on their github: &lt;a href=&#34;https://github.com/rtidatascience/data-scientist-exercise01&#34;&gt;RTI exercise 1&lt;/a&gt;, &lt;a href=&#34;https://github.com/rtidatascience/data-scientist-exercise02&#34;&gt;RTI exercise 2&lt;/a&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;and, depending on the questions, may save the team time in evaluation&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;particularly in a ‘hot’ field like data science where a lot of people are transitioning into it&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;and that provides some latitude for constructing a diverse team that fits well together&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Feature Engineering with Sliding Windows and Lagged Inputs</title>
      <link>/2020/10/12/window-functions-for-resampling/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/10/12/window-functions-for-resampling/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#load-data&#34;&gt;Load data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering-data-splits&#34;&gt;Feature Engineering &amp;amp; Data Splits&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lag-based-features-before-split-use-dplyr-or-similar&#34;&gt;Lag Based Features (Before Split, use &lt;code&gt;dplyr&lt;/code&gt; or similar)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-splits&#34;&gt;Data Splits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-features-after-split-use-recipes&#34;&gt;Other Features (After Split, use &lt;code&gt;recipes&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-specification-and-training&#34;&gt;Model Specification and Training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-evaluation&#34;&gt;Model Evaluation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#model-building-with-hyperparameter-tuning&#34;&gt;Model Building with Hyperparameter Tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;The new &lt;code&gt;rsample::sliding_*()&lt;/code&gt; functions bring the windowing approaches used in &lt;a href=&#34;https://github.com/DavisVaughan/slider&#34;&gt;slider&lt;/a&gt; to the sampling procedures used in the &lt;a href=&#34;https://github.com/tidymodels&#34;&gt;tidymodels&lt;/a&gt; framework&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. These functions make evaluation of models with time-dependent variables easier&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For some problems you may want to take a traditional regression or classification based approach&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; while still accounting for the date/time-sensitive components of your data. In this post I will use the &lt;code&gt;tidymodels&lt;/code&gt; suite of packages to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build lag based and non-lag based features&lt;/li&gt;
&lt;li&gt;set-up appropriate time series cross-validation windows&lt;/li&gt;
&lt;li&gt;evaluate performance of linear regression and random forest models on a regression problem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For my example I will use data from Wake County food inspections. I will try to predict the &lt;code&gt;SCORE&lt;/code&gt; for upcoming restaurant food inspections.&lt;/p&gt;
&lt;div id=&#34;load-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Load data&lt;/h1&gt;
&lt;p&gt;You can use Wake County’s open API (does not require a login/account) and the &lt;a href=&#34;https://github.com/r-lib/httr&#34;&gt;httr&lt;/a&gt; and &lt;a href=&#34;https://github.com/jeroen/jsonlite&#34;&gt;jsonlite&lt;/a&gt; packages to load in the data. You can also download the data directly from the Wake County &lt;a href=&#34;https://data.wakegov.com/datasets/1b08c4eb32f44a198277c418b71b3a48_2&#34;&gt;website&lt;/a&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
library(httr)
library(jsonlite)
library(tidymodels)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Get food inspections data:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_insp &amp;lt;- GET(&amp;quot;https://opendata.arcgis.com/datasets/ebe3ae7f76954fad81411612d7c4fb17_1.geojson&amp;quot;)

inspections &amp;lt;- content(r_insp, &amp;quot;text&amp;quot;) %&amp;gt;% 
  fromJSON() %&amp;gt;% 
  .$features %&amp;gt;%
  .$properties %&amp;gt;% 
  as_tibble()

inspections_clean &amp;lt;- inspections %&amp;gt;% 
  mutate(date = ymd_hms(DATE_) %&amp;gt;% as.Date()) %&amp;gt;% 
  select(-c(DATE_, DESCRIPTION, OBJECTID))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Get food locations data:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r_rest &amp;lt;- GET(&amp;quot;https://opendata.arcgis.com/datasets/124c2187da8c41c59bde04fa67eb2872_0.geojson&amp;quot;) #json

restauraunts &amp;lt;- content(r_rest, &amp;quot;text&amp;quot;) %&amp;gt;% 
  fromJSON() %&amp;gt;% 
  .$features %&amp;gt;%
  .$properties %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  select(-OBJECTID)

restauraunts &amp;lt;- restauraunts %&amp;gt;% 
  mutate(RESTAURANTOPENDATE = ymd_hms(RESTAURANTOPENDATE) %&amp;gt;% as.Date())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Further prep:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Join the &lt;code&gt;inspections&lt;/code&gt; and &lt;code&gt;restaurants&lt;/code&gt; datasets&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Filter out extreme outliers in &lt;code&gt;SCORE&lt;/code&gt; (likely data entry errors)&lt;/li&gt;
&lt;li&gt;Filter to only locations of &lt;code&gt;TYPE&lt;/code&gt; restaurant&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Filter out potential duplicate entries&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;It’s important to consider which fields should be excluded for ethical reasons. For our problem, we will say that any restaurant name or location information must be excluded&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspections_restaurants &amp;lt;- inspections_clean %&amp;gt;% 
  left_join(restauraunts, by = c(&amp;quot;HSISID&amp;quot;, &amp;quot;PERMITID&amp;quot;)) %&amp;gt;% 
  filter(SCORE &amp;gt; 50, FACILITYTYPE == &amp;quot;Restaurant&amp;quot;) %&amp;gt;% 
  distinct(HSISID, date, .keep_all = TRUE) %&amp;gt;% 
  select(-c(FACILITYTYPE, PERMITID)) %&amp;gt;% 
  select(-c(NAME, contains(&amp;quot;ADDRESS&amp;quot;), CITY, STATE, POSTALCODE, PHONENUMBER, X, Y, GEOCODESTATUS))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspections_restaurants %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 24,294
## Columns: 6
## $ HSISID             &amp;lt;chr&amp;gt; &amp;quot;04092017542&amp;quot;, &amp;quot;04092017542&amp;quot;, &amp;quot;04092017542&amp;quot;, &amp;quot;04...
## $ SCORE              &amp;lt;dbl&amp;gt; 94.5, 92.0, 95.0, 93.5, 93.0, 93.5, 92.5, 94.0, ...
## $ TYPE               &amp;lt;chr&amp;gt; &amp;quot;Inspection&amp;quot;, &amp;quot;Inspection&amp;quot;, &amp;quot;Inspection&amp;quot;, &amp;quot;Inspe...
## $ INSPECTOR          &amp;lt;chr&amp;gt; &amp;quot;Anne-Kathrin Bartoli&amp;quot;, &amp;quot;Laura McNeill&amp;quot;, &amp;quot;Laura ...
## $ date               &amp;lt;date&amp;gt; 2017-04-07, 2017-11-08, 2018-03-23, 2018-09-07,...
## $ RESTAURANTOPENDATE &amp;lt;date&amp;gt; 2017-03-01, 2017-03-01, 2017-03-01, 2017-03-01,...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;feature-engineering-data-splits&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Feature Engineering &amp;amp; Data Splits&lt;/h1&gt;
&lt;p&gt;Discussion on issue &lt;a href=&#34;https://github.com/tidymodels/rsample/pull/168&#34;&gt;#168&lt;/a&gt; suggests that some features (those depending on prior observations) should be created before the data is split&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. The first and last sub-sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#lag-based-features-before-split-use-dplyr-or-similar&#34;&gt;Lag Based Features (Before Split, use &lt;code&gt;dplyr&lt;/code&gt; or similar)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-features-after-split-use-recipes&#34;&gt;Other Features (After Split, use &lt;code&gt;recipes&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;provide examples of the types of features that should be created before and after splitting your data respectively. Lag based features can, in some ways, be thought of as ‘raw inputs’ as they should be created prior to building a &lt;code&gt;recipe&lt;/code&gt;&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;lag-based-features-before-split-use-dplyr-or-similar&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lag Based Features (Before Split, use &lt;code&gt;dplyr&lt;/code&gt; or similar)&lt;/h2&gt;
&lt;p&gt;Lag based features should generally be computed prior to splitting your data into “training” / “testing” (or “analysis” / “assessment”&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;) sets. This is because calculation of these features may depend on observations in prior splits&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;. Let’s build a few features where this is the case:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prior &lt;code&gt;SCORE&lt;/code&gt; for &lt;code&gt;HSISID&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Average of prior 3 years of &lt;code&gt;SCORE&lt;/code&gt; for &lt;code&gt;HSISISD&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overall recent (year) prior average &lt;code&gt;SCORE&lt;/code&gt; (across &lt;code&gt;HSISISD&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Days since &lt;code&gt;RESTAURANTOPENDATE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Days since last inspection &lt;code&gt;date&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_time_feats &amp;lt;- inspections_restaurants %&amp;gt;% 
  arrange(date) %&amp;gt;% 
  mutate(SCORE_yr_overall = slider::slide_index_dbl(SCORE, 
                                                    .i = date, 
                                                    .f = mean, 
                                                    na.rm = TRUE, 
                                                    .before = lubridate::days(365), 
                                                    .after = -lubridate::days(1))
         ) %&amp;gt;% 
  group_by(HSISID) %&amp;gt;% 
  mutate(SCORE_lag = lag(SCORE),
         SCORE_recent = slider::slide_index_dbl(SCORE, 
                                                date, 
                                                mean, 
                                                na.rm = TRUE, 
                                                .before = lubridate::days(365*3), 
                                                .after = -lubridate::days(1), 
                                                .complete = FALSE),
         days_since_open = (date - RESTAURANTOPENDATE) / ddays(1),
         days_since_last = (date - lag(date)) / ddays(1)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  arrange(date)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The use of &lt;code&gt;.after = -lubridate::days(1)&lt;/code&gt; prevents data leakage by ensuring that this feature does not include information from the current day in its calculation&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-splits&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Splits&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Additional Filtering:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We will presume that the model is only intended for restaurants that have previous inspections on record&lt;a href=&#34;#fn15&#34; class=&#34;footnote-ref&#34; id=&#34;fnref15&#34;&gt;&lt;sup&gt;15&lt;/sup&gt;&lt;/a&gt; and will use only the most recent seven years of data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_time_feats &amp;lt;- data_time_feats %&amp;gt;% 
  filter(date &amp;gt;= (max(date) - years(7)), !is.na(SCORE_lag))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Initial Split:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After creating our lag based features, we can split our data into training and testing splits.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;initial_split &amp;lt;- rsample::initial_time_split(data_time_feats, prop = .8)
train &amp;lt;- rsample::training(initial_split)
test &amp;lt;- rsample::testing(initial_split)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Resampling (Time Series Cross-Validation):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For this problem we should evaluate our models using time series cross-validation&lt;a href=&#34;#fn16&#34; class=&#34;footnote-ref&#34; id=&#34;fnref16&#34;&gt;&lt;sup&gt;16&lt;/sup&gt;&lt;/a&gt;. This entails creating multiple ordered subsets of the training data where each set has a different assignment of observations into “analysis” or “assessment” data&lt;a href=&#34;#fn17&#34; class=&#34;footnote-ref&#34; id=&#34;fnref17&#34;&gt;&lt;sup&gt;17&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ideally the resampling scheme used for model evaluation mirrors how the model will be built and evaluated in production. For example, if the production model will be updated once every three months it makes sense that the “assessment” sets be this length. We can use &lt;code&gt;rsample::sliding_period()&lt;/code&gt; to set things up.&lt;/p&gt;
&lt;p&gt;For each set, we will use three years of “analysis” data for training a model and then three months of “assessment” data for evaluation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;resamples &amp;lt;- rsample::sliding_period(train, 
                                     index = date, 
                                     period = &amp;quot;month&amp;quot;, 
                                     lookback = 36, 
                                     assess_stop = 3, 
                                     step = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I will load in some helper functions I created for reviewing the dates of our resampling windows&lt;a href=&#34;#fn18&#34; class=&#34;footnote-ref&#34; id=&#34;fnref18&#34;&gt;&lt;sup&gt;18&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(&amp;quot;https://gist.github.com/brshallo/7d180bde932628a151a4d935ffa586a5&amp;quot;)

resamples  %&amp;gt;% 
  extract_dates_rset() %&amp;gt;% 
  print() %&amp;gt;% 
  plot_dates_rset() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 6
##    splits         id     analysis_min analysis_max assessment_min assessment_max
##    &amp;lt;list&amp;gt;         &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;       &amp;lt;date&amp;gt;       &amp;lt;date&amp;gt;         &amp;lt;date&amp;gt;        
##  1 &amp;lt;split [6.2K/~ Slice~ 2013-10-09   2016-10-31   2016-11-01     2017-01-31    
##  2 &amp;lt;split [6.3K/~ Slice~ 2014-01-02   2017-01-31   2017-02-01     2017-04-28    
##  3 &amp;lt;split [6.6K/~ Slice~ 2014-04-01   2017-04-28   2017-05-01     2017-07-31    
##  4 &amp;lt;split [7.1K/~ Slice~ 2014-07-01   2017-07-31   2017-08-01     2017-10-31    
##  5 &amp;lt;split [7.5K/~ Slice~ 2014-10-01   2017-10-31   2017-11-01     2018-01-31    
##  6 &amp;lt;split [7.9K/~ Slice~ 2015-01-02   2018-01-31   2018-02-01     2018-04-30    
##  7 &amp;lt;split [8.3K/~ Slice~ 2015-04-01   2018-04-30   2018-05-01     2018-07-31    
##  8 &amp;lt;split [8.6K/~ Slice~ 2015-07-01   2018-07-31   2018-08-01     2018-10-31    
##  9 &amp;lt;split [9K/1K~ Slice~ 2015-10-01   2018-10-31   2018-11-01     2019-01-31    
## 10 &amp;lt;split [9.5K/~ Slice~ 2016-01-04   2019-01-31   2019-02-01     2019-04-30    
## 11 &amp;lt;split [9.9K/~ Slice~ 2016-04-01   2019-04-30   2019-05-01     2019-07-31    
## 12 &amp;lt;split [10.4K~ Slice~ 2016-07-01   2019-07-31   2019-08-01     2019-10-31&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-12-window-functions-for-resampling_files/figure-html/check-resampling-splits-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For purposes of overall &lt;a href=&#34;#model-evaluation&#34;&gt;Model Evaluation&lt;/a&gt;, performance across each period will be weighted equally (regardless of number of observations in a period)&lt;a href=&#34;#fn19&#34; class=&#34;footnote-ref&#34; id=&#34;fnref19&#34;&gt;&lt;sup&gt;19&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn20&#34; class=&#34;footnote-ref&#34; id=&#34;fnref20&#34;&gt;&lt;sup&gt;20&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-features-after-split-use-recipes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other Features (After Split, use &lt;code&gt;recipes&lt;/code&gt;)&lt;/h2&gt;
&lt;p&gt;Where possible, features should be created using the &lt;a href=&#34;https://github.com/tidymodels/recipes&#34;&gt;recipes&lt;/a&gt; package&lt;a href=&#34;#fn21&#34; class=&#34;footnote-ref&#34; id=&#34;fnref21&#34;&gt;&lt;sup&gt;21&lt;/sup&gt;&lt;/a&gt;. &lt;code&gt;recipes&lt;/code&gt; makes pre-processing convenient and helps prevent data leakage.&lt;/p&gt;
&lt;p&gt;It is OK to modify or transform a previously created lag based feature in a &lt;code&gt;recipes&lt;/code&gt; step. Assuming that you created the lag based input as well as your resampling windows in an appropriate manner, you should be safe from data leakage issues when modifying the variables during later feature engineering steps&lt;a href=&#34;#fn22&#34; class=&#34;footnote-ref&#34; id=&#34;fnref22&#34;&gt;&lt;sup&gt;22&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Some features / transformations I’ll make with &lt;code&gt;recipes&lt;/code&gt;:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;collapse rare values for &lt;code&gt;INSPECTOR&lt;/code&gt; and &lt;code&gt;TYPE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;log transform &lt;code&gt;days_since_open&lt;/code&gt; and &lt;code&gt;days_since_last&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;add calendar based features&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rec_general &amp;lt;- recipes::recipe(SCORE ~ ., data = train) %&amp;gt;% 
  step_rm(RESTAURANTOPENDATE) %&amp;gt;% 
  update_role(HSISID, new_role = &amp;quot;ID&amp;quot;) %&amp;gt;% 
  step_other(INSPECTOR, TYPE, threshold = 50) %&amp;gt;% 
  step_string2factor(one_of(&amp;quot;TYPE&amp;quot;, &amp;quot;INSPECTOR&amp;quot;)) %&amp;gt;%
  step_novel(one_of(&amp;quot;TYPE&amp;quot;, &amp;quot;INSPECTOR&amp;quot;)) %&amp;gt;%
  step_log(days_since_open, days_since_last) %&amp;gt;% 
  step_date(date, features = c(&amp;quot;dow&amp;quot;, &amp;quot;month&amp;quot;)) %&amp;gt;% 
  update_role(date, new_role = &amp;quot;ID&amp;quot;) %&amp;gt;% 
  step_zv(all_predictors()) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s peak at the features we will be passing into the model building step:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prep(rec_general, data = train) %&amp;gt;% 
  juice() %&amp;gt;% 
  glimpse() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 17,048
## Columns: 12
## $ HSISID           &amp;lt;fct&amp;gt; 04092016152, 04092014520, 04092014483, 04092012102...
## $ TYPE             &amp;lt;fct&amp;gt; Inspection, Inspection, Inspection, Inspection, In...
## $ INSPECTOR        &amp;lt;fct&amp;gt; David Adcock, Naterra McQueen, Andrea Anover, othe...
## $ date             &amp;lt;date&amp;gt; 2013-10-09, 2013-10-09, 2013-10-09, 2013-10-09, 2...
## $ SCORE_yr_overall &amp;lt;dbl&amp;gt; 96.22766, 96.22766, 96.22766, 96.22766, 96.22766, ...
## $ SCORE_lag        &amp;lt;dbl&amp;gt; 96.0, 95.5, 97.0, 94.5, 97.5, 99.0, 96.0, 96.0, 10...
## $ SCORE_recent     &amp;lt;dbl&amp;gt; 96.75000, 95.75000, 97.50000, 95.25000, 96.75000, ...
## $ days_since_open  &amp;lt;dbl&amp;gt; 6.410175, 7.926964, 7.959276, 8.682029, 8.970432, ...
## $ days_since_last  &amp;lt;dbl&amp;gt; 4.709530, 4.941642, 4.934474, 4.875197, 5.117994, ...
## $ SCORE            &amp;lt;dbl&amp;gt; 98.5, 96.0, 96.0, 93.0, 95.0, 93.5, 95.0, 92.0, 98...
## $ date_dow         &amp;lt;fct&amp;gt; Wed, Wed, Wed, Wed, Wed, Wed, Wed, Wed, Wed, Thu, ...
## $ date_month       &amp;lt;fct&amp;gt; Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, Oct, ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-specification-and-training&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model Specification and Training&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Simple linear regression model:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm_mod &amp;lt;- parsnip::linear_reg() %&amp;gt;% 
  set_engine(&amp;quot;lm&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)

lm_workflow_rs &amp;lt;- workflows::workflow() %&amp;gt;% 
  add_model(lm_mod) %&amp;gt;% 
  add_recipe(rec_general) %&amp;gt;% 
  fit_resamples(resamples,
                control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;ranger&lt;/code&gt; Random Forest model (using defaults):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rand_mod &amp;lt;- parsnip::rand_forest() %&amp;gt;% 
  set_engine(&amp;quot;ranger&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)
  
set.seed(1234)
rf_workflow_rs &amp;lt;- workflow() %&amp;gt;% 
  add_model(rand_mod) %&amp;gt;% 
  add_recipe(rec_general) %&amp;gt;% 
  fit_resamples(resamples,
                control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;parsnip::null_model&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The NULL model will be helpful as a baseline Root Mean Square Error (RMSE) comparison.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;null_mod &amp;lt;- parsnip::null_model(mode = &amp;quot;regression&amp;quot;) %&amp;gt;% 
  set_engine(&amp;quot;parsnip&amp;quot;)

null_workflow_rs &amp;lt;- workflow() %&amp;gt;% 
  add_model(null_mod) %&amp;gt;% 
  add_formula(SCORE ~ NULL) %&amp;gt;%
  fit_resamples(resamples,
                control = control_resamples(save_pred = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See code in &lt;a href=&#34;#model-building-with-hyperparameter-tuning&#34;&gt;Model Building with Hyperparameter Tuning&lt;/a&gt; for more sophisticated examples that include hyperparameter tuning for &lt;code&gt;glmnet&lt;/code&gt;&lt;a href=&#34;#fn23&#34; class=&#34;footnote-ref&#34; id=&#34;fnref23&#34;&gt;&lt;sup&gt;23&lt;/sup&gt;&lt;/a&gt; and &lt;code&gt;ranger&lt;/code&gt; models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-evaluation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model Evaluation&lt;/h1&gt;
&lt;p&gt;The next several code chunks extract the &lt;em&gt;average&lt;/em&gt; performance across “assessment” sets&lt;a href=&#34;#fn24&#34; class=&#34;footnote-ref&#34; id=&#34;fnref24&#34;&gt;&lt;sup&gt;24&lt;/sup&gt;&lt;/a&gt; or extract the performance across each of the individual “assessment” sets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod_types &amp;lt;- list(&amp;quot;lm&amp;quot;, &amp;quot;rf&amp;quot;, &amp;quot;null&amp;quot;)

avg_perf &amp;lt;- map(list(lm_workflow_rs, rf_workflow_rs, null_workflow_rs), 
                collect_metrics) %&amp;gt;% 
  map2(mod_types, ~mutate(.x, source = .y)) %&amp;gt;% 
  bind_rows() &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;extract_splits_metrics &amp;lt;- function(rs_obj, name){
  
  rs_obj %&amp;gt;% 
    select(id, .metrics) %&amp;gt;% 
    unnest(.metrics) %&amp;gt;% 
    mutate(source = name)
}

splits_perf &amp;lt;- map2(list(lm_workflow_rs, rf_workflow_rs, null_workflow_rs), 
     mod_types, 
     extract_splits_metrics) %&amp;gt;% 
  bind_rows()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The overall performance as well as the performance across splits suggests that both models were better than the baseline (the mean within the analysis set)&lt;a href=&#34;#fn25&#34; class=&#34;footnote-ref&#34; id=&#34;fnref25&#34;&gt;&lt;sup&gt;25&lt;/sup&gt;&lt;/a&gt; and that the linear model outperformed the random forest model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;splits_perf %&amp;gt;% 
  mutate(id = forcats::fct_rev(id)) %&amp;gt;% 
  ggplot(aes(x = .estimate, y = id, colour = source))+
  geom_vline(aes(xintercept = mean, colour = fct_relevel(source, c(&amp;quot;lm&amp;quot;, &amp;quot;rf&amp;quot;, &amp;quot;null&amp;quot;))), 
           alpha = 0.4,
           data = avg_perf)+
  geom_point()+
  facet_wrap(~.metric, scales = &amp;quot;free_x&amp;quot;)+
  xlim(c(0, NA))+
  theme_bw()+
  labs(caption = &amp;quot;Vertical lines are average performance as captured by `tune::collect_metrics()`&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-12-window-functions-for-resampling_files/figure-html/plot-performance-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We could use a paired sample t-test to formally compare the random forest and linear models’ out-of-sample RMSE performance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(
  filter(splits_perf, source == &amp;quot;lm&amp;quot;, .metric == &amp;quot;rmse&amp;quot;) %&amp;gt;% pull(.estimate),
  filter(splits_perf, source == &amp;quot;rf&amp;quot;, .metric == &amp;quot;rmse&amp;quot;) %&amp;gt;% pull(.estimate),
  paired = TRUE
) %&amp;gt;% 
  broom::tidy() %&amp;gt;% 
  mutate(across(where(is.numeric), round, 4)) %&amp;gt;% 
  knitr::kable() &lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;statistic&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p.value&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;conf.low&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;conf.high&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;method&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;alternative&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-0.0839&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.7277&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0033&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.1334&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0343&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Paired t-test&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;two.sided&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This suggests the better performance by the linear model &lt;em&gt;is&lt;/em&gt; statistically significant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other potential steps:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There is lots more we could do from here&lt;a href=&#34;#fn26&#34; class=&#34;footnote-ref&#34; id=&#34;fnref26&#34;&gt;&lt;sup&gt;26&lt;/sup&gt;&lt;/a&gt;. However the purpose of this post was to provide a short &lt;code&gt;tidymodels&lt;/code&gt; example that incorporates window functions from &lt;code&gt;rsample&lt;/code&gt; and &lt;code&gt;slider&lt;/code&gt; on a regression problem. For more resources on modeling and the &lt;code&gt;tidymodels&lt;/code&gt; framework, see &lt;a href=&#34;https://www.tidymodels.org/&#34;&gt;tidymodels.org&lt;/a&gt; or &lt;a href=&#34;https://www.tmwr.org/&#34;&gt;Tidy Modeling with R&lt;/a&gt;&lt;a href=&#34;#fn27&#34; class=&#34;footnote-ref&#34; id=&#34;fnref27&#34;&gt;&lt;sup&gt;27&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;model-building-with-hyperparameter-tuning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model Building with Hyperparameter Tuning&lt;/h2&gt;
&lt;p&gt;Below is code for tuning a &lt;code&gt;glmnet&lt;/code&gt; linear regression model (use &lt;code&gt;tune&lt;/code&gt; to optimize the L1/L2 penalty)&lt;a href=&#34;#fn28&#34; class=&#34;footnote-ref&#34; id=&#34;fnref28&#34;&gt;&lt;sup&gt;28&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rec_glmnet &amp;lt;- rec_general %&amp;gt;% 
  step_dummy(all_predictors(), -all_numeric()) %&amp;gt;%
  step_normalize(all_predictors(), -all_nominal()) %&amp;gt;% 
  step_zv(all_predictors())

glmnet_mod &amp;lt;- parsnip::linear_reg(penalty = tune(), mixture = tune()) %&amp;gt;% 
  set_engine(&amp;quot;glmnet&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)

glmnet_workflow &amp;lt;- workflow::workflow() %&amp;gt;% 
  add_model(glmnet_mod) %&amp;gt;% 
  add_recipe(rec_glmnet)

glmnet_grid &amp;lt;- tidyr::crossing(penalty = 10^seq(-6, -1, length.out = 20), mixture = c(0.05, 
    0.2, 0.4, 0.6, 0.8, 1))

glmnet_tune &amp;lt;- tune::tune_grid(glmnet_workflow, 
                         resamples = resamples, 
                         control = control_grid(save_pred = TRUE), 
                         grid = glmnet_grid)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And code to tune a &lt;code&gt;ranger&lt;/code&gt; Random Forest model, tuning the &lt;code&gt;mtry&lt;/code&gt; and &lt;code&gt;min_n&lt;/code&gt; parameters&lt;a href=&#34;#fn29&#34; class=&#34;footnote-ref&#34; id=&#34;fnref29&#34;&gt;&lt;sup&gt;29&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rand_mod &amp;lt;- parsnip::rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&amp;gt;% 
  set_engine(&amp;quot;ranger&amp;quot;) %&amp;gt;% 
  set_mode(&amp;quot;regression&amp;quot;)
  
rf_workflow &amp;lt;- workflow() %&amp;gt;% 
  add_model(rand_mod) %&amp;gt;% 
  add_recipe(rec_general)

cores &amp;lt;- parallel::detectCores()

set.seed(1234)
rf_tune &amp;lt;- tune_grid(rf_workflow, 
                         resamples = resamples, 
                         control = control_grid(save_pred = TRUE), 
                         grid = 25)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;resources&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Link on doing regressions in slider: &lt;a href=&#34;https://twitter.com/dvaughan32/status/1247270052782637056?s=20&#34; class=&#34;uri&#34;&gt;https://twitter.com/dvaughan32/status/1247270052782637056?s=20&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Rstudio lightning talk on &lt;code&gt;slider&lt;/code&gt;: &lt;a href=&#34;https://rstudio.com/resources/rstudioconf-2020/sliding-windows-and-calendars-davis-vaughan/&#34; class=&#34;uri&#34;&gt;https://rstudio.com/resources/rstudioconf-2020/sliding-windows-and-calendars-davis-vaughan/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;modeltime&lt;/code&gt; package that applies &lt;code&gt;tidymodels&lt;/code&gt; suite to time series and forecasting problems: &lt;a href=&#34;https://business-science.github.io/modeltime/&#34; class=&#34;uri&#34;&gt;https://business-science.github.io/modeltime/&lt;/a&gt; (business-science course has more fully developed training materials on this topic as well)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;These were announced with version &lt;a href=&#34;https://github.com/tidymodels/rsample/blob/master/NEWS.md&#34;&gt;0.0.8&lt;/a&gt;. The help pages for &lt;code&gt;rsample&lt;/code&gt; (as well as the &lt;code&gt;slider&lt;/code&gt; package) are helpful resources for understanding the three types of sliding you can use, briefly these are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sliding_window()&lt;/code&gt;: only takes into account order / position of dates&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sliding_index()&lt;/code&gt;: slide according to an index&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sliding_period()&lt;/code&gt;: slide according to an index and set k split points based on period (and other function arguments)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;rsample::sliding_index()&lt;/code&gt; and &lt;code&gt;rsample::sliding_period()&lt;/code&gt; are maybe the most useful additions as they allow you to do resampling based on a date/time index. For &lt;code&gt;sliding_index()&lt;/code&gt;, you usually want to make use of the &lt;code&gt;step&lt;/code&gt; argument (otherwise it defaults to having a split for every observation).&lt;/p&gt;
&lt;p&gt;I found &lt;code&gt;rsample::sliding_period()&lt;/code&gt; easier to get acquantied with than &lt;code&gt;rsample::sliding_index()&lt;/code&gt;. However within the &lt;code&gt;slider&lt;/code&gt; package I found &lt;code&gt;slider::sliding_index()&lt;/code&gt; easier to use than &lt;code&gt;slider::sliding_period()&lt;/code&gt;. Perhaps this makes sense as when setting sampling windows you are usually trying to return an object with far fewer rows, that is, collapsed to k number of rows (unless you are doing Leave-One-Out cross-validation). On the other hand, the &lt;code&gt;slider&lt;/code&gt; package is often used in a &lt;code&gt;mutate()&lt;/code&gt; step where you often want to output the same number of observations as are inputted. Perhaps then it is unsurprising the different scenarios when the &lt;code&gt;index&lt;/code&gt; vs &lt;code&gt;period&lt;/code&gt; approach feels more intuitive.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Previously users would have needed to use &lt;code&gt;rsample::rolling_origin()&lt;/code&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;As opposed to a more specialized time-series modeling approach.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;This dataset is updated on an ongoing basis as Food Inspections are conducted. This makes it a poor choice as an example dataset (because results will vary if running in the future when more data has been collected). I used it because I am familiar with the dataset, it made for a good example, and because I wanted a publicly documented example of pulling in data using an API (even a simple one).&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;There is also “violations” dataset available, which may have additional useful features, but which I will ignore for this example.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;For this example I’m pretending that we only care about predicting &lt;code&gt;SCORE&lt;/code&gt; for restaurants… as opposed to food trucks or other entities that may receive inspections.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Or at least cases where historical data is claiming there were multiple inspections on the same day.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;In some cases you may need to be more careful than this and exclude information that are proxies for inappropriate fields as well. For example, pretend that the &lt;code&gt;INSPECTOR&lt;/code&gt;s are assigned based on region. In this case, &lt;code&gt;INSPECTOR&lt;/code&gt; would be a proxy for geographic information and perhaps warranting exclusion as well (in certain cases).&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;Into training / testing sets or analysis / assessment sets.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;As discussed by Davis Vaughn at the end of this &lt;a href=&#34;https://gist.github.com/DavisVaughan/433dbdceb439c9be30ddcc78d836450d&#34;&gt;gist&lt;/a&gt;.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;An “Analysis” / “Assessment” split is similar to a “training” / “testing” split but within the training dataset (and typically multiple of these are created on the same training dataset). See section 3.4 of &lt;a href=&#34;http://www.feat.engineering/resampling.html&#34;&gt;Feature Engineering and Selection…&lt;/a&gt; for further explanation.]&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;It is important that these features be created in a way that does not cause data leakage.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Which would not be available at the time of prediction.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;I’m a fan of the ability to use negative values in the &lt;code&gt;.after&lt;/code&gt; argument:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
This is a fairly obscure feature in {slider}, but I love it. Don’t want the current day in your rolling window? Set a negative &lt;code&gt;.after&lt;/code&gt; value to shift the end of the window backwards. For example:&lt;br&gt;&lt;br&gt;On day 5&lt;br&gt;.before = days(3)&lt;br&gt;.after = -days(1)&lt;br&gt;&lt;br&gt;Includes days:&lt;br&gt;[2, 4] &lt;a href=&#34;https://t.co/rG0IGuTj1c&#34;&gt;https://t.co/rG0IGuTj1c&lt;/a&gt;
&lt;/p&gt;
— Davis Vaughan (&lt;span class=&#34;citation&#34;&gt;@dvaughan32&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/dvaughan32/status/1233116713010573312?ref_src=twsrc%5Etfw&#34;&gt;February 27, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn15&#34;&gt;&lt;p&gt;If I did not make this assumption, I would need to impute the time based features at this point.&lt;a href=&#34;#fnref15&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn16&#34;&gt;&lt;p&gt;Two helpful resources for understanding time series cross-validation:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;From &lt;a href=&#34;https://eng.uber.com/forecasting-introduction/&#34;&gt;uber engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;From &lt;a href=&#34;https://otexts.com/fpp3/tscv.html&#34;&gt;Forecasting Principles and Practices&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;a href=&#34;#fnref16&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn17&#34;&gt;&lt;p&gt;An “Analysis” / “Assessment” split is similar to a “training” / “testing” split but within the training dataset (and typically multiple of these are created on the same training dataset). See section 3.4 of &lt;a href=&#34;http://www.feat.engineering/resampling.html&#34;&gt;Feature Engineering and Selection…&lt;/a&gt; for further explanation.]&lt;a href=&#34;#fnref17&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn18&#34;&gt;&lt;p&gt;I’ve tweeted previously about helper functions for reviewing your resampling scheme:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
❤️new &lt;code&gt;rsample::sliding_*()&lt;/code&gt; funs by &lt;a href=&#34;https://twitter.com/dvaughan32?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@dvaughan32&lt;/span&gt;&lt;/a&gt;. It can take a minute to check that all arguments are set correctly. Here are helper funs I&#39;ve used to check that my resampling windows are constructed as intended: &lt;a href=&#34;https://t.co/HhSjuRzAsB&#34;&gt;https://t.co/HhSjuRzAsB&lt;/a&gt; may make into an &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/shiny?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#shiny&lt;/a&gt; dashboard. &lt;a href=&#34;https://t.co/sNloHfkh4a&#34;&gt;pic.twitter.com/sNloHfkh4a&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1314720234373287937?ref_src=twsrc%5Etfw&#34;&gt;October 10, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;a href=&#34;#fnref18&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn19&#34;&gt;&lt;p&gt;Note that using &lt;code&gt;rsample::sliding_period()&lt;/code&gt; is likely to produce different numbers of observations between splits.&lt;a href=&#34;#fnref19&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn20&#34;&gt;&lt;p&gt;It could also make sense to weight performance metrics by number of observations. One way to do this, would be to use a control function to extract the predictions, and then evaluate the performance across the predictions. In my examples below I do keep the predictions, but end-up not doing anything with them. Alternatively you could weight the performance metric by number of observations. The justification for weighting periods of different number of observations equally is that noise may vary consistently across time windows – weighting by observations may allow an individual time period too much influence (simply because it happened to be that there were a greater proportion of inspections at that period).&lt;a href=&#34;#fnref20&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn21&#34;&gt;&lt;p&gt;For each split, this will then build the features for the assessment set based on each analysis set.&lt;a href=&#34;#fnref21&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn22&#34;&gt;&lt;p&gt;Although I just do a simple &lt;code&gt;step_log()&lt;/code&gt; transform below, more sophisticated steps on lag based inputs would also be kosher, e.g. &lt;code&gt;step_pca()&lt;/code&gt;. However there is a good argument that many of these should be done prior to a &lt;code&gt;recipes&lt;/code&gt; step. For example, say you have missing values for some of the lag based inputs – in that case it may make sense to use a lag based method for imputation, which may work better than say a mean imputation using the training set. So, like many things, just be thoughtful and constantly ask youself what will be the ideal method while &lt;em&gt;being careful&lt;/em&gt; that, to the question of “will this data be available prior to the prediction?” that you can answer in the affirmitive.&lt;a href=&#34;#fnref22&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn23&#34;&gt;&lt;p&gt;Our number of observations is relatively high compared to the number of features, so there is a good chance we will have relatively low penalties. While working interactively, I did not see any substantive difference in performance.&lt;a href=&#34;#fnref23&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn24&#34;&gt;&lt;p&gt;Remember that this is not weighted by observations, so each assessment set impacts the overall performance equally, regardless of small differences in number of observations.&lt;a href=&#34;#fnref24&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn25&#34;&gt;&lt;p&gt;There is no baseline performance for Rsquared because the metric itself is based off amount of variance that is explained compared to the baseline (i.e. the mean).&lt;a href=&#34;#fnref25&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn26&#34;&gt;&lt;p&gt;You would likely iterate on the model building process (e.g. perform exploratory data analysis, review outliers in initial models, etc.) and eventually get to a final set of models to evaluate on the test set.&lt;a href=&#34;#fnref26&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn27&#34;&gt;&lt;p&gt;I added a few other links to the &lt;a href=&#34;#resources&#34;&gt;Resources&lt;/a&gt; section in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;a href=&#34;#fnref27&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn28&#34;&gt;&lt;p&gt;Our number of observations is relatively high compared to the number of features, so there is a good chance we will have relatively low penalties.&lt;a href=&#34;#fnref28&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn29&#34;&gt;&lt;p&gt;This was taking a &lt;em&gt;long&lt;/em&gt; time and is part of why I decided to move the tuned examples to the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;.&lt;a href=&#34;#fnref29&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A National Popular Vote Weighted by the Electoral College</title>
      <link>/2020/09/11/compromise-between-the-electoral-college-and-a-national-popular-vote/</link>
      <pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/11/compromise-between-the-electoral-college-and-a-national-popular-vote/</guid>
      <description>


&lt;p&gt;&lt;em&gt;In this post I discuss using a national popular vote weighted by the electoral college to elect the president. This approach would empower voters by expanding political influence outside of ‘battleground states.’ It would also preserve the existing biases built into the American electoral college (thereby making such a system legislatively palatable across party affiliations and electoral college traditionalists)&lt;/em&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Irrespective of political party or disposition towards direct democracy, the winner-take-all approach (currently applied by most US states to allocate their electoral votes for the president) has clear drawbacks. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;incentivizes only campaigning in battleground states&lt;/li&gt;
&lt;li&gt;less reliable outcomes compared to alternatives&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;incentivizes policies that benefit battleground states over the interests of ‘all Americans’&lt;/li&gt;
&lt;li&gt;promotes a feeling among much of the electorate that their vote is unlikely to influence the election&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the last several years&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, the movement for a national popular vote (to elect the president) has gained traction. A compact between states to vote for the national popular vote winner has been passed in states representing 196 of the 270 electoral votes required for the agreement to have legal force. The &lt;a href=&#34;https://www.nationalpopularvote.com/&#34;&gt;website&lt;/a&gt; of the organization promoting the National Popular Vote initiative outlines the disadvantages of the winner-take-all approach used by most states and provides arguments for employing a national popular vote. The site also provides evidence for the constitutionality of a national popular vote and counters ‘myths’ that a popular vote would overly advantage or disadvantage certain states.&lt;/p&gt;
&lt;p&gt;However partisanship makes transitioning to a national popular vote difficult. For any given presidential election cycle, the electoral college may favor a particular political party&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. Hence it may be against the advantaged party’s interests to support a change to the election process (likewise, the disadvantaged party has an incentive to &lt;em&gt;support&lt;/em&gt; a change in the election process&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;). Therefore a cynic could argue that getting the requisite number of states to legislate support for the national popular vote compact is almost synonymous with winning the election. Even a national popular vote that &lt;em&gt;was&lt;/em&gt; passed into law may be politically fragile, and at risk of frequent challenges depending on the state-level political party in power.&lt;/p&gt;
&lt;p&gt;The goal of the National Popular Vote initiative is to &lt;em&gt;make every vote matter equally&lt;/em&gt;. However if we weaken this goal to be: &lt;em&gt;make the importance of votes more equal than they currently are,&lt;/em&gt; &lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; it may be easier to change the electoral system in a way that is less likely to agitate partisans or traditionalists attached to the influences inherent in the electoral college.&lt;/p&gt;
&lt;p&gt;I propose that a popular vote &lt;em&gt;weighted by the electoral college&lt;/em&gt; deserves consideration. Such an approach is equivalent to having the allocation of electoral votes in each state be based on the popular vote within that state. For example, if a state has 30 electoral votes, and 55% of those go to the Republican and 45% to the Democrat, the Republican would receive 16.5 votes and the Democrat 13.5. Let’s apply this across states for the 2012 election.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://github.com/brshallo/weighted-national-popular-vote/blob/master/state-electoral-votes-split.png?raw=true&#34; alt=&#34;brshallo/weighted-national-popular-vote&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;&lt;a href=&#34;https://github.com/brshallo/weighted-national-popular-vote&#34;&gt;brshallo/weighted-national-popular-vote&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Aggregating these for the 2012 election, the Democrat (Obama) would have received 271.4 electoral votes, the Republican (Romney) 255 electoral votes, and other candidates 11.6 electoral votes. This represents 50.4%, 47.4%, and 2.2% respectively. Describing outcomes in terms of ‘proportional allocation of electoral votes by state’ or as a ‘electoral college weighted percentage of the popular vote’ are interchangeable&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. However percentages are easier to articulate, hence this is the terminology I use for the remainder of the post.&lt;/p&gt;
&lt;p&gt;A national popular vote weighted by the electoral college would truly empower small states&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; whose voters’ ballots could be worth as much as three times those of larger states&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/US_2010_Census_State_Population_Per_Electoral_Vote.png/660px-US_2010_Census_State_Population_Per_Electoral_Vote.png&#34; alt=&#34;State Population per electoral vote from the 2010 census, Wikipedia, National Popular Vote Interstate Compact&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;State Population per electoral vote from the 2010 census, &lt;a href=&#34;https://en.wikipedia.org/wiki/National_Popular_Vote_Interstate_Compact&#34;&gt;Wikipedia, National Popular Vote Interstate Compact&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;While this may seem horribly unfair, it only makes the existing biases built into the electoral college more transparent. Also&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;, it still represents a major improvement in representativeness over the existing system – where only a ~quarter of the population’s votes make any substantitive difference in the outcome of the election (those votes in battleground states&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A weighted national popular vote would likely preserve (at least in part) any advantage a party has in the electoral college (for a given election cycle). This would make associated legislation potentially easier to pass and more enduring across changes in state party leadership (compared to legislation for a raw popular vote). The weighted popular vote also maintains the essence of the existing electoral college&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt; – it just replaces ‘winner-take-all’ with ‘proportional’ allocation of a state’s electoral votes (perhaps a less glaring difference compared to adopting a raw national popular vote).&lt;/p&gt;
&lt;p&gt;Let’s review what the results would have been in recent elections if applying a national popular vote weighted by the electoral college.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Proportion of electoral college weighted national popular vote won on elections from 1976 to 2016:&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;year&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;dem&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;rep&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;other&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1976&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.499&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.476&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.024&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1980&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.411&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.504&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.085&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1984&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.401&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.588&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1988&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.454&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.533&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1992&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.427&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.373&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;1996&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.488&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.407&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.105&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.478&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.480&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.478&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.509&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.525&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.456&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.019&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2012&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.504&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.474&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2016&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.474&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.462&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.064&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Since 1976 there have been two elections where the popular vote and the electoral college did not agree (2000 and 2016). The weighted national popular vote would have disagreed with the raw national popular vote once (in the 2000 election) and with the winner-take-all based electoral college once (in 2016)&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;See github repo &lt;a href=&#34;https://github.com/brshallo/weighted-national-popular-vote&#34;&gt;brshallo/weighted-national-popular-vote&lt;/a&gt; for details on data sources and scripts used to produce the above figures and calculations.&lt;/p&gt;
&lt;div id=&#34;how-to-get-it-passed&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to get it passed?&lt;/h1&gt;
&lt;p&gt;The beginning of the video “Myths About Constitutionality” explains how we got our current ‘winner-take-all’ systems across states.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/ubIeQ-uO_b0?start=92&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Essentially it was a &lt;a href=&#34;https://en.wikipedia.org/wiki/Collective_action_problem#:~:text=A%20collective%20action%20problem%20or,individuals%20that%20discourage%20joint%20action.&#34;&gt;collective action problem&lt;/a&gt; whereby states (controlled by one party or another) adopted a ‘winner-take-all’ approach as a means of attempting to maximize their individual influence (and give the most advantage they could to their preferred candidate). Once a few states adopted the ‘winner-take-all’ system it created a domino effect whereby all states adopted it&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ways of getting around this collective action problem:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The approach the National Popular Vote initiative has used is to have individual states pass laws that only go into effect once the requisite threshold of electoral votes is reached – thereby not forcing any individual state to ‘give-up’ some of their influence prematurely. The same approach could be taken to push adoption of a weighted national popular vote&lt;a href=&#34;#fn15&#34; class=&#34;footnote-ref&#34; id=&#34;fnref15&#34;&gt;&lt;sup&gt;15&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Other approaches may be more piecemeal. For example states of similar size and counterbalanced political leanings could agree to pass proportional voting laws simultaneously – thereby not reducing the support to their preferred presidential candidate&lt;a href=&#34;#fn16&#34; class=&#34;footnote-ref&#34; id=&#34;fnref16&#34;&gt;&lt;sup&gt;16&lt;/sup&gt;&lt;/a&gt;. Such an approach would be more effective if fractional votes among electors are allowed&lt;a href=&#34;#fn17&#34; class=&#34;footnote-ref&#34; id=&#34;fnref17&#34;&gt;&lt;sup&gt;17&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn18&#34; class=&#34;footnote-ref&#34; id=&#34;fnref18&#34;&gt;&lt;sup&gt;18&lt;/sup&gt;&lt;/a&gt;. However there is an argument that states would not have an incentive to pass this type of legislation on a piecemeal basis because it would transfer influence to the existing ‘winner-take-all’ states&lt;a href=&#34;#fn19&#34; class=&#34;footnote-ref&#34; id=&#34;fnref19&#34;&gt;&lt;sup&gt;19&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;A US constitutional amendment…&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-note&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Closing note&lt;/h1&gt;
&lt;p&gt;The chief advantage of a national popular vote for presidential elections is not that it achieves &lt;em&gt;perfect&lt;/em&gt; representation but that it provides &lt;em&gt;improved incentives&lt;/em&gt; for presidential candidates. For example it would incentivize campaigns to give attention to a broader subset of the American public and increase the reliability of election results. However a national popular vote inevitably faces partisan challenges and may give-off the appearance of being too momentous a departure from the norms of the existing electoral college. As a compromise between these systems, a national popular vote that is weighted by the electoral college avoids many of the challenges to legislating a pure national popular vote while still achieving its most important objectives.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;what-about-nebraska-and-maine&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What about Nebraska and Maine?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;In all but two states, electoral votes are ‘winner-take-all’. The candidate winning the popular vote normally receives all of that state’s votes. Maine and Nebraska have taken a different approach. Using the ‘congressional district method’, these states allocate two electoral votes to the state popular vote winner, and then one electoral vote to the popular vote winner in each Congressional district (2 in Maine, 3 in Nebraska). This creates multiple popular vote contests in these states, which could lead to a split electoral vote.&lt;/p&gt;
&lt;p&gt;-&lt;a href=&#34;https://www.270towin.com/content/split-electoral-votes-maine-and-nebraska/&#34;&gt;270towin.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There may be some philosophical appeal to this method for allocating votes however there are still relatively similar problems with it to the ‘winner-take-all’ method when applied to the state. For example,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if your vote is not in a ‘battleground district’ your vote, once again, may not matter as much (i.e. a ‘battleground state’ is simply replaced by a ‘battleground district’)&lt;/li&gt;
&lt;li&gt;opens-up presidential election to risks associated with gerrymandering&lt;/li&gt;
&lt;li&gt;if this were applied nationally, appealing to specific states could be supplanted by appealing to specific types of congressional districts, e.g. districts with more urban or rural areas (which may influence president’s against ‘looking out for all Americans’)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;This post presents potential merits of a weighted national popular vote however it does not represent a personal endorsement.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;A few thousand votes have a greater chance of swaying entire elections in our current system compared to the likelihood of this occurring with, for example, a national popular vote (&lt;a href=&#34;https://theconversation.com/the-electoral-college-is-surprisingly-vulnerable-to-popular-vote-changes-141104&#34;&gt;Heilman, 2020&lt;/a&gt;).&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;particularly since the 2016 election&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;However the political party the electoral college advantages frequently changes between election cycles (&lt;a href=&#34;https://fivethirtyeight.com/features/will-the-electoral-college-doom-the-democrats-again/&#34;&gt;Silver, 2016&lt;/a&gt;).&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;It’s not a coincidence that the popular vote initiative is gained substantial support from many Democrats following the 2016 election.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;by spreading political influence away from the dozen or so battleground states&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;As long as you allow for fractional electoral votes.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;The electoral college is designed to empower small states, though in practice it only empowers battleground states (at least for presidential elections).&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;For an alternative approach to weighting influence, see &lt;a href=&#34;https://theconversation.com/whose-votes-count-the-least-in-the-electoral-college-74280&#34;&gt;Durran, 2017&lt;/a&gt; which reviews states have the highest or lowest weighted votes based on actual voters (rather than the census). In the article they point-out that many of the votes in mid-sized states actually have the lowest weights. They attribute this to higher voter turnout and note (at the end of the article) that this may be contributed to by many of these being in battleground states.&lt;/p&gt;
&lt;p&gt;I did a similar analysis weighting by: &lt;span class=&#34;math display&#34;&gt;\[\frac{totalVotes/nationalElectoralVotes(538)}{stateVotes/stateElectoralVotes}\]&lt;/span&gt; Below is a figure of weights for the 2012 election:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/brshallo/weighted-national-popular-vote/blob/master/electoral-influence-2012.png?raw=true&#34; /&gt;&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;regardless of your opinion on the electoral college and whether voters in small states &lt;em&gt;should&lt;/em&gt; be afforded outsized representation compared to their population&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;“Influence” here is evidenced by campaign events and ad spending among candidates as described by the &lt;a href=&#34;https://www.nationalpopularvote.com/written-explanation&#34;&gt;the National Popular Vote Initiative&lt;/a&gt;.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;I.e. it still spreads out votes by states and not just across the population&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;In 2016 Clinton would have had a ~1 percentage point advantage over Trump in the weighted popular vote (compared to the ~2 percentage point advantage she had in the raw popular vote). Under the weighted popular vote George W. Bush would still have still won the election in 2000, despite losing the raw popular vote.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;The result of every state adopting it however has, at least in modern elections, resulted in the majority of states’ influence being reduced.&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn15&#34;&gt;&lt;p&gt;I.e. the law would only go into effect when states representing 270 electoral votes passed legislation.&lt;a href=&#34;#fnref15&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn16&#34;&gt;&lt;p&gt;E.g. say a ten vote state that tends to go 60% democratic teams up with another ten vote state that tends to go 60% republican and each pass a proportional voting system simultaneously.&lt;a href=&#34;#fnref16&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn17&#34;&gt;&lt;p&gt;Interesting article on fractional representatives: &lt;a href=&#34;http://www.hnn.us/articles/129114.html&#34; class=&#34;uri&#34;&gt;http://www.hnn.us/articles/129114.html&lt;/a&gt; .&lt;a href=&#34;#fnref17&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn18&#34;&gt;&lt;p&gt;If such an approach were adopted by all states, it would create the problem of it being more likely that an individual candidates does not receive the constitutionally required 270 electoral votes… which would need to be addressed. Perhaps could be handled by letting voters put a second choice of candidate. Then If a candidate isn’t in the top two, his voters ballots would flow to their 2nd choices (or 3rd, and so-on).&lt;a href=&#34;#fnref18&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn19&#34;&gt;&lt;blockquote&gt;
&lt;p&gt;“Enactment of the whole number proportional approach on a state-by-state basis would penalize early adopters and quickly become a self-arresting process, because each enactment would increase the influence of the remaining winner-take-all states.”
&lt;a href=&#34;https://www.nationalpopularvote.com/shortcoming-proportional-method-awarding-electoral-votes&#34;&gt;National Popular Vote Iniative&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href=&#34;#fnref19&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Linear Regression in Pricing Analysis, Essential Things to Know</title>
      <link>/2020/08/17/pricing-insights-from-historical-data-part-1/</link>
      <pubDate>Mon, 17 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/08/17/pricing-insights-from-historical-data-part-1/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-influences-price&#34;&gt;What influences price?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#simple-linear-regression-model&#34;&gt;Simple linear regression model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#inference-and-challenges&#34;&gt;Inference and challenges&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#violation-of-model-assumptions&#34;&gt;Violation of model assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-tug-of-war-between-colinear-inputs&#34;&gt;The tug-of-war between colinear inputs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#improving-model-fit-considerations&#34;&gt;Improving model fit, considerations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#closing-notes-and-tips&#34;&gt;Closing notes and tips&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#pricing-challenges&#34;&gt;Pricing challenges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#future-pricing-posts&#34;&gt;Future pricing posts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dataset-considerations&#34;&gt;Dataset considerations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interpretability-of-machine-learning-methods&#34;&gt;Interpretability of machine learning methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regularization-and-colinear-variables&#34;&gt;Regularization and colinear variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#coefficients-of-a-regularized-model&#34;&gt;Coefficients of a regularized model&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Pricing is hard.&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media2.giphy.com/media/SG0KKFtwUpqJW/giphy.gif&#34; alt=&#34;Price is Right Contestant… struggling&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Price is Right Contestant… struggling&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is particularly true with large complicated products, common in Business to Business sales (B2B). B2B sellers may lack important information (e.g. accurate estimates of customer budget or ‘street’ prices for the various configurations of their products – the &lt;a href=&#34;#pricing-challenges&#34;&gt;Pricing challenges&lt;/a&gt; section discusses other internal and external limitations in setting prices). However organizations typically &lt;em&gt;do have&lt;/em&gt; historical data on internal sales transactions as well as leadership with a strong desire for &lt;em&gt;insights&lt;/em&gt; into pricing behavior. For now I’ll put aside the question of how to use econometric approaches to set ideal prices. Instead, I’ll walk through some statistical methods that rely only on historical sales information and that can be used for analyzing differences, trends, and abnormalities in your organizations pricing.&lt;/p&gt;
&lt;p&gt;With internal data&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; you can still support answers to many important questions and provide a starting place for more sophisticated pricing strategies or analyses. I will be writing a series of posts on pricing (see &lt;a href=&#34;#future-pricing-posts&#34;&gt;Future pricing posts&lt;/a&gt; section for likely topics). In this post, I will focus on the basic ideas and considerations important when using regression models to understand prices.&lt;/p&gt;
&lt;p&gt;I will use data from the Ames, Iowa housing market. See the &lt;a href=&#34;#dataset-considerations&#34;&gt;Dataset considerations&lt;/a&gt; section for why I use the &lt;a href=&#34;https://cran.r-project.org/web/packages/AmesHousing/AmesHousing.pdf&#34;&gt;ames&lt;/a&gt; dataset as an analogue for B2B selling / pricing scenarios (as well as problems with this choice). My examples were built using the R programming language, you can find the source code at my &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-08-11-pricing-insights-from-historical-data-part-1.Rmd&#34;&gt;github page&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;what-influences-price&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What influences price?&lt;/h1&gt;
&lt;p&gt;Products have features. These features&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; can be used to train a model to estimate price. For a linear model, the outputted coefficients associated with these features can act as proxies for the expected &lt;em&gt;dollar per unit&lt;/em&gt; change associated with the component&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; (&lt;a href=&#34;https://en.wikipedia.org/wiki/Ceteris_paribus&#34;&gt;ceteris paribus&lt;/a&gt;). In pricing contexts, the idea that regression coefficients relate to the value (i.e. ‘implicit price’) of the constituent components of the product is sometimes called hedonic modeling&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. An assumption in hedonic modeling is that our model includes all variables that matter to price&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;. This assumption is important in that it suggests:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Regression modeling of price is not well suited to contexts where you cannot explain a reasonably high proportion of the variance in the price of your product.&lt;/li&gt;
&lt;li&gt;You should be particularly thoughtful regarding the variables you include in your model and avoid including variables that represent overlapping/duplicated information about your product.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For a more full discussion on hedonic modeling&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; see the &lt;a href=&#34;https://www.oecd-ilibrary.org/docserver/9789264197183-7-en.pdf?expires=1597241573&amp;amp;id=id&amp;amp;accname=guest&amp;amp;checksum=0FA9E2EB249B3EB5DBA108E3AC44CCA3&#34;&gt;Handbook on Residential Property Prices Indices&lt;/a&gt;. In this post I will build very simple models that obviously don’t represent all relevant factors or meet some of the strong assumptions in hedonic modeling. Instead, my focus is on illustrating some basic considerations in regression that are particular important in pricing contexts.&lt;/p&gt;
&lt;div id=&#34;simple-linear-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simple linear regression model&lt;/h2&gt;
&lt;p&gt;Let’s build a model for home price that uses &lt;em&gt;just&lt;/em&gt; house square footage, represented by &lt;code&gt;Gr_Liv_Area&lt;/code&gt;&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;, as a feature for predicting home price.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\operatorname{Sale\_Price} = 13290 + 112(\operatorname{Gr\_Liv\_Area}) + \epsilon
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The coefficient on sale price of &lt;em&gt;112&lt;/em&gt; is a measure of expected dollars per unit change in square foot. If you build the model without an intercept&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;, the coefficient more directly equates to dollars per square foot&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. However it’s &lt;em&gt;typically&lt;/em&gt; more appropriate to &lt;a href=&#34;https://stats.stackexchange.com/questions/7948/when-is-it-ok-to-remove-the-intercept-in-a-linear-regression-model&#34;&gt;leave the intercept in the model&lt;/a&gt;&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inference-and-challenges&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Inference and challenges&lt;/h2&gt;
&lt;p&gt;In evaluating the impact of a component on the price, we don’t want &lt;em&gt;just&lt;/em&gt; an estimate of the magnitude of the impact. Instead we want a measure of the likely range this estimate falls within. The traditional way to compute this is by using the standard error associated with our estimate.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13289.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3269.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Gr_Liv_Area&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;111.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can do &lt;em&gt;{coefficient estimate} +/- 2&lt;/em&gt;&lt;span class=&#34;math inline&#34;&gt;\(\cdot\)&lt;/span&gt;&lt;em&gt;{standard error of estimate}&lt;/em&gt; to get a 95% confidence interval for where we believe the ‘true’ coefficient estimate for &lt;code&gt;Gr_Liv_Area&lt;/code&gt; falls. In this case, this means that across our observations, the mean price change per square foot (while only taking into account this variables) is roughly between 108 and 116&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;violation-of-model-assumptions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Violation of model assumptions&lt;/h3&gt;
&lt;p&gt;Linear regression has a number of &lt;a href=&#34;https://en.wikipedia.org/wiki/Linear_regression#Assumptions&#34;&gt;model assumptions&lt;/a&gt;. Following these is less important when using the model for predictions compared to for inference&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;. However if you are interpreting the coefficients as representations of the value associated with components of a product (as in our case), model assumptions &lt;em&gt;matter&lt;/em&gt;&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;. I will leave it up to you and Google to read more on model assumptions&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-tug-of-war-between-colinear-inputs&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The tug-of-war between colinear inputs&lt;/h3&gt;
&lt;p&gt;Let’s add to our regression model another variable, number of bathrooms represented by the &lt;code&gt;bathrooms&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\operatorname{Sale\_Price} = 5491 + 94(\operatorname{Gr\_Liv\_Area}) + 19555(\operatorname{bathrooms}) + \epsilon
\]&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5491.2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3356.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Gr_Liv_Area&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;94.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bathrooms&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19555.3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2284.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The coefficient on square footage has decreased – this is because number of bathrooms and square feet of home are correlated (they have a &lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34;&gt;correlation&lt;/a&gt; of 0.71). Some of the impact on home price that previously existed entirely in the coefficient for &lt;code&gt;Gr_Liv_Area&lt;/code&gt; is now shared with the related &lt;code&gt;bathrooms&lt;/code&gt; variable. Also, the standard error on &lt;code&gt;Gr_Liv_Area&lt;/code&gt; has increased – representing greater uncertainty as to the mean impact of the variable within the model (compared to the prior simple linear regression example).&lt;/p&gt;
&lt;p&gt;Let’s consider a model with another variable added: &lt;code&gt;TotRms_AbvGrd&lt;/code&gt;, the total number of rooms (above ground and excluding bathrooms) in the home. This variable is also correlated with &lt;code&gt;Gr_Liv_Area&lt;/code&gt; and number of &lt;code&gt;bathrooms&lt;/code&gt; (correlation of ~0.8 and ~0.6 respectively).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\operatorname{Sale\_Price} &amp;amp;= 35600 + 122(\operatorname{Gr\_Liv\_Area})\ + \\
&amp;amp;\quad 20411(\operatorname{bathrooms}) - 11389(\operatorname{TotRms\_AbvGrd})\ + \\
&amp;amp;\quad \epsilon
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;term&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;estimate&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;std.error&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;(Intercept)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;35600.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4384.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Gr_Liv_Area&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;121.8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bathrooms&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20410.7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2245.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;TotRms_AbvGrd&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-11389.4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1093.6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notice the coefficient on &lt;code&gt;TotRms_AbvGrd&lt;/code&gt; is negative at &lt;em&gt;-11792.2&lt;/em&gt;. This doesn’t mean houses with more bedrooms are associated with negative home prices. Though it suggests a house with the same square footage and number of bathrooms will be less expensive if it has more rooms&lt;a href=&#34;#fn15&#34; class=&#34;footnote-ref&#34; id=&#34;fnref15&#34;&gt;&lt;sup&gt;15&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theoretical challenge:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pretend we put in another variable: &lt;code&gt;half_bathrooms&lt;/code&gt; that represented the number of half bathrooms in the home. Our previous variable &lt;code&gt;bathrooms&lt;/code&gt; already included both full and half bathrooms. This presents a theoretical problem for the model: bathrooms would be represented in two different variables that have a &lt;em&gt;necessary&lt;/em&gt; overlap&lt;a href=&#34;#fn16&#34; class=&#34;footnote-ref&#34; id=&#34;fnref16&#34;&gt;&lt;sup&gt;16&lt;/sup&gt;&lt;/a&gt; with one another. Our understanding of the value of a bathroom as its coefficient value would become less clear&lt;a href=&#34;#fn17&#34; class=&#34;footnote-ref&#34; id=&#34;fnref17&#34;&gt;&lt;sup&gt;17&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Beyond this &lt;em&gt;theoretical challenge&lt;/em&gt;, duplicated or highly associated inputs also create &lt;em&gt;numeric challenges&lt;/em&gt;. The remainder of this post will be focused on numeric challenges and considerations in fitting regression models. These lessons can be applied broadly across inferential contexts but are particularly important in pricing analysis.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numeric challenge:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Linear regression models feature this ‘tug-of-war’ between the magnitude of coefficients whereby correlated variables share general influences in the model. At times this causes similar variables to seem to have opposing impacts&lt;a href=&#34;#fn18&#34; class=&#34;footnote-ref&#34; id=&#34;fnref18&#34;&gt;&lt;sup&gt;18&lt;/sup&gt;&lt;/a&gt;. When evaluating coefficients for pricing analysis exercises&lt;a href=&#34;#fn19&#34; class=&#34;footnote-ref&#34; id=&#34;fnref19&#34;&gt;&lt;sup&gt;19&lt;/sup&gt;&lt;/a&gt; this competition between coefficients has potential drawbacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As you increase the number of variables in the model, colinearity can make for models with a high degree of instability / variance in the parameter estimates – meaning that the coefficients in your model (and your resulting predictions) could change dramatically even from small changes in the training data&lt;a href=&#34;#fn20&#34; class=&#34;footnote-ref&#34; id=&#34;fnref20&#34;&gt;&lt;sup&gt;20&lt;/sup&gt;&lt;/a&gt;, which undermines confidence in estimates.&lt;/li&gt;
&lt;li&gt;You may want to limit methods that result in models with unintuitive variable relationships (e.g. where related factors have coefficients that appear to act in opposing directions).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;improving-model-fit-considerations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Improving model fit, considerations&lt;/h2&gt;
&lt;p&gt;I do not discuss the topic of &lt;em&gt;variable selection&lt;/em&gt;, but highly recommend the associated chapter in the online textbook &lt;a href=&#34;http://www.feat.engineering/selection.html&#34;&gt;Feature Engineering and Selection&lt;/a&gt; by Max Kuhn and Kjell Johnson.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data transformations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before modeling, transformations to the underlying data are often applied for one of several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To help satisfy model assumptions or to minimize the impact of outliers and influential points on estimates.&lt;/li&gt;
&lt;li&gt;To improve the fit of the model.&lt;/li&gt;
&lt;li&gt;To help with model interpretation&lt;a href=&#34;#fn21&#34; class=&#34;footnote-ref&#34; id=&#34;fnref21&#34;&gt;&lt;sup&gt;21&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To facilitate preprocessing requirements important to the fitting procedure&lt;a href=&#34;#fn22&#34; class=&#34;footnote-ref&#34; id=&#34;fnref22&#34;&gt;&lt;sup&gt;22&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Important in pricing contexts, transformations to the data alter the meaning of the coefficients&lt;a href=&#34;#fn23&#34; class=&#34;footnote-ref&#34; id=&#34;fnref23&#34;&gt;&lt;sup&gt;23&lt;/sup&gt;&lt;/a&gt;. Data transformations may improve model fit, but may complicate coefficient interpretability. In some cases this may be helpful in other cases it may not – it all depends on the aims of the model and the types of interpretations the analyst is hoping to make&lt;a href=&#34;#fn24&#34; class=&#34;footnote-ref&#34; id=&#34;fnref24&#34;&gt;&lt;sup&gt;24&lt;/sup&gt;&lt;/a&gt;. As part of an internal presentation given at NetApp on pricing, I describe some common variable transformations and how these affect the resulting interpretation of the coefficients:&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/dqrkIIziBLE?start=448&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;strong&gt;More sophisticated Machine Learning Methods:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When using more sophisticated machine learning techniques the term &lt;em&gt;data transformation&lt;/em&gt; is sometimes supplanted by the term &lt;em&gt;feature engineering&lt;/em&gt; (though the latter typically suggests more numerous or more complicated changes to input data). Some machine learning techniques&lt;a href=&#34;#fn25&#34; class=&#34;footnote-ref&#34; id=&#34;fnref25&#34;&gt;&lt;sup&gt;25&lt;/sup&gt;&lt;/a&gt; can also identify hard to find relationships or obviate the need for complex data transformations that would be required to produce good model fits with a linear model&lt;a href=&#34;#fn26&#34; class=&#34;footnote-ref&#34; id=&#34;fnref26&#34;&gt;&lt;sup&gt;26&lt;/sup&gt;&lt;/a&gt;. This may save an analyst time or allow them to produce models with a better fit but may come at a cost to ease of model interpretability. For a brief discussion, see the section &lt;a href=&#34;#interpretability-of-machine-learning-methods&#34;&gt;Interpretability of machine learning methods&lt;/a&gt;. For this post, I will stick to linear models.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fitting procedures&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Alternatives to the standard optimization technique for linear regression, &lt;a href=&#34;https://en.wikipedia.org/wiki/Ordinary_least_squares#:~:text=In%20statistics%2C%20ordinary%20least%20squares,in%20a%20linear%20regression%20model.&amp;amp;text=Under%20these%20conditions%2C%20the%20method,the%20errors%20have%20finite%20variances&#34;&gt;Ordinary Least Squares&lt;/a&gt; (OLS), may be more robust to model assumptions and influential points or tend to produce more stable estimates&lt;a href=&#34;#fn27&#34; class=&#34;footnote-ref&#34; id=&#34;fnref27&#34;&gt;&lt;sup&gt;27&lt;/sup&gt;&lt;/a&gt;. A few options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Regularization&lt;/em&gt;: puts constraints on the linear model that discourage high levels of variance in your coefficient estimates. See the section &lt;a href=&#34;#regularization-and-colinear-variables&#34;&gt;Regularization and colinear variables&lt;/a&gt; for a more full discussion on how L1 &amp;amp; L2 penalties affect estimates for colinear inputs differently&lt;a href=&#34;#fn28&#34; class=&#34;footnote-ref&#34; id=&#34;fnref28&#34;&gt;&lt;sup&gt;28&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Bayesian approaches&lt;/em&gt;: can use &lt;a href=&#34;https://en.wikipedia.org/wiki/Prior_probability&#34;&gt;priors&lt;/a&gt; and rigorous estimation procedures to limit &lt;a href=&#34;https://en.wikipedia.org/wiki/Overfitting&#34;&gt;overfitting&lt;/a&gt; and subdue extreme estimates.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Robust regression&lt;/em&gt;: typically refers to using weighted least squares (or similar methods) which allows for giving different amounts of weight to observations (typically to reduce the weight of extreme and influential points).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these fitting procedures has different advantages and disadvantages and will modulate coefficient estimates differently&lt;a href=&#34;#fn29&#34; class=&#34;footnote-ref&#34; id=&#34;fnref29&#34;&gt;&lt;sup&gt;29&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-notes-and-tips&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Closing notes and tips&lt;/h1&gt;
&lt;p&gt;You can use regression models to evaluate the impact of different factors on price. However it is important to consider how coefficient estimates will respond to your particular input data (e.g. multicolinearity of your inputs or violations of your model assumptions) and to use techniques that will produce an appropriate model fit for your needs. In pricing contexts in particular you should consider the types of inferences you will be asked to make and build your model in a way that fits your business requirements.&lt;/p&gt;
&lt;p&gt;Some tips for building models for inference in pricing contexts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If your model doesn’t explain a high proportion of the data, be careful what you say to stakeholders about the respective value of components&lt;a href=&#34;#fn30&#34; class=&#34;footnote-ref&#34; id=&#34;fnref30&#34;&gt;&lt;sup&gt;30&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Getting a good model fit should be a driving force. However, in a similar way to how you may prefer fewer variables or a more simple modeling technique, you may also prefer fewer and less complicated variable transformations&lt;a href=&#34;#fn31&#34; class=&#34;footnote-ref&#34; id=&#34;fnref31&#34;&gt;&lt;sup&gt;31&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;When evaluating the influence of the components of your product, review the variability in your coefficient estimates and not just the estimates themselves.&lt;/li&gt;
&lt;li&gt;Consider building linear models using multiple model fit techniques&lt;a href=&#34;#fn32&#34; class=&#34;footnote-ref&#34; id=&#34;fnref32&#34;&gt;&lt;sup&gt;32&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn33&#34; class=&#34;footnote-ref&#34; id=&#34;fnref33&#34;&gt;&lt;sup&gt;33&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Even if you plan on using a linear model, using a generic more complex machine learning model can be helpful as a sanity check. If model performance is not substantially different between your models, you are fine, if it is, there may be an important relationship you are missing and need to identify.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Stay tuned for &lt;a href=&#34;#future-pricing-posts&#34;&gt;Future pricing posts&lt;/a&gt; on related topics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;pricing-challenges&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pricing challenges&lt;/h2&gt;
&lt;p&gt;Final price paid by a customer may vary substantially within a given product. This variability is often due in part to a high degree of complexity inherent in the product and different configurations between customers&lt;a href=&#34;#fn34&#34; class=&#34;footnote-ref&#34; id=&#34;fnref34&#34;&gt;&lt;sup&gt;34&lt;/sup&gt;&lt;/a&gt;. Fluctuations in product demand and macroeconomic factors are other important influences, as are factors associated with the buyer’s / seller’s negotiation skill and ability to use their brand and market information to leverage a higher or lower discount.&lt;/p&gt;
&lt;p&gt;The final price paid may also be influenced by a myriad of competing internal interests. Sales representatives may want leniency in price guidelines so they can hit their quota. Leadership may be concerned about potential brand erosion that often comes with lowering prices. Equity holders may be focused on immediate profitability or may be willing to sacrifice margin in order to expand market share. Effectively setting price guidelines requires the application of various economic, mathematical, and sociological principles&lt;a href=&#34;#fn35&#34; class=&#34;footnote-ref&#34; id=&#34;fnref35&#34;&gt;&lt;sup&gt;35&lt;/sup&gt;&lt;/a&gt; which may not be feasible to set-up&lt;a href=&#34;#fn36&#34; class=&#34;footnote-ref&#34; id=&#34;fnref36&#34;&gt;&lt;sup&gt;36&lt;/sup&gt;&lt;/a&gt;. Implementation of which requires reliable data, which could be lacking due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Market information may be inaccurate or unavailable&lt;a href=&#34;#fn37&#34; class=&#34;footnote-ref&#34; id=&#34;fnref37&#34;&gt;&lt;sup&gt;37&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Total&lt;/em&gt; costs of production may not be accessible (from your position in the organization).&lt;/li&gt;
&lt;li&gt;Current organizational goals may not be well defined.&lt;/li&gt;
&lt;li&gt;Information on successful deals may be more reliable than information on missed deals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These (or a host of other gaps in information) may make it difficult to define an objective function for identifying optimal price guidelines.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;future-pricing-posts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Future pricing posts&lt;/h2&gt;
&lt;p&gt;In a series of posts I will tackle a variety of questions stakeholders may ask regarding organizational pricing. Some likely topics include:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;How do differences in product components associate with differences in price? What is the magnitude of the influence of these factors?&lt;/li&gt;
&lt;li&gt;How have these factors changed over time?&lt;/li&gt;
&lt;li&gt;Which customers fall outside the ‘normal’ behavior in regard to the price they are receiving?&lt;/li&gt;
&lt;li&gt;How can complexities in pricing strategy be captured by a statistically rigorous modeling framework (E.g. when volume dictates price)?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;dataset-considerations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dataset considerations&lt;/h2&gt;
&lt;p&gt;The relevant qualities of a dataset I was looking for were:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Multiple years of data&lt;/li&gt;
&lt;li&gt;Many features, with a few key variables associated with a large proportion of the variance&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;code&gt;ames&lt;/code&gt; housing dataset meets these qualifications and i was already familiar with it. Evaluating home prices can serve as a practical analogue for our problem; both home sales and business to business sales often represent large purchases with many features influencing price. You can pretend that individual rows represent B2B transactions for a large corporation selling a complicated product line (rather than individual home sales).&lt;/p&gt;
&lt;p&gt;There are also many important &lt;em&gt;differences&lt;/em&gt; between home sales and B2B sales that make this a weaker analogue. To name a few:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in B2B contexts, repeat sales are typically more important than initial sales. In the housing market, repeat sales don’t exist.&lt;/li&gt;
&lt;li&gt;information on home prices and prior home sales is accessible to both the buyer and seller – meaning there are no options for targeted pricing.&lt;/li&gt;
&lt;li&gt;in B2B contexts, an influential buyer may be able to leverage their brand name&lt;a href=&#34;#fn38&#34; class=&#34;footnote-ref&#34; id=&#34;fnref38&#34;&gt;&lt;sup&gt;38&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Volume selling schemes and other pricing strategies may have less of an impact on house prices compared to in B2B settings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the notes in this first post, these don’t matter.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interpretability-of-machine-learning-methods&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interpretability of machine learning methods&lt;/h2&gt;
&lt;p&gt;In some pricing scenarios tree-based methods may be particularly helpful in modeling price – particularly in contexts where the price of a product can be well defined by if-then statements. This may be useful in cases where there is volume pricing – e.g. the pricing approach is different depending on the amount you are purchasing. Perhaps better though would be cubist models which start as decision trees but then terminate into individual linear models (allowing for different linear models based off pre-defined if-then statements).&lt;/p&gt;
&lt;p&gt;(Ignoring figuring out the &lt;em&gt;ideal&lt;/em&gt; type of model or feature engineering regiment&lt;a href=&#34;#fn39&#34; class=&#34;footnote-ref&#34; id=&#34;fnref39&#34;&gt;&lt;sup&gt;39&lt;/sup&gt;&lt;/a&gt; for your problem) the typical juxtaposition between linear models and more sophisticated machine learning techniques is in how easy they are to interpret. Sophisticated machine learning methods (sometimes described as ‘black-boxes’&lt;a href=&#34;#fn40&#34; class=&#34;footnote-ref&#34; id=&#34;fnref40&#34;&gt;&lt;sup&gt;40&lt;/sup&gt;&lt;/a&gt;) &lt;em&gt;can&lt;/em&gt; be made to be interpretable. Interpretation typically involves some approach that evaluates how the predictions change in relation to some change in the underlying data. This &lt;em&gt;prediction focused&lt;/em&gt; way of interpreting a model has the advantage of being more standard across model types. The argument goes that regardless of the structure of the model, you always get predictions, hence you should use these predictions to drive your interpretations of the model. This enables you to compare models (across things other than just raw performance) regardless of the type of model you use.&lt;/p&gt;
&lt;p&gt;The advantage linear models have is that the &lt;em&gt;model form itself&lt;/em&gt; is highly interpretable. Unlike other models the parameters of linear models are directly aggregatable. With a linear model you can more easily say how much value a component of a product adds to the price. With other types of models this translation is usually more difficult.&lt;/p&gt;
&lt;p&gt;Linear models can be understood by a wider audience and also may be viewed as more logical or fair&lt;a href=&#34;#fn41&#34; class=&#34;footnote-ref&#34; id=&#34;fnref41&#34;&gt;&lt;sup&gt;41&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn42&#34; class=&#34;footnote-ref&#34; id=&#34;fnref42&#34;&gt;&lt;sup&gt;42&lt;/sup&gt;&lt;/a&gt;. However, if you build a linear model with highly complicated transformations, interactions, or non-linear terms, notions of this ‘interpretability advantage’ start to deteriorate&lt;a href=&#34;#fn43&#34; class=&#34;footnote-ref&#34; id=&#34;fnref43&#34;&gt;&lt;sup&gt;43&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In summary, the breakdown of linear regression vs complicated machine learning models may be similar in pricing contexts as it is in other problem spaces:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you only care about accuracy of your predictions (i.e. pricing estimates) or want to save time on complex feature engineering more sophisticated machine learning techniques may be valuable.&lt;/li&gt;
&lt;li&gt;If you care about interpretability or have audit requirements regarding prices, linear models have a certain advantages.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;regularization-and-colinear-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regularization and colinear variables&lt;/h2&gt;
&lt;p&gt;Regularization typically comes in two flavors; either an L1 penalty (lasso regression) or L2 penalty (ridge regression), or some combination of these (elastic net) is applied to the linear model. These penalties provides a cost for larger coefficient which acts to decrease the variance in our estimates&lt;a href=&#34;#fn44&#34; class=&#34;footnote-ref&#34; id=&#34;fnref44&#34;&gt;&lt;sup&gt;44&lt;/sup&gt;&lt;/a&gt;. In conditions of colinear inputs, these two penalties act differently on coefficient estimates of colinear features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lasso regression tends to choose a ‘best’ variable (among a subset of colinear variables) whose coefficient ‘survives’, while the other associated variables’ coefficients are pushed towards zero&lt;/li&gt;
&lt;li&gt;For ridge regression, coefficients of similar variables gravitate to a similar value&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;coefficients-of-a-regularized-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coefficients of a regularized model&lt;/h2&gt;
&lt;p&gt;Variable inputs are usually standardized before applying regularization. Hence because inputs are all (essentially) put on the same scale, the coefficient estimates can be directly compared with one another as measures of their relative influence on the target (home price). This ease of comparison may be convenient. However if our goal is interpreting the coefficient estimates in terms of dollar change per &lt;em&gt;unit&lt;/em&gt; increase, we will need to back-transform the coefficients.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Internal sales data alone is limited in that its focused on only a component of sales, rather than considering the full picture – this puts the analyst in a familiar position of one with incomplete information, and a constrained scope of influence.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Dataset should be structured such that each feature is a column and each row an observation, e.g. a sale.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Sort of, and under certain contexts…&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Hedonic_regression&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Hedonic_regression&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Missing important components or misattributing influence of price can cause bias in the model (omitted variable bias).&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;and how it can also be used for things like creating price indices&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Does not including basement.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;I.e. make it zero so that the expected value of a house of 0 square foot is $0&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;In this case, the coefficient for the model becomes 119.7 if the intercept is set to zero.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;Hedonic modeling also has a variety of approaches associated with evaluating changes in the intercept term between models that (again) can be read in the the &lt;a href=&#34;https://www.oecd-ilibrary.org/docserver/9789264197183-7-en.pdf?expires=1597241573&amp;amp;id=id&amp;amp;accname=guest&amp;amp;checksum=0FA9E2EB249B3EB5DBA108E3AC44CCA3&#34;&gt;Handbook on Residential Property Prices Indices&lt;/a&gt;.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Note there are more modern approaches to estimating this range using Bayesian or simulation based methods.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;At least to the extent that satisfying them doesn’t improve your predictions, or suggest a different model type may be more appropriate.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Although some would argue that you don’t need to worry too much about any of your assumptions except that your observations are independent of one another.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;Model assumptions of linear regression by Ordinary Least Squares is already covered extensively in essentially every tutorial and Introduction to Statistics textbook on regression.&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn15&#34;&gt;&lt;p&gt;Perhaps representing a preference for larger rooms or open space among buyers or a confounding effect with some other variable. For the purposes of this post i simply want to point out how coefficient values can vary under conditions of colinearity.&lt;a href=&#34;#fnref15&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn16&#34;&gt;&lt;p&gt;(though not perfect colinearity)&lt;a href=&#34;#fnref16&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn17&#34;&gt;&lt;p&gt;Hence the importance of being particularly thoughtful of the variables you input into the model and avoiding variables that roughly duplicate one another.&lt;a href=&#34;#fnref17&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn18&#34;&gt;&lt;p&gt;A common rule of thumb for when variables are ‘too correlated’ is 0.90 – at least in regression contexts and cases where you are focused on inference. In other contexts (e.g. those that appear in &lt;a href=&#34;https://www.kaggle.com/&#34;&gt;Kaggle&lt;/a&gt; prediction competitions) this threshold can be much higher. However, as discussed, lower levels of correlation can still contribute to instability in your coefficient estimates&lt;a href=&#34;#fnref18&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn19&#34;&gt;&lt;p&gt;Where you care about the individual parameter estimates and want them to be meaningful.&lt;a href=&#34;#fnref19&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn20&#34;&gt;&lt;p&gt;This is what “variance” means in the bias-variance trade-off common in model development. This may also be referred to as instability in the model or parameter estimates.&lt;a href=&#34;#fnref20&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn21&#34;&gt;&lt;p&gt;An example of this may be standardizing the underlying data so that the coefficient estimates may be more directly compared to one another (as the underlying data is all on the same scale).&lt;a href=&#34;#fnref21&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn22&#34;&gt;&lt;p&gt;Standardizing the data is also important for many fitting methods, e.g. regularization.&lt;a href=&#34;#fnref22&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn23&#34;&gt;&lt;p&gt;E.g. a log transform on an input alters the interpretation of the coefficient to be something closer to dollars per percentage point change of input. Log on target means percentage change in price per unit change in input. If you take the log of both your inputs and your target, the coefficient represents percent change in x related to percent change in y, also known as an ‘elasticity’ model in econometrics.&lt;a href=&#34;#fnref23&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn24&#34;&gt;&lt;p&gt;There may be a preference to speak in the simplest terms: change in price as a function of unit change in component – which may put pressure on the analyst to limit data transformations. It is the analysts job then to strike the correct balance between producing a model that fits the data and one that can be understood by stakeholders.&lt;a href=&#34;#fnref24&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn25&#34;&gt;&lt;p&gt;Neural networks in particular.&lt;a href=&#34;#fnref25&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn26&#34;&gt;&lt;p&gt;Many non-linear methods still have sophisticated preprocessing requirements. Though these are sometimes more generic – meaning less work to customize between problems to reach at least some minimum level of fit between problems (again, in some contexts).&lt;a href=&#34;#fnref26&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn27&#34;&gt;&lt;p&gt;Some of what I read on hedonic modeling seemed to discourage the use of methods other than Ordinary Least Squares (e.g. Weighted Least Squares) but I’ve found other methods to be helpful.&lt;a href=&#34;#fnref27&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn28&#34;&gt;&lt;p&gt;Regularization with an L1 penalty provides the added bonus of also doing variable selection.&lt;a href=&#34;#fnref28&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn29&#34;&gt;&lt;p&gt;For robust methods and regularization, there are less established methods for producing confidence intervals. You may need to use simulation methods (which are more computationally intensive).&lt;a href=&#34;#fnref29&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn30&#34;&gt;&lt;p&gt;Generally it is a good idea to describe the mean error or some other measure, so that they can get a sense of how close the model you are describing is fitting the data, or whether the effects you are talking about are general, but not particularly useful for predictions.&lt;a href=&#34;#fnref30&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn31&#34;&gt;&lt;p&gt;And a preference for transformations that retain an intuitive interpretability for the model.&lt;a href=&#34;#fnref31&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn32&#34;&gt;&lt;p&gt;Then review the coefficient estimates across them.&lt;a href=&#34;#fnref32&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn33&#34;&gt;&lt;p&gt;I tend to rely heavily on regularization techniques.&lt;a href=&#34;#fnref33&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn34&#34;&gt;&lt;p&gt;A variety of factors though push organizations to simplify their products and this process – for the purposes of this post though, I’ll assume a complicated product portfolio.&lt;a href=&#34;#fnref34&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn35&#34;&gt;&lt;p&gt;For a more full discussion on these concepts see UVA coursera specialization on &lt;a href=&#34;https://www.coursera.org/learn/uva-darden-bcg-pricing-strategy-cost-economics?utm_source=gg&amp;amp;utm_medium=sem&amp;amp;utm_content=01-CourseraCatalog-DSA-US&amp;amp;campaignid=9918777773&amp;amp;adgroupid=102058276958&amp;amp;device=c&amp;amp;keyword=&amp;amp;matchtype=b&amp;amp;network=g&amp;amp;devicemodel=&amp;amp;adpostion=&amp;amp;creativeid=434544785640&amp;amp;hide_mobile_promo=&amp;amp;gclid=CjwKCAjwsan5BRAOEiwALzomXyDwos6rlUmAwFrv9BjJFUPnyvzPRedArpRD2iRkocMemgtsZrfihxoCjfUQAvD_BwE&#34;&gt;Cost and Economics in Pricing Strategy&lt;/a&gt;.&lt;a href=&#34;#fnref35&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn36&#34;&gt;&lt;p&gt;Organizations may lack the money or the will.&lt;a href=&#34;#fnref36&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn37&#34;&gt;&lt;p&gt;Maybe your company doesn’t want to pay the expensive prices that data vendors set for this information (this may especially be a problem if you are a small organization with a small budget).&lt;a href=&#34;#fnref37&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn38&#34;&gt;&lt;p&gt;While a home seller may be more sympathetic to some buyers over others (E.g. a newly wedded couple looking to start a family over a real-estate mogul looking for investment properties), such preferences likely impact price less than the analogue in the B2B contexts where sellers seek to strike details with popular brands as means of establishing product relevance and enabling further marketing and potentially collaboration opportunities.&lt;a href=&#34;#fnref38&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn39&#34;&gt;&lt;p&gt;PCA or factor analysis seems like a potentially useful approach in pricing contexts in cases where the variables you have do not clearly represent discrete components of the product – hopefully PCA would help to identify these implicit components.&lt;a href=&#34;#fnref39&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn40&#34;&gt;&lt;p&gt;Due to the lack of transparency into how they produce predictions.&lt;a href=&#34;#fnref40&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn41&#34;&gt;&lt;p&gt;Or at least in places where a price seems unfair, it may be easier to quickly identify where the issue lies.&lt;a href=&#34;#fnref41&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn42&#34;&gt;&lt;p&gt;There is a book &lt;em&gt;Weapons of Math Destruction&lt;/em&gt; by Cathy O’Neil that points to a lack of interpretability as one of the chief concerns with modern learning algorithms.&lt;a href=&#34;#fnref42&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn43&#34;&gt;&lt;p&gt;May as well use a Machine Learning method at this point.&lt;a href=&#34;#fnref43&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn44&#34;&gt;&lt;p&gt;In both cases non-informative regressors will tend towards zero (in the case of ridge regression, they will never &lt;em&gt;quite&lt;/em&gt; reach zero). These approaches typically require tuning to identify the ideal weight (i.e. pressure) assigned to the penalty.&lt;a href=&#34;#fnref44&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Animate interactive objects with Face Detection, JavaScript and Chrome Browser</title>
      <link>/2020/07/20/animate-interactive-objects-with-face-detection-javascript-and-chrome-browser/</link>
      <pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/07/20/animate-interactive-objects-with-face-detection-javascript-and-chrome-browser/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#things-following-you&#34;&gt;Things following you&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#codepen-example&#34;&gt;Codepen example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-i-made-it&#34;&gt;How I made it&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#next-steps&#34;&gt;Next steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learning-path-and-resources&#34;&gt;Learning path and resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#closing-thoughts&#34;&gt;Closing thoughts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#additional-actions&#34;&gt;Additional actions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;We spend the majority of our time in front of screens. It’s mostly one of computer/tablet/phone/tv&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. These are largely platforms the user owns or controls. I’m surprised we don’t yet have more interactions with screens &lt;em&gt;out in the world&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Face detection and object recognition technologies are now highly accessible, making it easy to use a camera to make a display interactive. In this post I’ll describe my starting place on a small project using this technology to create an animation designed to unnerve the user.&lt;/p&gt;
&lt;div id=&#34;things-following-you&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Things following you&lt;/h1&gt;
&lt;p&gt;Try to recall that creepy sensation you get when someone or something is looking at you. Now imagine having that all of the time. That is the unsettled feeling I want to evoke. A few ideas:&lt;/p&gt;
Poster for a new Lord of the Rings movie that has an Eye of Sauron that follows you as you walk into the cinema&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.
&lt;center&gt;
&lt;img src=&#34;https://i.insider.com/5aec114a19ee861f008b4855?width=1200&amp;amp;format=jpeg&amp;amp;auto=webp&#34; title=&#34;fig:&#34; alt=&#34;Eye of Sauron&#34; style=&#34;width:50.0%&#34; /&gt;
&lt;/center&gt;
An army recruiter with an “I want you” Uncle Sam poster behind him whose finger points at you as you walk by.
&lt;center&gt;
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1d/Unclesamwantyou.jpg/440px-Unclesamwantyou.jpg&#34; title=&#34;fig:&#34; alt=&#34;Uncle Sam&#34; style=&#34;width:50.0%&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Someone at the grocery store (during COVID19) whose shirt beeps and flashes red if you get within 6 feet of them.&lt;/p&gt;
&lt;p&gt;I intentionally made these examples somewhat dystopian. There is an important societal reckoning taking place right now regarding tracking technologies (particularly in regard to its impacts on communities of color). I wanted to work on something that, while playful, would call to mind concerns of a ‘Big Brother’ or ‘watchful eye’ like figure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;codepen-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Codepen example&lt;/h1&gt;
&lt;p&gt;As a starting place, I focused on animating an eye that would track a user that looked at it&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;strong&gt;Here is my first draft:&lt;/strong&gt;
&lt;div class=&#34;iframe-container&#34;&gt;
&lt;p&gt;&lt;iframe width=&#34;100%&#34; src=&#34;https://www.youtube.com/embed/UPAgQxaDDCo&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;If you want to set it up:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a Chrome browser and enable &lt;a href=&#34;chrome://flags/#enable-experimental-web-platform-features&#34;&gt;experimental web platform features&lt;/a&gt; (currently only works on Chrome and does not yet work on Android, iOS, or Linux)&lt;/li&gt;
&lt;li&gt;Go to my &lt;a href=&#34;https://codepen.io/brshallo/full/qBbyrLg&#34;&gt;codepen&lt;/a&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Allow use of webcam when prompted&lt;/li&gt;
&lt;li&gt;For a better view, ensure you are on the ‘Results’ tab and press the F11 key to hide the browser bar&lt;/li&gt;
&lt;li&gt;You will likely need to refresh when opening or when resizing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you want to use it to creep out the family members you are locked at home with, see the &lt;a href=&#34;#additional-actions&#34;&gt;Additional actions&lt;/a&gt; section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-i-made-it&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How I made it&lt;/h1&gt;
&lt;p&gt;To get the video and initial face detection set-up, I copied code from &lt;a href=&#34;https://github.com/wesbos/beginner-javascript/tree/764f0d589e6affeda2c0b6f17874311188de0d57/exercises/55%20-%20Face%20Detection%20Censorship&#34;&gt;this github repo&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/wesbos&#34;&gt;Wes Bos&lt;/a&gt;. To animate the eye I used an html5 canvas element and JavaScript. The eye simply follows your position in the video. Though I did a few things to make the eye movement look more interesting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rather than updating with every frame, it estimates your position based on the moving average of 10 frames, this makes the movement appear more smooth and softens the jitters of the algorithm constantly updating its estimate of your position.&lt;/li&gt;
&lt;li&gt;I used some trigonometry to soften the tracking so that the pupil’s movement would look more realistic at a distance.&lt;/li&gt;
&lt;li&gt;I also have the components of the eye slightly change shape and turn in or out depending on your position.&lt;/li&gt;
&lt;li&gt;However this is very much still a work in progress&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; – fixing the eye tracking is the major focus area for &lt;a href=&#34;#next-steps&#34;&gt;Next steps&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next steps&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Improve position mapping:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using estimates of the length of facial landmarks, you can estimate the distance someone is from the screen. See relevant project on &lt;a href=&#34;https://github.com/philiiiiiipp/Android-Screen-to-Face-Distance-Measurement&#34;&gt;github&lt;/a&gt;&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;. Once you have an estimate of someone’s position, you can more accurately adjust the animation so that the eye looks like it is following the user through space&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. Here is a ‘back of the napkin’ sketch of my mental model for the problem:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-07-20-animate-interactive-objects-with-face-detection-javascript-and-chrome-browser_files/back-of-napkin-eyeball.jpg&#34; alt=&#34;Diagram of key location points for animating eyeball with reference to a user.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Diagram of key location points for animating eyeball with reference to a user.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Once you have an estimate of the distance a face is from the camera, the important points for the projection of the eye to a 2d animation can be filled-in (with just a little bit of trigonometry). Ultimately I’d love to do something like can be found at this &lt;a href=&#34;https://github.com/evermeer/EVFaceTracker&#34;&gt;github repo&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/evermeer/EVFaceTracker/raw/master/EVFaceTracker.gif?raw=true&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
Or picture a digital version of the creepy t-rex meme that was going around:
&lt;div class=&#34;iframe-container&#34;&gt;
&lt;p&gt;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/A4QcyW-qTUg?start=9&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;but tailored to where the user is standing. However this may be limited&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;, also the view would be tailored to a single user&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Improve everything else:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The above improvements would require a great deal more sophistication in the animation. I’d also like to improve the code quality. All of these &lt;a href=&#34;#next-steps&#34;&gt;Next steps&lt;/a&gt; are largely aspirational – this project is &lt;em&gt;far removed&lt;/em&gt; from my day job and I am inexperienced in much of the underlying technologies / software. Hence I’m unsure when I’ll pick this back-up&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-path-and-resources&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Learning path and resources&lt;/h1&gt;
&lt;p&gt;My initial plan (for building the eye tracking component) was to use the python bindings for OpenCV&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt; for the face detection. I would then use the open source video editing software, &lt;em&gt;Blender&lt;/em&gt; (which can also run python scripts) to overlay an animation&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;. See &lt;a href=&#34;https://www.youtube.com/watch?v=O7nNO3FLkLU&#34;&gt;example&lt;/a&gt; where someone uses webcam and Blender to demo their face animations on a character. A problem with this approach is that Blender is not a light-weight application. Hence I wasn’t sure how I would easily deploy it… so I investigated alternative approaches.&lt;/p&gt;
&lt;p&gt;Near the end of &lt;a href=&#34;https://www.youtube.com/watch?v=8p5SDI4TNDc&#34;&gt;this presentation&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/cassiecodes?lang=en&#34;&gt;Cassie Evans&lt;/a&gt; on making interactive SVG images is where I learned about Google Chrome’s experimental shape detection API. I then found Wes Bos’s tweet on the subject.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
😮 Did you know Chrome has a FaceDetector API? &lt;a href=&#34;https://t.co/wSwDdI8p1u&#34;&gt;pic.twitter.com/wSwDdI8p1u&lt;/a&gt;
&lt;/p&gt;
— Wes Bos (&lt;span class=&#34;citation&#34;&gt;@wesbos&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/wesbos/status/976097163834019842?ref_src=twsrc%5Etfw&#34;&gt;March 20, 2018&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;I decided to go this route because of the relative simplicity of the shape detection API and the ease with which I could then deploy a first draft through a Chrome browser. &lt;em&gt;A problem&lt;/em&gt; was that I needed to learn some web development (or at least JavaScript) basics.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Preliminary learning resources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;About 40% of the videos/exercises from the first three courses of &lt;a href=&#34;https://www.coursera.org/specializations/web-design#courses&#34;&gt;University of Michigan’s Web Design series on coursera&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/ColleenAtUMSI&#34;&gt;Colleen van Lent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The first few chapters of &lt;a href=&#34;https://learn.shayhowe.com/html-css/building-your-first-web-page/&#34;&gt;Learn to Code HTML &amp;amp; CSS&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/shayhowe&#34;&gt;Shay Howe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Most of the &lt;a href=&#34;https://www.youtube.com/watch?v=EO6OkltgudE&amp;amp;list=PLpPnRKq7eNW3We9VdCfx9fprhqXHwTPXL&#34;&gt;tutorials on HTML5 canvas&lt;/a&gt; elements by &lt;a href=&#34;https://twitter.com/chriscourses?lang=en&#34;&gt;Chris Courses&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rather than using SVG’s, I ended-up just using a canvas element and JavaScript&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-thoughts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Closing thoughts&lt;/h1&gt;
&lt;p&gt;Try it out or consider ways you can make something engaging or surprising for users. If you do, please let me know at &lt;a href=&#34;https://twitter.com/brshallo&#34;&gt;brshallo&lt;/a&gt; on Twitter 😄.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;p&gt;Associated Twitter post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
New addition to the livingroom, giant eyeball that follows you around when you look at it.&lt;br&gt;&lt;br&gt;See blog on how I made it using &lt;a href=&#34;https://twitter.com/chrome?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@chrome&lt;/span&gt;&lt;/a&gt; browser&#39;s &lt;a href=&#34;https://twitter.com/hashtag/FaceDetection?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#FaceDetection&lt;/a&gt; api and &lt;a href=&#34;https://twitter.com/hashtag/JavaScript?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#JavaScript&lt;/a&gt; : &lt;a href=&#34;https://t.co/S993yWZEpn&#34;&gt;https://t.co/S993yWZEpn&lt;/a&gt; &lt;a href=&#34;https://t.co/1ebjaGmPzC&#34;&gt;pic.twitter.com/1ebjaGmPzC&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1285394365855211520?ref_src=twsrc%5Etfw&#34;&gt;July 21, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;additional-actions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional actions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ensure there is &lt;em&gt;good&lt;/em&gt; lighting, tracking tends to get jumpy at a distance (honestly only works so-so at this point)&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Plug device into a TV or larger display&lt;/li&gt;
&lt;li&gt;Get the camera lined-up (ideally is close to eye-level)&lt;/li&gt;
&lt;li&gt;Call your loved one into the room and wait for them to notice and start interacting with the giant eye ball that is following them&lt;/li&gt;
&lt;li&gt;For &lt;em&gt;bonus&lt;/em&gt; points capture it on video and tweet it at me or with an appropriate hashtag (e.g. #eyeseeyou)&lt;/li&gt;
&lt;li&gt;For &lt;em&gt;bonus&lt;/em&gt; bonus points, edit (or improve) the code and make some fun new animation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Maybe also Peloton, car display, watch, Mirror… (if you’re fancy).&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Similarly, picture a portrait whose eyes follow you as you walk-by – similar to Mark Rober’s [video] (&lt;a href=&#34;https://www.youtube.com/watch?v=sPgKu2E-jdw&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=sPgKu2E-jdw&lt;/a&gt;), but tracking you automatically.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;And that could be easily shared across devices.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;This is my first project using JavaScript (don’t expect much when it comes to code quality).&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;There are errors and most of the math here is almost nonsensical.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;For my use-case though I may use face height rather than (or in addition to) face width – as cannot trust that people will be turned towards my camera and figure it is less likely they will tilt their head.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Though may be somewhat limited as a user has two eyes, not just one, so depth illusion might not work perfectly.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Afterall, we’re not working with holograms or special glasses.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;The animation would become distorted for users other than the individual the animation is tracking.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;But wanted to at least post this first draft&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Open Computer Vision&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;Or some python animation library I might be able to find.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Again, don’t expect much when it comes to code quality.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;Perhaps will fix / improve in future.&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Short Examples of Best Practices When Writing Functions That Call dplyr Verbs</title>
      <link>/2020/06/25/using-across-to-build-functions-with-dplyr-with-notes-on-legacy-approaches/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/25/using-across-to-build-functions-with-dplyr-with-notes-on-legacy-approaches/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#function-expecting-one-column&#34;&gt;Function expecting one column&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#functions-allowing-multiple-columns&#34;&gt;Functions allowing multiple columns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#older-approaches&#34;&gt;Older approaches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tidyverse/dplyr&#34;&gt;dplyr&lt;/a&gt;, the foundational &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; package, makes a trade-off between being easy to code in interactively at the expense of being more difficult to create functions with. The source of the trade-off is in how &lt;code&gt;dplyr&lt;/code&gt; evaluates column names (specifically, allowing for unquoted column names as argument inputs). Tidy evaluation has been under major development the last couple of years in order to make &lt;a href=&#34;https://dplyr.tidyverse.org/articles/programming.html&#34;&gt;programming with dplyr&lt;/a&gt; easier.&lt;/p&gt;
&lt;p&gt;During this development, there have been a variety of proposed methods for programming with &lt;code&gt;dplyr&lt;/code&gt;. In this post, I will document the current ‘best-practices’ with &lt;code&gt;dplyr&lt;/code&gt; 1.0.0. In the &lt;a href=&#34;#older-approaches&#34;&gt;Older approaches&lt;/a&gt; section I provide analogous examples that someone (i.e. myself) might have used during this maturation period.&lt;/p&gt;
&lt;p&gt;For a more full discussion on this topic see &lt;code&gt;dplyr&lt;/code&gt;’s documentation at &lt;a href=&#34;https://dplyr.tidyverse.org/articles/programming.html&#34;&gt;programming with dplyr&lt;/a&gt; and the various links referenced there.&lt;/p&gt;
&lt;div id=&#34;function-expecting-one-column&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Function expecting one column&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pretend we want to create a function that calculates the sum of a given variable in a dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_var &amp;lt;- function(df, var){
  
  summarise(df, {{var}} := sum({{var}}))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To run this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_vars(mpg, cty)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you wanted to edit the variable in place and avoid using the special assignment operator &lt;code&gt;:=&lt;/code&gt;, you could use the new (in &lt;code&gt;dplyr&lt;/code&gt; 1.0.0) &lt;code&gt;across()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_vars &amp;lt;- function(df, vars){
  
  summarise(df, across({{vars}}, sum))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;functions-allowing-multiple-columns&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Functions allowing multiple columns&lt;/h1&gt;
&lt;p&gt;Using the &lt;code&gt;across()&lt;/code&gt; approach also allows you to input more than one variable, e.g. a user could call the following to get summaries on both &lt;code&gt;cty&lt;/code&gt; and &lt;code&gt;hwy&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_vars(mpg, c(cty, hwy))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you wanted to compute multiple column summaries with different functions and you wanted to glue the function name onto your outputted column names&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, you could instead pass a named list of functions into the &lt;code&gt;.fns&lt;/code&gt; argument of &lt;code&gt;across()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_vars &amp;lt;- function(df, vars){
  
  summarise(df, across({{vars}}, list(sum = sum, mean = mean)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might want to create a function that can take in multiple sets of columns, e.g. the function below allows you to &lt;code&gt;group_by()&lt;/code&gt; one set of variables and &lt;code&gt;summarise()&lt;/code&gt; another set:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_group_vars &amp;lt;- function(df, group_vars, sum_vars){
  df %&amp;gt;% 
    group_by(across({{group_vars}})) %&amp;gt;% 
    summarise(across({{sum_vars}}, list(sum = sum, mean = mean)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How a user would run &lt;code&gt;sum_group_vars()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_group_vars(mpg,
               c(model, year), 
               c(hwy, cty))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re feeling fancy, you could also make the input to &lt;code&gt;.fns&lt;/code&gt; an argument to &lt;code&gt;sum_group_vars()&lt;/code&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;older-approaches&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Older approaches&lt;/h1&gt;
&lt;p&gt;Generally, I find the new &lt;code&gt;across()&lt;/code&gt; approaches introduced in &lt;code&gt;dplyr&lt;/code&gt; 1.0.0 are easier and more consistent to use than the methods that preceded them. However the methods in this section still work and are supported. They are just no longer the ‘recommended’ or most ‘modern’ approach available for creating functions that pass column names into &lt;code&gt;dplyr&lt;/code&gt; verbs.&lt;/p&gt;
&lt;p&gt;Prior to the introduction of the &lt;em&gt;bracket-bracket&lt;/em&gt;, &lt;code&gt;{{}}&lt;/code&gt;, you would have used the &lt;em&gt;&lt;code&gt;enquo()&lt;/code&gt; + bang-bang&lt;/em&gt; approach&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. The function below is equivalent to the &lt;code&gt;sum_var()&lt;/code&gt; function shown at the start of this post.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_var &amp;lt;- function(df, var){
  var_quo &amp;lt;- enquo(var)
  summarise(df, !!var_quo := sum(!!var_quo))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To modify variables in-place you would have used the &lt;code&gt;*_at()&lt;/code&gt;, &lt;code&gt;*_if()&lt;/code&gt; or &lt;code&gt;*_all()&lt;/code&gt; function variants (which are now superseded by &lt;code&gt;across()&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_vars &amp;lt;- function(df, vars){
  
  summarise_at(df, {{vars}}, sum)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similar to using &lt;code&gt;across()&lt;/code&gt; this method allows multiple variables being input. However what is weird about this function is that it requires the user wrapping the variable names in &lt;code&gt;vars()&lt;/code&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. Hence to use the previously created function, a user would run:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_vars(mpg, vars(hwy, cty))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively, you could have the variable name inputs be character vectors by modifying the function like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_var &amp;lt;- function(df, vars){
  
  summarise_at(df, vars(one_of(vars)), sum)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which could be called by a user as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_var(mpg, c(&amp;quot;hwy&amp;quot;, &amp;quot;cty&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These &lt;code&gt;*_at()&lt;/code&gt; variants also support inputting a list of functions, e.g. the below function would output both the sums and means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_var &amp;lt;- function(df, var){
  
  summarise_at(df, vars(one_of(var)), list(sum = sum, mean = mean))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For multiple grouping variables and multiple variables to be summarised you could create:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;groupsum &amp;lt;- function(df, group_vars, sum_vars){
  df %&amp;gt;% 
    group_by_at(vars(one_of(group_vars))) %&amp;gt;% 
    summarise_at(vars(one_of(sum_vars)), list(sum = sum, mean = mean))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which would be called by a user:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_var(mpg, 
        c(&amp;quot;model&amp;quot;, &amp;quot;year&amp;quot;), 
        c(&amp;quot;hwy&amp;quot;, &amp;quot;cty&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are a variety of similar spins you might take on handling tidy evaluation when creating these or similar types of functions.&lt;/p&gt;
&lt;p&gt;One other older approach perhaps worth mentioning (presented &lt;a href=&#34;https://rstudio.com/resources/rstudioconf-2019/working-with-names-and-expressions-in-your-tidy-eval-code/&#34;&gt;here&lt;/a&gt;) is “passing the dots”. Here is an example for if we want to &lt;code&gt;group_by()&lt;/code&gt; multiple columns and then &lt;code&gt;summarise()&lt;/code&gt; on just one column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum_group_var &amp;lt;- function(df, sum_var, ...){
  df %&amp;gt;% 
    group_by(...) %&amp;gt;% 
    summarise({{sum_var}} := sum({{sum_var}}))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The limitation with this approach is that only one set of your inputs can have more than one variable in it, i.e. wherever you pass the &lt;code&gt;...&lt;/code&gt; in your function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;p&gt;Image shared on social media was created using &lt;code&gt;xaringan&lt;/code&gt; and &lt;code&gt;flair&lt;/code&gt;. See &lt;a href=&#34;https://github.com/brshallo/dplyr-1.0.0-example&#34;&gt;dplyr-1.0.0-example&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/brshallo/dplyr-1.0.0-example/blob/master/dplyr-example-cropped.png?raw=true&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;code&gt;dplyr&lt;/code&gt; 1.0.0 also now has &lt;a href=&#34;https://www.tidyverse.org/blog/2020/02/glue-strings-and-tidy-eval/&#34;&gt;support for using the glue&lt;/a&gt; package syntax for modifying variable names.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Doing this doesn’t require any tidy evaluation knowledge&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;There is also the &lt;code&gt;rlang::enquos()&lt;/code&gt; and &lt;code&gt;!!!&lt;/code&gt; operator for when the input has length greater than one.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;A niche function specific to tidy evaluation (which users might not think of).&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Use Flipbooks to Explain Your Code and Thought Process</title>
      <link>/2020/06/24/use-flipbooks-to-explain-your-code-and-thought-process/</link>
      <pubDate>Wed, 24 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/24/use-flipbooks-to-explain-your-code-and-thought-process/</guid>
      <description>


&lt;div id=&#34;learning-rs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Learning R’s &lt;code&gt;%&amp;gt;%&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Using the pipe operator (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) is one of my favorite things about coding in R and the &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt;. However when it was first shown to me, I couldn’t understand what the &lt;a href=&#34;https://twitter.com/search?q=%23rstats&amp;amp;src=typed_query&#34;&gt;#rstats&lt;/a&gt; nut describing it was &lt;em&gt;so enthusiastic&lt;/em&gt; about. They tried to explain, “It means &lt;em&gt;and then&lt;/em&gt; do the next operation.” When that didn’t click for me, they continued (while becoming ever more excited) “It &lt;em&gt;passes the previous steps output into the first argument&lt;/em&gt; of the next function,” still… 😐😐😕.
Self-evident verbs in their code like &lt;code&gt;select()&lt;/code&gt;, &lt;code&gt;filter()&lt;/code&gt;, &lt;code&gt;summarise()&lt;/code&gt; helped me nod along, partly following the operations. Though it wasn’t until I evaluated the code &lt;em&gt;line-by-line&lt;/em&gt; that I recognized the pipe’s elegance, power, beauty, simplicity 😄!&lt;/p&gt;
&lt;p&gt;Now, a few years and reads through &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt; later&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, I will often share my work by keeping the code and output together and showing, line-by-line, what I am building towards. For example when…&lt;/p&gt;
&lt;p&gt;… giving a 2019 talk on &lt;em&gt;“Managing objects in analytics workflows, using lists as columns in dataframes”&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/gme4Fb9JVjk?start=258&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/blockquote&gt;
&lt;p&gt;… giving a 2017 talk on &lt;em&gt;“Getting started with ‘tidy’ data science in R”&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/eeCELJNWEuw?start=474&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;/blockquote&gt;
&lt;p&gt;… promoting a recent blog post on &lt;em&gt;“Tidy pairwise operations”&lt;/em&gt; (though in this case I removed the code):&lt;/p&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
What is your &lt;a href=&#34;https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#tidyverse&lt;/a&gt; (or other &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; ) approach for doing arbitrary pairwise operations across variables? Mine is frequently something like:&lt;br&gt;&lt;br&gt;I. nest…&lt;br&gt;II. expand combos… &lt;br&gt;III. filter…&lt;br&gt;IV. map fun(s)…&lt;br&gt;…&lt;br&gt;&lt;br&gt;I wrote a post walking through this: &lt;a href=&#34;https://t.co/xRnRf5yh3m&#34;&gt;https://t.co/xRnRf5yh3m&lt;/a&gt; &lt;a href=&#34;https://t.co/Zvxey2gm3H&#34;&gt;pic.twitter.com/Zvxey2gm3H&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1271194908477591553?ref_src=twsrc%5Etfw&#34;&gt;June 11, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;p&gt;However each of these examples were built using PowerPoint (and a lot of copy and pasting of code + output). The series of images cannot be easily reproduced. In this post I’ll point to resources on how to create these sorts of code communication materials in ways that &lt;em&gt;are reproducible&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;flipbooks&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Flipbooks&lt;/h1&gt;
&lt;p&gt;When I started writing this post, I planned to call this type of output a “&lt;strong&gt;LEXPREX&lt;/strong&gt;” for “&lt;strong&gt;L&lt;/strong&gt;ine-by-line &lt;strong&gt;EX&lt;/strong&gt;ecution with &lt;strong&gt;PR&lt;/strong&gt;inted &lt;strong&gt;EX&lt;/strong&gt;amples” (and a name evocative of the inspiring &lt;a href=&#34;https://github.com/tidyverse/reprex&#34;&gt;reprex&lt;/a&gt; package by &lt;a href=&#34;https://twitter.com/JennyBryan%5D&#34;&gt;Jenny Bryan&lt;/a&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;). But, thankfully, an excellent solution containing thorough explanations (and a much better name) already existed, &lt;em&gt;flipbooks&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As described in the &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;flipbookr documentation&lt;/a&gt;, “flipbooks are tools that present side-by-side, aligned, incremental code-output.”&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://github.com/brshallo/flipbookr-gifs-examples/raw/master/example-r4ds.gif?raw=true&#34; alt=&#34;(Example inspired by ‘Many Models’ chapter of ‘R For Data Science’ by Grolemund &amp;amp; Wickham.)&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;(Example inspired by ‘Many Models’ chapter of ‘R For Data Science’ by Grolemund &amp;amp; Wickham.)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;At this point you should stop reading this blog and instead go learn about &lt;a href=&#34;https://github.com/EvaMaeRey/flipbookr&#34;&gt;flipbookr&lt;/a&gt;. My post was largely written before I learned about this package. Hence, starting at &lt;a href=&#34;https://rstudio.com/resources/rstudioconf-2020/flipbooks-evangeline-reynolds/&#34;&gt;this presentation&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/EvaMaeRey&#34;&gt;Gina Reynolds&lt;/a&gt; or &lt;code&gt;flipbookr&lt;/code&gt;’s &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;about page&lt;/a&gt; will generally be a more productive use of your time. The remainder of this post discusses either tools adjacent to flipbooks or describes workflows that can also be found within &lt;code&gt;flipbookr&lt;/code&gt; documentation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-with-xaringan&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example with xaringan&lt;/h1&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/yihui/xaringan&#34;&gt;xaringan&lt;/a&gt; package for making slideshows contains highlighting features (and is what &lt;code&gt;flipbookr&lt;/code&gt; is built-on). For highlighting &lt;em&gt;code&lt;/em&gt; you can use the trailing comment &lt;code&gt;#&amp;lt;&amp;lt;&lt;/code&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. For highlighting &lt;em&gt;output&lt;/em&gt; there is the &lt;code&gt;highlight.output&lt;/code&gt; code chunk option.&lt;/p&gt;
&lt;blockquote&gt;
&lt;iframe src=&#34;https://slides.yihui.org/xaringan/#31&#34; style=&#34;width: 560px; height: 315px;&#34;&gt;
&lt;/iframe&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/mitchoharawild&#34;&gt;Mitchell O’Hara-Wild&lt;/a&gt;’s 2019 presentation on &lt;em&gt;“Flexible futures for &lt;a href=&#34;https://github.com/tidyverts/fable&#34;&gt;fable&lt;/a&gt; functionality”&lt;/em&gt; contains a helpful example where he uses these features to walk-through &lt;a href=&#34;https://github.com/mitchelloharawild/fable-combinations-2019/blob/6a55628e1ad156c0040676b7881a799f7f75370a/user2019/index.Rmd&#34;&gt;his code&lt;/a&gt;.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/DhDOTxojQ3k?start=554&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;See &lt;a href=&#34;#more-sophisticated-highlighting&#34;&gt;More sophisticated highlighting&lt;/a&gt; if your use-case requires more than line-level highlighting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animating-a-flipbook&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Animating a flipbook&lt;/h1&gt;
&lt;p&gt;I sometimes want to convert a flipbook into a gif, e.g. when sharing an example in a README or a snippet of a concept on social media. If you ignored my prior entreaty, this is a second reminder to stop and go read about &lt;code&gt;flipbookr&lt;/code&gt;. The &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;template file&lt;/a&gt; now shows how to create gifs using &lt;code&gt;flipbookr&lt;/code&gt; (html) –&amp;gt; &lt;code&gt;pagedown&lt;/code&gt; (pdf) –&amp;gt; &lt;code&gt;magick&lt;/code&gt; (gif). I also describe this workflow and provide examples &lt;a href=&#34;https://github.com/brshallo/flipbookr-gifs-examples&#34;&gt;here&lt;/a&gt;, e.g.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://github.com/brshallo/flipbookr-gifs-examples/raw/master/example-riddler-solution.gif&#34; alt=&#34;(Example from a prior blog post, “Riddler Solutions: Pedestrian Puzzles”)&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;(Example from a prior blog post, “Riddler Solutions: Pedestrian Puzzles”)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-note&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Closing note&lt;/h1&gt;
&lt;p&gt;I recommend exploring the &lt;a href=&#34;https://education.rstudio.com/blog/&#34;&gt;Rstudio Education blog&lt;/a&gt;. The site contains helpful resources for improving your technical communication. It was here that I stumbled on the post &lt;a href=&#34;https://education.rstudio.com/blog/2020/05/flair/&#34;&gt;Decorate your R code with flair&lt;/a&gt;. Reading this inspired me to make a first attempt at building a reproducible animation of line-by-line execution of R code (something I’d been wanting to do for ages). The positive response &amp;amp; feedback to my initial tweet led me to learn about &lt;code&gt;flipbookr&lt;/code&gt; and motivated additional actions (described in &lt;a href=&#34;#engagement-contributions&#34;&gt;Engagement &amp;amp; contributions&lt;/a&gt;) including the review and completion of this blog post.&lt;/p&gt;
&lt;p&gt;Finally, please go enjoy the beautiful examples you can find at the &lt;code&gt;flipbookr&lt;/code&gt; &lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;about page&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://evamaerey.github.io/flipbooks/about&#34;&gt;&lt;img src=&#34;/post/2020-06-16-use-flipbooks-to-explain-your-code-and-thought-process_files/flipbookr-example.gif&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;more-sophisticated-highlighting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More sophisticated highlighting&lt;/h2&gt;
&lt;p&gt;For more sophisticated highlighting of &lt;em&gt;code&lt;/em&gt;, use the &lt;a href=&#34;https://github.com/kbodwin/flair&#34;&gt;flair package&lt;/a&gt;. I’m not sure what to recommend for highlighting changes in &lt;em&gt;output&lt;/em&gt; to the console… perhaps &lt;a href=&#34;https://github.com/brodieG/diffobj&#34;&gt;diffobj&lt;/a&gt; would be an option. You could also just explicitly format the output, e.g. using &lt;a href=&#34;https://github.com/rstudio/gt&#34;&gt;gt&lt;/a&gt; or &lt;a href=&#34;https://github.com/haozhu233/kableExtra&#34;&gt;kableExtra&lt;/a&gt; for tabular outputs, or using geoms, annotations, etc. in &lt;a href=&#34;https://github.com/tidyverse/ggplot2&#34;&gt;ggplot&lt;/a&gt;s. And, of course, you can always dive into the html.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;engagement-contributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Engagement &amp;amp; contributions&lt;/h2&gt;
&lt;p&gt;Blogging is time consuming. Reaching out to package maintainers or making contributions (even small ones) on open-source software projects can be intimidating. As a &lt;em&gt;tiny&lt;/em&gt; success story, I documented actions that stemmed (in some part) from engaging with the #rstats online communities while working on this blog post topic:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;While this post was in draft form, I tweeted out my initial approach (that used the &lt;a href=&#34;https://github.com/kbodwin/flair&#34;&gt;flair&lt;/a&gt; package).
&lt;ul&gt;
&lt;li&gt;The next step might have been trying to improve upon this. Thankfully, instead, &lt;a href=&#34;https://twitter.com/KellyBodwin&#34;&gt;Kelly Bodwin&lt;/a&gt; pointed me to &lt;code&gt;flipbookr&lt;/code&gt;!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
P.S. &lt;br&gt;&lt;br&gt;The &lt;code&gt;flair_lines()&lt;/code&gt; function lets you highlight whole line(s) if you want! &lt;br&gt;&lt;br&gt;{flipbookr} is a better option for making gifs/slides like this, but {flair} + {pagedown} + {magick} might help if you want specialty or layered highlighting.
&lt;/p&gt;
— Kelly Bodwin (&lt;span class=&#34;citation&#34;&gt;@KellyBodwin&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/KellyBodwin/status/1272741205365764097?ref_src=twsrc%5Etfw&#34;&gt;June 16, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Kelly also created an &lt;a href=&#34;https://github.com/kbodwin/flair/issues/15&#34;&gt;issue&lt;/a&gt; to further discuss possible integrations between &lt;code&gt;flair&lt;/code&gt; and &lt;code&gt;flipbookr&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I remade my initial example using &lt;code&gt;flipbookr&lt;/code&gt; (&lt;a href=&#34;https://github.com/EvaMaeRey/flipbookr/issues/22&#34;&gt;see issue&lt;/a&gt;).
&lt;ul&gt;
&lt;li&gt;I first created an &lt;a href=&#34;https://github.com/EvaMaeRey/flipbookr/issues/21&#34;&gt;issue&lt;/a&gt; showing how to print &lt;code&gt;xaringan&lt;/code&gt; slides incrementally using &lt;code&gt;pagedown::chrome_print()&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;Which helped to close a related &lt;a href=&#34;https://github.com/rstudio/pagedown/issues/110&#34;&gt;issue&lt;/a&gt; on &lt;code&gt;xaringan&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Gina Reynolds made a variety of updates to &lt;code&gt;flipbookr&lt;/code&gt;, one of which included adding the html –&amp;gt; pdf –&amp;gt; gif workflow to the template 😄.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Big thanks to &lt;a href=&#34;https://twitter.com/grrrck?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@grrrck&lt;/span&gt;&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/statsgen?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@statsgen&lt;/span&gt;&lt;/a&gt; for helps and &lt;a href=&#34;https://twitter.com/xieyihui?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@xieyihui&lt;/span&gt;&lt;/a&gt; because {xaringan}! And to &lt;a href=&#34;https://twitter.com/brshallo?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/KellyBodwin?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@KellyBodwin&lt;/span&gt;&lt;/a&gt; for new ideas about how to share flipbooks, html -&amp;gt; pdf -&amp;gt; gif. Guidance now included in template update on this - this gif created w/ that workflow!🙏🤩
&lt;/p&gt;
— Gina Reynolds (&lt;span class=&#34;citation&#34;&gt;@EvaMaeRey&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/EvaMaeRey/status/1274837474460626945?ref_src=twsrc%5Etfw&#34;&gt;June 21, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;See my notes and solutions &lt;a href=&#34;https://brshallo.github.io/r4ds_solutions/&#34;&gt;here&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I also considered names such as &lt;code&gt;pexprex&lt;/code&gt;, &lt;code&gt;sexprex&lt;/code&gt;, &lt;code&gt;pripex&lt;/code&gt;, … I’ll let the reader guess at the acronyms.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Which I prefer over the alternatives of using the leading &lt;code&gt;*&lt;/code&gt; or wrapping the message in&lt;code&gt;{{}}&lt;/code&gt;.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tidy Pairwise Operations</title>
      <link>/2020/06/03/tidy-2-way-column-combinations/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/06/03/tidy-2-way-column-combinations/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#i.-nest-and-pivot&#34;&gt;I. Nest and pivot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ii.-expand-combinations&#34;&gt;II. Expand combinations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#iii.-filter-redundancies&#34;&gt;III. Filter redundancies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#iv.-map-functions&#34;&gt;IV. Map function(s)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#v.-return-to-normal-dataframe&#34;&gt;V. Return to normal dataframe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vi.-bind-back-to-data&#34;&gt;VI. Bind back to data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#functionalize&#34;&gt;Functionalize&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-creating-evaluating-features&#34;&gt;Example creating &amp;amp; evaluating features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#when-is-this-approach-inappropriate&#34;&gt;When is this approach inappropriate?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#interactions-example-tidymodels&#34;&gt;Interactions example, tidymodels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expand-via-join&#34;&gt;Expand via join&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nested-tibbles&#34;&gt;Nested tibbles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pivot-and-then-summarise&#34;&gt;Pivot and then summarise&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#gif-for-social-media&#34;&gt;Gif for social media&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tweets&#34;&gt;Tweets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#session-info&#34;&gt;Session info&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;Say you want to map an operation or list of operations across all two-way&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; combinations of a set of variables/columns in a dataframe. For example, you may be doing feature engineering and want to create a set of interaction terms, ratios, etc&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. You may be interested in computing a summary statistic across all pairwise combinations of a given set of variables&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. In some cases there may be a pairwise implementation already available, e.g. R’s &lt;code&gt;cor()&lt;/code&gt; function for computing correlations&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. In other cases one may not exist or is not easy to use&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;. In this post I’ll walk through an example&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; explaining code and steps for setting-up arbitrary pairwise operations across sets of variables.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I’ll break my approach down into several steps:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I. Nest and pivot&lt;br /&gt;
II. Expand combinations&lt;br /&gt;
III. Filter redundancies&lt;br /&gt;
IV. Map function(s)&lt;br /&gt;
V. Return to normal dataframe&lt;br /&gt;
VI. Bind back to data&lt;/p&gt;
&lt;p&gt;If your interest is only in computing summary statistics (as opposed to modifying an existing dataframe with new columns / features), then only steps I - IV are needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevant software and style:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I will primarily be using R’s &lt;code&gt;tidyverse&lt;/code&gt; packages. I make frequent use of lists as columns within dataframes – if you are new to these, see my previous &lt;a href=&#34;https://www.youtube.com/watch?v=gme4Fb9JVjk&#34;&gt;talk&lt;/a&gt; and the resources&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; I link to in the description.&lt;/p&gt;
&lt;p&gt;Throughout this post, wherever I write “dataframe” I really mean “tibble” (a dataframe with minor changes to default options and printing behavior). Also note that I am using &lt;code&gt;dplyr&lt;/code&gt; 0.8.3 rather than the newly released 1.0.0&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other resources and open issues (updated 2020-06-14):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In particular, the comments in issue &lt;a href=&#34;https://github.com/tidymodels/corrr/issues/44&#34;&gt;44&lt;/a&gt; for the &lt;code&gt;corrr&lt;/code&gt; package contain excellent solutions for doing pairwise operations (the subject of this post)&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. Issue &lt;a href=&#34;https://github.com/tidymodels/corrr/issues/94&#34;&gt;94&lt;/a&gt; also features discussion on this topic. Throughout this post I will reference other alternative code/approaches (especially in the footnotes and the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I’ll use the ames housing dataset across examples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames &amp;lt;- AmesHousing::make_ames()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Specifically, I’ll focus on ten numeric columns that, based on a random sample of 1000 rows, show the highest correlation with &lt;code&gt;Sale_Price&lt;/code&gt;&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

set.seed(2020)
ames_cols &amp;lt;- ames %&amp;gt;% 
  select_if(is.numeric) %&amp;gt;% 
  sample_n(1000) %&amp;gt;% 
  corrr::correlate() %&amp;gt;% 
  corrr::focus(Sale_Price) %&amp;gt;% 
  arrange(-abs(Sale_Price)) %&amp;gt;% 
  head(10) %&amp;gt;% 
  pull(rowname)

ames_subset &amp;lt;- select(ames, ames_cols) %&amp;gt;% 
  # Could normalize data or do other prep 
  # but is not pertinent for examples
  mutate_all(as.double)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;i.-nest-and-pivot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I. Nest and pivot&lt;/h2&gt;
&lt;p&gt;There are a variety of ways to make lists into columns within a dataframe. In the example below, I first use &lt;code&gt;summarise_all(.tbl = ames_subset, .funs = list)&lt;/code&gt; to create a one row dataframe where each column is a list containing a single element and each individual element corresponds with a numeric vector of length 2930.&lt;/p&gt;
&lt;p&gt;After nesting, I pivot&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt; the columns leaving a dataframe with two columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;var&lt;/code&gt; the variable names&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vector&lt;/code&gt; a list where each element contains the associated vector&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_lists &amp;lt;- ames_subset %&amp;gt;% 
  summarise_all(list) %&amp;gt;% 
  pivot_longer(cols = everything(), 
               names_to = &amp;quot;var&amp;quot;, 
               values_to = &amp;quot;vector&amp;quot;) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 2
##    var            vector       
##    &amp;lt;chr&amp;gt;          &amp;lt;list&amp;gt;       
##  1 Gr_Liv_Area    &amp;lt;dbl [2,930]&amp;gt;
##  2 Garage_Cars    &amp;lt;dbl [2,930]&amp;gt;
##  3 Garage_Area    &amp;lt;dbl [2,930]&amp;gt;
##  4 Total_Bsmt_SF  &amp;lt;dbl [2,930]&amp;gt;
##  5 First_Flr_SF   &amp;lt;dbl [2,930]&amp;gt;
##  6 Year_Built     &amp;lt;dbl [2,930]&amp;gt;
##  7 Full_Bath      &amp;lt;dbl [2,930]&amp;gt;
##  8 Year_Remod_Add &amp;lt;dbl [2,930]&amp;gt;
##  9 TotRms_AbvGrd  &amp;lt;dbl [2,930]&amp;gt;
## 10 Fireplaces     &amp;lt;dbl [2,930]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See &lt;a href=&#34;#pivot-and-then-summarise&#34;&gt;Pivot and then summarise&lt;/a&gt; for a nearly identical approach with just an altered order of steps. Also see &lt;a href=&#34;#nested-tibbles&#34;&gt;Nested tibbles&lt;/a&gt; for how you could create a list-column of dataframes&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt; rather than vectors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What if my variables are across rows not columns?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For example, pretend you want to see if &lt;code&gt;Sale_Price&lt;/code&gt; is different across &lt;code&gt;Mo_Sold&lt;/code&gt;. Perhaps you started by doing an F-test, found that to be significant, and now want to do pairwise t-tests across the samples of &lt;code&gt;Sale_Price&lt;/code&gt; for each &lt;code&gt;Mo_Sold&lt;/code&gt;. To set this up, you will want a &lt;code&gt;group_by()&lt;/code&gt; rather than a &lt;code&gt;pivot_longer()&lt;/code&gt; step. E.g.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames %&amp;gt;% 
  group_by(Mo_Sold) %&amp;gt;% 
  summarise(Sale_Price = list(Sale_Price)) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 12 x 2
##    Mo_Sold Sale_Price 
##      &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;     
##  1       1 &amp;lt;int [123]&amp;gt;
##  2       2 &amp;lt;int [133]&amp;gt;
##  3       3 &amp;lt;int [232]&amp;gt;
##  4       4 &amp;lt;int [279]&amp;gt;
##  5       5 &amp;lt;int [395]&amp;gt;
##  6       6 &amp;lt;int [505]&amp;gt;
##  7       7 &amp;lt;int [449]&amp;gt;
##  8       8 &amp;lt;int [233]&amp;gt;
##  9       9 &amp;lt;int [161]&amp;gt;
## 10      10 &amp;lt;int [173]&amp;gt;
## 11      11 &amp;lt;int [143]&amp;gt;
## 12      12 &amp;lt;int [104]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At which point your data is in fundamentally the same form as was created in the previous code chunk (at least for if we only care about computing summary metrics that don’t require vectors of equal length&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;) so you can move onto &lt;a href=&#34;#ii.-expand-combinations&#34;&gt;II. Expand combinations&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If the variables needed for your combinations of interest are across both rows and columns, you may want to use both &lt;code&gt;pivot_longer()&lt;/code&gt; and &lt;code&gt;group_by()&lt;/code&gt; steps and may need to make a few small modifications.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ii.-expand-combinations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;II. Expand combinations&lt;/h2&gt;
&lt;p&gt;I then use &lt;code&gt;tidyr::nesting()&lt;/code&gt; within &lt;code&gt;tidyr::expand()&lt;/code&gt; to make all 2-way combinations of our rows.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_lists_comb &amp;lt;- expand(df_lists,
                        nesting(var, vector),
                        nesting(var2 = var, vector2 = vector)) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 4
##    var        vector        var2           vector2      
##    &amp;lt;chr&amp;gt;      &amp;lt;list&amp;gt;        &amp;lt;chr&amp;gt;          &amp;lt;list&amp;gt;       
##  1 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Fireplaces     &amp;lt;dbl [2,930]&amp;gt;
##  2 Fireplaces &amp;lt;dbl [2,930]&amp;gt; First_Flr_SF   &amp;lt;dbl [2,930]&amp;gt;
##  3 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Full_Bath      &amp;lt;dbl [2,930]&amp;gt;
##  4 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Garage_Area    &amp;lt;dbl [2,930]&amp;gt;
##  5 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Garage_Cars    &amp;lt;dbl [2,930]&amp;gt;
##  6 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Gr_Liv_Area    &amp;lt;dbl [2,930]&amp;gt;
##  7 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Total_Bsmt_SF  &amp;lt;dbl [2,930]&amp;gt;
##  8 Fireplaces &amp;lt;dbl [2,930]&amp;gt; TotRms_AbvGrd  &amp;lt;dbl [2,930]&amp;gt;
##  9 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Year_Built     &amp;lt;dbl [2,930]&amp;gt;
## 10 Fireplaces &amp;lt;dbl [2,930]&amp;gt; Year_Remod_Add &amp;lt;dbl [2,930]&amp;gt;
## # ... with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See &lt;a href=&#34;#expand-via-join&#34;&gt;Expand via join&lt;/a&gt; for an alternative approach using the &lt;code&gt;dplyr::*_join()&lt;/code&gt; operations.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You could make a strong case that this step should be after &lt;a href=&#34;#iii.-filter-redundancies&#34;&gt;III. Filter redundancies&lt;/a&gt;&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;. However putting it beforehand makes the required code easier to write and to read.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;iii.-filter-redundancies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;III. Filter redundancies&lt;/h2&gt;
&lt;p&gt;Filter-out redundant columns, sort the rows, better organize the columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_lists_comb &amp;lt;- df_lists_comb %&amp;gt;% 
  filter(var != var2) %&amp;gt;% 
  arrange(var, var2) %&amp;gt;% 
  mutate(vars = paste0(var, &amp;quot;.&amp;quot;, var2)) %&amp;gt;% 
  select(contains(&amp;quot;var&amp;quot;), everything()) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 90 x 5
##    var          var2           vars                    vector       vector2     
##    &amp;lt;chr&amp;gt;        &amp;lt;chr&amp;gt;          &amp;lt;chr&amp;gt;                   &amp;lt;list&amp;gt;       &amp;lt;list&amp;gt;      
##  1 Fireplaces   First_Flr_SF   Fireplaces.First_Flr_SF &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  2 Fireplaces   Full_Bath      Fireplaces.Full_Bath    &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  3 Fireplaces   Garage_Area    Fireplaces.Garage_Area  &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  4 Fireplaces   Garage_Cars    Fireplaces.Garage_Cars  &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  5 Fireplaces   Gr_Liv_Area    Fireplaces.Gr_Liv_Area  &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  6 Fireplaces   Total_Bsmt_SF  Fireplaces.Total_Bsmt_~ &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  7 Fireplaces   TotRms_AbvGrd  Fireplaces.TotRms_AbvG~ &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  8 Fireplaces   Year_Built     Fireplaces.Year_Built   &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
##  9 Fireplaces   Year_Remod_Add Fireplaces.Year_Remod_~ &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
## 10 First_Flr_SF Fireplaces     First_Flr_SF.Fireplaces &amp;lt;dbl [2,930~ &amp;lt;dbl [2,930~
## # ... with 80 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your operation of interest is associative&lt;a href=&#34;#fn15&#34; class=&#34;footnote-ref&#34; id=&#34;fnref15&#34;&gt;&lt;sup&gt;15&lt;/sup&gt;&lt;/a&gt;, apply a filter to remove additional redundant combinations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c_sort_collapse &amp;lt;- function(...){
  c(...) %&amp;gt;% 
    sort() %&amp;gt;% 
    str_c(collapse = &amp;quot;.&amp;quot;)
}

df_lists_comb_as &amp;lt;- df_lists_comb %&amp;gt;% 
  mutate(vars = map2_chr(.x = var, 
                         .y = var2, 
                         .f = c_sort_collapse)) %&amp;gt;%
  distinct(vars, .keep_all = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;iv.-map-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;IV. Map function(s)&lt;/h2&gt;
&lt;p&gt;Each row of your dataframe now contains the relevant combinations of variables and is ready to have any arbitrary function(s) mapped across them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example with summary statistic&lt;a href=&#34;#fn16&#34; class=&#34;footnote-ref&#34; id=&#34;fnref16&#34;&gt;&lt;sup&gt;16&lt;/sup&gt;&lt;/a&gt;:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For example, let’s say we want to compute the p-value of the correlation coefficient for each pair&lt;a href=&#34;#fn17&#34; class=&#34;footnote-ref&#34; id=&#34;fnref17&#34;&gt;&lt;sup&gt;17&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pairs_cor_pvalues &amp;lt;- df_lists_comb_as %&amp;gt;% 
  mutate(cor_pvalue = map2(vector, vector2, cor.test) %&amp;gt;% map_dbl(&amp;quot;p.value&amp;quot;),
         vars = fct_reorder(vars, -cor_pvalue)) %&amp;gt;% 
  arrange(cor_pvalue) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 45 x 6
##    var        var2         vars                vector     vector2     cor_pvalue
##    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;        &amp;lt;fct&amp;gt;               &amp;lt;list&amp;gt;     &amp;lt;list&amp;gt;           &amp;lt;dbl&amp;gt;
##  1 First_Flr~ Total_Bsmt_~ First_Flr_SF.Total~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  0.       
##  2 Full_Bath  Gr_Liv_Area  Full_Bath.Gr_Liv_A~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  0.       
##  3 Garage_Ar~ Garage_Cars  Garage_Area.Garage~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  0.       
##  4 Gr_Liv_Ar~ TotRms_AbvG~ Gr_Liv_Area.TotRms~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  0.       
##  5 Year_Built Year_Remod_~ Year_Built.Year_Re~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  7.85e-301
##  6 First_Flr~ Gr_Liv_Area  First_Flr_SF.Gr_Li~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  8.17e-244
##  7 Garage_Ca~ Year_Built   Garage_Cars.Year_B~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  1.57e-219
##  8 Full_Bath  TotRms_AbvG~ Full_Bath.TotRms_A~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  1.24e-210
##  9 First_Flr~ Garage_Area  First_Flr_SF.Garag~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  8.16e-178
## 10 Garage_Ca~ Gr_Liv_Area  Garage_Cars.Gr_Liv~ &amp;lt;dbl [2,9~ &amp;lt;dbl [2,93~  4.80e-175
## # ... with 35 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For fun, let’s plot the most significant associations onto a bar graph.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pairs_cor_pvalues %&amp;gt;% 
  head(15) %&amp;gt;% 
  mutate(cor_pvalue_nlog = -log(cor_pvalue)) %&amp;gt;% 
  ggplot(aes(x = vars, 
             y = cor_pvalue_nlog, 
             fill = is.infinite(cor_pvalue_nlog) %&amp;gt;% factor(c(T, F))))+
  geom_col()+
  coord_flip()+
  theme_bw()+
  labs(title = &amp;quot;We are confident that garage area and # of garage cars are correlated&amp;quot;,
       y = &amp;quot;Negative log of p-value of correlation coefficient&amp;quot;,
       x = &amp;quot;Variable combinations&amp;quot;,
       fill = &amp;quot;Too high to\nmeaningfully\ndifferentiate:&amp;quot;)+
  theme(plot.title.position = &amp;quot;plot&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-31-tidy-2-way-column-combinations_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You could use this approach to calculate any pairwise summary statistic. For example, see &lt;a href=&#34;https://gist.github.com/brshallo/dc3c1f2f34519ca2a8a68024bc3a22e5&#34;&gt;gist&lt;/a&gt; where I calculate the K-S statistic across each combination of a group of distributions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you only care about computing summary statistics on your pairwise combinations, (and not adding new columns onto your original dataframe) you can stop here.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example with transformations&lt;a href=&#34;#fn18&#34; class=&#34;footnote-ref&#34; id=&#34;fnref18&#34;&gt;&lt;sup&gt;18&lt;/sup&gt;&lt;/a&gt;:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Back to the feature engineering example, perhaps we want to create new features of the difference and quotient of each combination of our variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_features_prep1 &amp;lt;- df_lists_comb %&amp;gt;% 
  mutate(difference = map2(vector, vector2, `-`),
         ratio = map2(vector, vector2, `/`))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;v.-return-to-normal-dataframe&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;V. Return to normal dataframe&lt;/h2&gt;
&lt;p&gt;The next set of steps will put our data back into a more traditional form consistent with our starting dataframe/tibble.&lt;/p&gt;
&lt;p&gt;First let’s revert our data to a form similar to where it was at the end of &lt;a href=&#34;#i.-nest-and-pivot&#34;&gt;I. Nest and pivot&lt;/a&gt; where we had two columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one with our variable names&lt;/li&gt;
&lt;li&gt;a second containing a list-column of vectors&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_features_prep2 &amp;lt;- new_features_prep1 %&amp;gt;% 
  pivot_longer(cols = c(difference, ratio)) %&amp;gt;% # 1
  mutate(name_vars = str_c(var, name, var2, sep = &amp;quot;.&amp;quot;)) %&amp;gt;% # 2
  select(name_vars, value) # 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At the end of each line of code above is a number corresponding with the following explanations:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;if we had done just one operation, this step would not be needed, but we did multiple operations, created multiple list-columns (&lt;code&gt;difference&lt;/code&gt; and &lt;code&gt;ratio&lt;/code&gt;) which we need to get into a single list-column&lt;/li&gt;
&lt;li&gt;create new variable name that combines constituent variable names with name of transformation&lt;/li&gt;
&lt;li&gt;remove old columns&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Next we simply apply the inverse of those operations performed in &lt;a href=&#34;#i.-nest-and-pivot&#34;&gt;I. Nest and pivot&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_features &amp;lt;- new_features_prep2 %&amp;gt;% 
  pivot_wider(values_from = value,
              names_from = name_vars) %&amp;gt;%
  unnest(cols = everything())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new features will add a good number of columns onto our original dataset&lt;a href=&#34;#fn19&#34; class=&#34;footnote-ref&#34; id=&#34;fnref19&#34;&gt;&lt;sup&gt;19&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(new_features)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2930  180&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;vi.-bind-back-to-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;VI. Bind back to data&lt;/h2&gt;
&lt;p&gt;I then bind the new features back onto the original subsetted dataframe.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_data_features &amp;lt;- bind_cols(ames_subset, new_features)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At which point I could do further exploring, feature engineering, model building, etc.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;functionalize&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Functionalize&lt;/h1&gt;
&lt;p&gt;I put these steps into a few (unpolished) functions found at &lt;a href=&#34;https://gist.github.com/brshallo/f92a5820030e21cfed8f823a6e1d56e1&#34;&gt;this gist&lt;/a&gt;&lt;a href=&#34;#fn20&#34; class=&#34;footnote-ref&#34; id=&#34;fnref20&#34;&gt;&lt;sup&gt;20&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::source_gist(&amp;quot;https://gist.github.com/brshallo/f92a5820030e21cfed8f823a6e1d56e1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;mutate_pairwise()&lt;/code&gt; takes in your dataframe, the set of numeric columns to create pairwise combinations from, and a list of functions&lt;a href=&#34;#fn21&#34; class=&#34;footnote-ref&#34; id=&#34;fnref21&#34;&gt;&lt;sup&gt;21&lt;/sup&gt;&lt;/a&gt; to apply.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-creating-evaluating-features&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example creating &amp;amp; evaluating features&lt;/h1&gt;
&lt;p&gt;Let’s use the new &lt;code&gt;mutate_pairwise()&lt;/code&gt; function to create new columns for the differences and quotients between all pairwise combinations of our variables of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_data_features_example &amp;lt;- mutate_pairwise(
  df = mutate_if(ames, is.numeric, as.double),
  one_of(ames_cols),
  funs = list(&amp;quot;/&amp;quot;, &amp;quot;-&amp;quot;),
  funs_names = list(&amp;quot;ratio&amp;quot;, &amp;quot;difference&amp;quot;),
  associative = FALSE
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perhaps you want to calculate some measure of association between your features and a target of interest. To keep things simple, I’ll remove any columns that contain any NA’s or infinite values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;features_keep &amp;lt;- ames_data_features_example %&amp;gt;% 
  keep(is.numeric) %&amp;gt;% 
  keep(~sum(is.na(.) | is.infinite(.)) == 0) %&amp;gt;% 
  colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Maybe, for some reason, you want to see the statistical significance of the correlation of each feature with &lt;code&gt;Sale_Price&lt;/code&gt; when weighting by &lt;code&gt;Lot_Area&lt;/code&gt;. I’ll calculate these across variables (and a random sample of 1500 observations) then plot them on a histogram.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
ames_data_features_example %&amp;gt;% 
  sample_n(1500) %&amp;gt;% 
  summarise_at(
    .vars = features_keep[!(features_keep %in% c(&amp;quot;Sale_Price&amp;quot;, &amp;quot;Lot_Area&amp;quot;))],
    .funs = ~weights::wtd.cor(., Sale_Price, weight = Lot_Area)[1]) %&amp;gt;% 
  gather() %&amp;gt;% # gather() is an older version of pivot_longer() w/ fewer parameters
  ggplot(aes(x = value))+
  geom_vline(xintercept = 0, colour = &amp;quot;lightgray&amp;quot;, size = 2)+
  geom_histogram()+
  scale_x_continuous(labels = scales::comma)+
  labs(title = &amp;quot;Distribution of correlations with Sale_Price&amp;quot;,
       subtitle = &amp;quot;Weighted by Lot Area&amp;quot;,
       x = &amp;quot;Weighted correlation coefficient&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-31-tidy-2-way-column-combinations_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If doing predictive modeling or inference you may want to fit any transformations and analysis into a &lt;code&gt;tidymodels&lt;/code&gt; pipeline or other framework. For some brief notes on this see &lt;a href=&#34;#interactions-example-tidymodels&#34;&gt;Interactions example, tidymodels&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;when-is-this-approach-inappropriate&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;When is this approach inappropriate?&lt;/h1&gt;
&lt;p&gt;Combinatorial growth is very fast&lt;a href=&#34;#fn22&#34; class=&#34;footnote-ref&#34; id=&#34;fnref22&#34;&gt;&lt;sup&gt;22&lt;/sup&gt;&lt;/a&gt;. As you increase either the number of variables in your pool or the size of each set, you will quickly bump into computational limitations.&lt;/p&gt;
&lt;p&gt;Tidyverse packages are optimized to be efficient. However operations with matrices or other specialized formats&lt;a href=&#34;#fn23&#34; class=&#34;footnote-ref&#34; id=&#34;fnref23&#34;&gt;&lt;sup&gt;23&lt;/sup&gt;&lt;/a&gt; are generally faster&lt;a href=&#34;#fn24&#34; class=&#34;footnote-ref&#34; id=&#34;fnref24&#34;&gt;&lt;sup&gt;24&lt;/sup&gt;&lt;/a&gt; than with dataframes/tibbles. If you are running into computational challenges but prefer to stick with a tidyverse aesthetic (which uses dataframes as a cornerstone), you might:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use heuristics to reduce the number of variables or operations you need to perform (e.g. take a sample, use a preliminary filter, a step-wise like iteration, etc.)&lt;/li&gt;
&lt;li&gt;Look for packages that abstract the storage and computationally heavy operations away&lt;a href=&#34;#fn25&#34; class=&#34;footnote-ref&#34; id=&#34;fnref25&#34;&gt;&lt;sup&gt;25&lt;/sup&gt;&lt;/a&gt; and then return back an output in a convenient form&lt;a href=&#34;#fn26&#34; class=&#34;footnote-ref&#34; id=&#34;fnref26&#34;&gt;&lt;sup&gt;26&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Improve the efficiency of your code (e.g. filter redundancies before rather than after expanding combinations)&lt;a href=&#34;#fn27&#34; class=&#34;footnote-ref&#34; id=&#34;fnref27&#34;&gt;&lt;sup&gt;27&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Consider parralelizing&lt;/li&gt;
&lt;li&gt;Use matrices&lt;a href=&#34;#fn28&#34; class=&#34;footnote-ref&#34; id=&#34;fnref28&#34;&gt;&lt;sup&gt;28&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is sometimes an urge to do &lt;em&gt;everything&lt;/em&gt; in a tidy way, which is not necessary. For example, you &lt;em&gt;could&lt;/em&gt; use an approach like the one I walk through to calculate pairwise correlations between each of your variables. However, the &lt;code&gt;cor()&lt;/code&gt; function would do this much more efficiently if called on a matrix or traditional dataframe without list-columns (though you could also use the &lt;code&gt;corrr&lt;/code&gt; package within the &lt;code&gt;tidymodels&lt;/code&gt; suite which calls &lt;code&gt;cor()&lt;/code&gt; in the back-end&lt;a href=&#34;#fn29&#34; class=&#34;footnote-ref&#34; id=&#34;fnref29&#34;&gt;&lt;sup&gt;29&lt;/sup&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;However, for many operations…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;there may not be an efficient pairwise implementation available / accessible&lt;/li&gt;
&lt;li&gt;the slower computation may not matter or can be mitigated in some way&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These situations&lt;a href=&#34;#fn30&#34; class=&#34;footnote-ref&#34; id=&#34;fnref30&#34;&gt;&lt;sup&gt;30&lt;/sup&gt;&lt;/a&gt; are where the approach I walked through is most appropriate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;interactions-example-tidymodels&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interactions example, tidymodels&lt;/h2&gt;
&lt;p&gt;A good example for creating and evaluating interaction terms&lt;a href=&#34;#fn31&#34; class=&#34;footnote-ref&#34; id=&#34;fnref31&#34;&gt;&lt;sup&gt;31&lt;/sup&gt;&lt;/a&gt; is in &lt;a href=&#34;http://www.feat.engineering/complete-enumeration.html#complete-enumeration-simple-screening&#34;&gt;The Brute-Force Approach to Identifying Predictive Interactions, Simple Screening&lt;/a&gt; section of &lt;em&gt;Max Kuhn&lt;/em&gt; and &lt;em&gt;Kjell Johnson’s&lt;/em&gt; (free) online book “Feature Engineering and Selection: A Practical Approach for Predictive Models”.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://github.com/topepo/FES/blob/master/07_Detecting_Interaction_Effects/7_04_The_Brute-Force_Approach_to_Identifying_Predictive_Interactions/ames_pairwise.R&#34;&gt;source code&lt;/a&gt; shows another approach for combining variables. The author uses…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;combn()&lt;/code&gt; to create all combinations of variable names which are then…&lt;/li&gt;
&lt;li&gt;turned into formulas and passed into &lt;code&gt;recipes::step_interact()&lt;/code&gt;, specifying the new columns to be created&lt;a href=&#34;#fn32&#34; class=&#34;footnote-ref&#34; id=&#34;fnref32&#34;&gt;&lt;sup&gt;32&lt;/sup&gt;&lt;/a&gt;…&lt;/li&gt;
&lt;li&gt;for each interaction term…&lt;/li&gt;
&lt;li&gt;in each associated model being evaluated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The example uses a mix of packages and styles and is not a purely tidy approach – &lt;code&gt;tidymodels&lt;/code&gt; has also gone through a lot of development since “Feature Engineering and Selection…” was published in 2019&lt;a href=&#34;#fn33&#34; class=&#34;footnote-ref&#34; id=&#34;fnref33&#34;&gt;&lt;sup&gt;33&lt;/sup&gt;&lt;/a&gt;. Section 11.2 on &lt;a href=&#34;http://www.feat.engineering/greedy-simple-filters.html&#34;&gt;Greedy Search Methods, Simple Filters&lt;/a&gt; is also highly relevant.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;expand-via-join&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Expand via join&lt;/h2&gt;
&lt;p&gt;You can take advantage of join&lt;a href=&#34;#fn34&#34; class=&#34;footnote-ref&#34; id=&#34;fnref34&#34;&gt;&lt;sup&gt;34&lt;/sup&gt;&lt;/a&gt; behavior to create all possible row combinations. In this case, the output will be the same as shown when using &lt;code&gt;expand()&lt;/code&gt; (except row order will be different).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;left_join(mutate(df_lists, id = 1),
          mutate(df_lists, id = 1) %&amp;gt;% rename_at(vars(-one_of(&amp;quot;id&amp;quot;)), paste0, &amp;quot;2&amp;quot;)) %&amp;gt;%
  select(-id)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;nested-tibbles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nested tibbles&lt;/h2&gt;
&lt;p&gt;Creates list of tibbles rather than list of vectors – typically the first way lists as columns in dataframes is introduced.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_subset %&amp;gt;% 
  pivot_longer(everything(), names_to = &amp;quot;var&amp;quot;, values_to = &amp;quot;list&amp;quot;) %&amp;gt;% 
  group_by(var) %&amp;gt;% 
  nest()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;pivot-and-then-summarise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pivot and then summarise&lt;/h2&gt;
&lt;p&gt;(Almost) equivalent to the example in &lt;a href=&#34;#i.-nest-and-pivot&#34;&gt;I. Nest and pivot&lt;/a&gt;. Steps just run in a different order (row order will also be different).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ames_test %&amp;gt;% 
  pivot_longer(cols = everything(), 
             names_to = &amp;quot;var&amp;quot;, 
             values_to = &amp;quot;vector&amp;quot;) %&amp;gt;% 
  group_by(var) %&amp;gt;% 
  summarise_all(list)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;gif-for-social-media&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gif for social media&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AmesHousing::make_ames() %&amp;gt;% 
  select(Year = Year_Sold, Price = Sale_Price) %&amp;gt;% 
  # I.
  group_by(Year) %&amp;gt;% 
  summarise(Price = list(Gr_Liv_Area)) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  # II.
  expand(nesting(Year, Price),
         nesting(Year2 = Year, Price2 = Price)
  ) %&amp;gt;%
  # III.
  filter(Year != Year2) %&amp;gt;% 
  mutate(Years = map2_chr(.x = Year, 
                          .y = Year2, 
                          .f = c_sort_collapse)) %&amp;gt;%
  distinct(Years, .keep_all = TRUE) %&amp;gt;% 
  select(-Years) %&amp;gt;% 
  #IV.
  mutate(ks_test = map2(Price, 
                        Price2, 
                        stats::ks.test) %&amp;gt;% map_dbl(&amp;quot;p.value&amp;quot;)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-31-tidy-2-way-column-combinations_files/pairwise-comparison-gif-edit.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Actual gif was created by embedding above code into a presentation and exporting it as a gif and then making a few minor edits.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tweets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tweets&lt;/h2&gt;
&lt;p&gt;A few tweets as documentation of thinking.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Original tweet + R bloggers tweet:&lt;/em&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
What is your &lt;a href=&#34;https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#tidyverse&lt;/a&gt; (or other &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; ) approach for doing arbitrary pairwise operations across variables? Mine is frequently something like:&lt;br&gt;&lt;br&gt;I. nest…&lt;br&gt;II. expand combos… &lt;br&gt;III. filter…&lt;br&gt;IV. map fun(s)…&lt;br&gt;…&lt;br&gt;&lt;br&gt;I wrote a post walking through this: &lt;a href=&#34;https://t.co/xRnRf5yh3m&#34;&gt;https://t.co/xRnRf5yh3m&lt;/a&gt; &lt;a href=&#34;https://t.co/Zvxey2gm3H&#34;&gt;pic.twitter.com/Zvxey2gm3H&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1271194908477591553?ref_src=twsrc%5Etfw&#34;&gt;June 11, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Tidy Pairwise Operations {&lt;a href=&#34;https://t.co/mI5r2e5ttN&#34;&gt;https://t.co/mI5r2e5ttN&lt;/a&gt;} &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/DataScience?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#DataScience&lt;/a&gt;
&lt;/p&gt;
— R-bloggers (&lt;span class=&#34;citation&#34;&gt;@Rbloggers&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/Rbloggers/status/1307007573611155456?ref_src=twsrc%5Etfw&#34;&gt;September 18, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;em&gt;Tweet with link to gist of other example applying this approach:&lt;/em&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
&lt;a href=&#34;https://twitter.com/W_R_Chase?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@W_R_Chase&lt;/span&gt;&lt;/a&gt; alludes to using &lt;code&gt;expand()&lt;/code&gt; for a solution but takes a different approach. I wrote a short gist that fleshes in what a &lt;code&gt;tidyr::expand()&lt;/code&gt; approach to this problem could look like: &lt;a href=&#34;https://t.co/agloPgJR1r&#34;&gt;https://t.co/agloPgJR1r&lt;/a&gt; (2/3)
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1272411480193974273?ref_src=twsrc%5Etfw&#34;&gt;June 15, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;em&gt;Tweet about &lt;code&gt;widyr&lt;/code&gt;:&lt;/em&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
Will add &lt;code&gt;widyr&lt;/code&gt; to my set of tools for tidy pairwise operations: &lt;a href=&#34;https://t.co/NSxNC3nehK&#34;&gt;https://t.co/NSxNC3nehK&lt;/a&gt; !&lt;br&gt;&lt;br&gt;Seems to overlap some w/ tidymodels, eg &lt;code&gt;corrr&lt;/code&gt;📦 (&lt;a href=&#34;https://twitter.com/thisisdaryn?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@thisisdaryn&lt;/span&gt;&lt;/a&gt; ) or could imagine widely_kmeans() as a &lt;code&gt;recipe&lt;/code&gt;/&lt;code&gt;embed&lt;/code&gt; step…&lt;a href=&#34;https://twitter.com/drob?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@drob&lt;/span&gt;&lt;/a&gt; any tips on when/how you use these in combination? &lt;a href=&#34;https://t.co/dAsJtNW7Vo&#34;&gt;https://t.co/dAsJtNW7Vo&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1313966803488583686?ref_src=twsrc%5Etfw&#34;&gt;October 7, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;em&gt;Tweet with more efficient approach (for case when just combining multiple columns and returning output of equal number of rows):&lt;/em&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
How you can use &lt;code&gt;dplyr::mutate()&lt;/code&gt; to return a dataframe consisting of all combinations of arbitrary pairwise operations across a selection of columns: &lt;a href=&#34;https://t.co/RxwtbmWqap&#34;&gt;https://t.co/RxwtbmWqap&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/rstats?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#rstats&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/tidyverse?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#tidyverse&lt;/a&gt; … &lt;a href=&#34;https://t.co/UpJw0pGPUd&#34;&gt;pic.twitter.com/UpJw0pGPUd&lt;/a&gt;
&lt;/p&gt;
— Bryan Shalloway (&lt;span class=&#34;citation&#34;&gt;@brshallo&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/brshallo/status/1316851879658356736?ref_src=twsrc%5Etfw&#34;&gt;October 15, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 3.5.1 (2018-07-02)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18363)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] forcats_0.4.0   stringr_1.4.0   dplyr_1.0.1     purrr_0.3.4    
## [5] readr_1.3.1     tidyr_1.1.1     tibble_3.0.3    ggplot2_3.3.2  
## [9] tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] fs_1.3.2            usethis_1.4.0       lubridate_1.7.9    
##  [4] devtools_2.0.0      RColorBrewer_1.1-2  httr_1.4.0         
##  [7] rprojroot_1.3-2     tools_3.5.1         backports_1.1.8    
## [10] utf8_1.1.4          R6_2.4.1            rpart_4.1-13       
## [13] Hmisc_4.1-1         colorspace_1.4-1    nnet_7.3-12        
## [16] withr_2.2.0         gridExtra_2.3       tidyselect_1.1.0   
## [19] prettyunits_1.1.1   processx_3.4.2      curl_3.3           
## [22] compiler_3.5.1      cli_2.0.2           rvest_0.3.4        
## [25] htmlTable_1.12      mice_3.8.0          xml2_1.2.0         
## [28] desc_1.2.0          labeling_0.3        bookdown_0.11      
## [31] checkmate_2.0.0     scales_1.1.1        corrr_0.4.2.9000   
## [34] callr_3.4.3         digest_0.6.25       foreign_0.8-70     
## [37] rmarkdown_1.13      base64enc_0.1-3     pkgconfig_2.0.3    
## [40] htmltools_0.5.0     sessioninfo_1.1.1   htmlwidgets_1.3    
## [43] rlang_0.4.7         readxl_1.3.1        rstudioapi_0.11    
## [46] farver_2.0.3        generics_0.0.2      jsonlite_1.6.1     
## [49] gtools_3.8.2        acepack_1.4.1       magrittr_1.5       
## [52] Formula_1.2-3       Matrix_1.2-14       Rcpp_1.0.4.6       
## [55] munsell_0.5.0       fansi_0.4.1         lifecycle_0.2.0    
## [58] weights_1.0.1       stringi_1.4.6       yaml_2.2.1         
## [61] pkgbuild_1.1.0      grid_3.5.1          gdata_2.18.0       
## [64] crayon_1.3.4        lattice_0.20-35     haven_2.1.0        
## [67] splines_3.5.1       hms_0.5.2           knitr_1.29         
## [70] ps_1.3.2            pillar_1.4.6        pkgload_1.0.2      
## [73] glue_1.4.1          evaluate_0.14       blogdown_0.15      
## [76] latticeExtra_0.6-28 data.table_1.12.8   remotes_2.1.0      
## [79] modelr_0.1.4        vctrs_0.3.2         testthat_2.3.2     
## [82] cellranger_1.1.0    gtable_0.3.0        assertthat_0.2.1   
## [85] xfun_0.16           broom_0.7.0         AmesHousing_0.0.3  
## [88] survival_2.42-3     memoise_1.1.0       cluster_2.0.7-1    
## [91] ellipsis_0.3.1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Will focus on two-way example in this post, but could use similar methods to make more generalizable solution across n-way examples. If I were to do this, the code below would change. E.g.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;to use &lt;code&gt;pmap*()&lt;/code&gt; operations over &lt;code&gt;map2*()&lt;/code&gt; operations&lt;/li&gt;
&lt;li&gt;I’d need to make some functions that make it so I can remove all the places where I have &lt;code&gt;var&lt;/code&gt; and &lt;code&gt;var2&lt;/code&gt; type column names hard-coded&lt;/li&gt;
&lt;li&gt;Alternatively, I might shift approaches and make better use of &lt;code&gt;combn()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Though this “throw everything and the kitchen-sink” approach may not always be a good idea.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;I’ve done this type of operation in a variety of ways. Sometimes without any really good reason as to why I used one approach or another. It isn’t completely clear (at least to me) the recommended way of doing these type of operations within the tidyverse – hence the diversity of my approaches in the past and deciding to document the typical steps in the approach I take… via writing this post.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Or the tidymodels implementation &lt;code&gt;corrr::correlate()&lt;/code&gt; in the &lt;a href=&#34;https://corrr.tidymodels.org/&#34;&gt;corrr&lt;/a&gt; package.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;or is not in a style you prefer&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;I’ll also reference related approaches / small tweaks (putting those materials in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;. This is by no means an exhaustive list (e.g. don’t have an example with a &lt;code&gt;for&lt;/code&gt; loop or with a &lt;code&gt;%do%&lt;/code&gt; operator). The source code of my post on &lt;a href=&#34;https://www.bryanshalloway.com/2020/02/13/fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs/&#34;&gt;Ambiguous Absolute Value&lt;/a&gt; signs shows a related but more complex / messy approach on a combinatorics problem.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;In particular, the chapters on “Iteration” and “Many Models” in &lt;a href=&#34;https://r4ds.had.co.nz/iteration.html&#34;&gt;R for Data Science&lt;/a&gt;. I would also recommend Rebecca Barter’s &lt;a href=&#34;http://www.rebeccabarter.com/blog/2019-08-19_purrr/&#34;&gt;Learn to purrr&lt;/a&gt; blog post.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;The new &lt;code&gt;dplyr&lt;/code&gt; 1.0.0. contains new functions that would have been potentially useful for several of these operations. I highly recommend checking these updates out in the various &lt;a href=&#34;https://www.tidyverse.org/tags/dplyr-1-0-0/&#34;&gt;recent posts&lt;/a&gt; by Hadley Wickham. Some of the major updates (potentially relevant to the types of operations I’ll be discussing in my post):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;new approach for across-column operations (replacing &lt;code&gt;_at()&lt;/code&gt;, &lt;code&gt;_if()&lt;/code&gt;, &lt;code&gt;_all()&lt;/code&gt; variants with &lt;code&gt;across()&lt;/code&gt; function)&lt;/li&gt;
&lt;li&gt;brought-back rowwise operations&lt;/li&gt;
&lt;li&gt;emphasize ability to output tibbles / multiple columns in core &lt;code&gt;dplyr&lt;/code&gt; verbs. This is something I had only taken advantage of occassionally in the past (&lt;a href=&#34;https://stackoverflow.com/a/54725732/9059865&#34;&gt;example&lt;/a&gt;), but will look to use more going forward.&lt;/li&gt;
&lt;/ul&gt;
&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;f I’d spotted this issue initially I’m not sure I would have written this post. However what this post offers is a more verbose treatment of the problem which may be useful for people newer to pairwise operations or the tidyverse.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;For technical reasons, I also converted all integer types to doubles – was getting integer overflow problems in later operations before changing. &lt;a href=&#34;https://stackoverflow.com/questions/8804779/what-is-integer-overflow-in-r-and-how-can-it-happen&#34;&gt;Thread&lt;/a&gt; on integer overflow in R. In this post I’m not taking a disciplined approach to feature engineering. For example it may make sense to normalize the variables so that variable combinations would be starting on a similar scale. This could be done using &lt;code&gt;recipes::step_normalize()&lt;/code&gt; or with code like &lt;code&gt;dplyr::mutate_all(df, ~(. - mean(.)) / sd(.))&lt;/code&gt; .&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Note that this part of the problem is one where I actually find using &lt;code&gt;tidyr::gather()&lt;/code&gt; easier – but I’ve been forcing myself to switch over to using the &lt;code&gt;pivot_()&lt;/code&gt; functions over &lt;code&gt;spread()&lt;/code&gt; and &lt;code&gt;gather()&lt;/code&gt;.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;The more common approach.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;If your variables are across rows you are likely concerned with getting summary metrics rather than creating new features – as if your data is across rows there is nothing guaranteeing you have the same number of observations or that they are lined-up appropriately. If you &lt;em&gt;are&lt;/em&gt; interested in creating new features, you should probably have first reshaped your data to ensure each column represented a variable.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;As switching these would be more computationally efficient – see &lt;a href=&#34;#when-is-this-approach-inappropriate&#34;&gt;When is this approach inappropriate?&lt;/a&gt; for notes related to this. Switching the order here would suggest using approaches with the&lt;code&gt;combn()&lt;/code&gt; function.&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn15&#34;&gt;&lt;p&gt;I.e. has the same output regardless of the order of the variables. E.g. multiplication or addition but not subtraction or division.&lt;a href=&#34;#fnref15&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn16&#34;&gt;&lt;p&gt;Function(s) that output vectors of length 1 (or less than length of input vectors).&lt;a href=&#34;#fnref16&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn17&#34;&gt;&lt;p&gt;Note that the pairwise implementation &lt;code&gt;psych::corr.test()&lt;/code&gt; could have been used on your original subsetted dataframe, see &lt;a href=&#34;https://stackoverflow.com/questions/13112238/a-matrix-version-of-cor-test&#34;&gt;stack overflow thread&lt;/a&gt;.&lt;a href=&#34;#fnref17&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn18&#34;&gt;&lt;p&gt;Function(s) that output vector of length equal to length of input vectors.&lt;a href=&#34;#fnref18&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn19&#34;&gt;&lt;p&gt;Did not print this output because cluttered-up page with so many column names.&lt;a href=&#34;#fnref19&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn20&#34;&gt;&lt;p&gt;Steps I - III and V &amp;amp; VI are essentially direct copies of the code above. The approach I took with Step IV may take more effort to follow as it requires understanding a little &lt;code&gt;rlang&lt;/code&gt; and could likely have been done more simply.&lt;a href=&#34;#fnref20&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn21&#34;&gt;&lt;p&gt;Must have two vectors as input, but do not need to be infix functions.&lt;a href=&#34;#fnref21&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn22&#34;&gt;&lt;p&gt;Non-technical article discussing combinatorial explosion in context of company user growth targets: &lt;a href=&#34;https://medium.com/@TorBair/exponential-growth-isn-t-cool-combinatorial-growth-is-85a0b1fdb6a5&#34;&gt;Exponential Growth Isn’t Cool. Combinatorial Growth Is.&lt;/a&gt;.&lt;a href=&#34;#fnref22&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn23&#34;&gt;&lt;p&gt;E.g. &lt;a href=&#34;https://github.com/Rdatatable/data.table&#34;&gt;data.table&lt;/a&gt; dataframes&lt;a href=&#34;#fnref23&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn24&#34;&gt;&lt;p&gt;Hence, if you are doing operations across combinations of lots of variables it may not make sense to do the operations directly within dataframes.&lt;a href=&#34;#fnref24&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn25&#34;&gt;&lt;p&gt;Much (if not most) of the &lt;code&gt;tidyverse&lt;/code&gt; (and the R programming language generally) is about creating a smooth interface between the analyst/scientist and the back-end complexity of the operations they are performing. Projects like &lt;a href=&#34;https://spark.rstudio.com/&#34;&gt;sparklyr&lt;/a&gt;, &lt;a href=&#34;https://db.rstudio.com/dbi/&#34;&gt;DBI&lt;/a&gt;, &lt;a href=&#34;https://github.com/rstudio/reticulate&#34;&gt;reticulate&lt;/a&gt;, &lt;a href=&#34;https://www.tidymodels.org/&#34;&gt;tidymodels&lt;/a&gt;, and &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; (to name a few) represent cases where this &lt;em&gt;interface&lt;/em&gt; role of R is most apparent.&lt;a href=&#34;#fnref25&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn26&#34;&gt;&lt;p&gt;For tidyverse packages, this is often returned into or in the form of a dataframe.&lt;a href=&#34;#fnref26&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn27&#34;&gt;&lt;p&gt;Could make better use of &lt;code&gt;combn()&lt;/code&gt; function to help.&lt;a href=&#34;#fnref27&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn28&#34;&gt;&lt;p&gt;Depending on the complexity may just need to brush-up on your linear algebra.&lt;a href=&#34;#fnref28&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn29&#34;&gt;&lt;p&gt;&lt;code&gt;corrr&lt;/code&gt; can also be used to run the operation on databases that may have larger data than you could fit on your computer.&lt;a href=&#34;#fnref29&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn30&#34;&gt;&lt;p&gt;Likely more common for many, if not most, analysts and data scientists.&lt;a href=&#34;#fnref30&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn31&#34;&gt;&lt;p&gt;I.e. multiplying two variables together&lt;a href=&#34;#fnref31&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn32&#34;&gt;&lt;p&gt;Created upon the recipe being &lt;em&gt;baked&lt;/em&gt; or &lt;em&gt;juiced&lt;/em&gt; – if you have not checked it out, &lt;a href=&#34;https://github.com/tidymodels/recipes&#34;&gt;recipes&lt;/a&gt; is AWESOME!&lt;a href=&#34;#fnref32&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn33&#34;&gt;&lt;p&gt;Maybe at a future date I’ll make a post writing out the example here using the newer approaches now available in &lt;code&gt;tidymodels&lt;/code&gt;. &lt;a href=&#34;https://gist.github.com/brshallo/674ff06608c1a55fefb8d5dc49896d65&#34;&gt;Gist&lt;/a&gt; of &lt;code&gt;combn_ttible()&lt;/code&gt;… starting place for if I ever get to that write-up.&lt;a href=&#34;#fnref33&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn34&#34;&gt;&lt;p&gt;Could also have used &lt;code&gt;right_join()&lt;/code&gt; or &lt;code&gt;full_join()&lt;/code&gt;.&lt;a href=&#34;#fnref34&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Riddler Solutions: Pedestrian Puzzles</title>
      <link>/2020/03/04/riddler-solutions-pedestrian-puzzles/</link>
      <pubDate>Wed, 04 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/03/04/riddler-solutions-pedestrian-puzzles/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#riddler-express&#34;&gt;Riddler express&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#riddler-classic&#34;&gt;Riddler classic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#time-to-center&#34;&gt;Time to center&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#transform-grid-rotate-first&#34;&gt;Transform grid, rotate first&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#transform-city-pretty&#34;&gt;Transform city, pretty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;This post contains solutions to FiveThirtyEight’s two riddles released 2020-02-14, &lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt; and &lt;a href=&#34;#riddler-classic&#34;&gt;Riddler Classic&lt;/a&gt;. I created a &lt;em&gt;toy&lt;/em&gt; package &lt;a href=&#34;https://github.com/brshallo/animatrixr&#34;&gt;animatrixr&lt;/a&gt; to help with some of the visualizations and computations for my solutions&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;riddler-express&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Riddler express&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The riddle:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Riddler City is a large circular metropolis, with countless square city blocks that each have a side length of 1 km. A small section of the city, composed of 36 blocks, is shown in the diagram below:
&lt;img src=&#34;https://fivethirtyeight.com/wp-content/uploads/2020/02/Screen-Shot-2020-02-11-at-9.41.05-PM.png?w=1150&#34; style=&#34;width:50.0%&#34; /&gt;
At the very center of the city lies Riddler City Hall. Its many employees all walk to and from work, and their homes are evenly scattered across the city. The sidewalks they walk along have always been adjacent to the streets — but that may be changing.
Recently, several city hall employees submitted a petition, requesting that the sidewalks should no longer lie alongside the streets. Instead, they want the sidewalks to cut diagonally across the city, connecting nearby street intersections. These proposed sidewalks are represented by the thicker blue lines in the diagram below:
&lt;img src=&#34;https://fivethirtyeight.com/wp-content/uploads/2020/02/Screen-Shot-2020-02-11-at-9.52.37-PM.png?w=1150&#34; style=&#34;width:50.0%&#34; /&gt;
The mayor of Riddler City has tasked you with resolving this dispute in a mathematical manner. She would like you to answer the following question: What fraction of the city hall employees would have a shorter walk home (that is, to the street intersection nearest to their home) if the city replaced its traditional sidewalks with these diagonal sidewalks?&lt;/p&gt;
&lt;p&gt;– &lt;a href=&#34;https://fivethirtyeight.com/contributors/zach-wissner-gross/&#34;&gt;Zach Wissner-Gross&lt;/a&gt;, &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-solve-this-rather-pedestrian-puzzle/&#34;&gt;“Can You Solve this Rather Pedestrian Puzzle,” FiveThirtyEight&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;My approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I. Create hypothetical simulation of city&lt;br /&gt;
II. For each scenario, calculate Manhattan Distances from center for all points&lt;br /&gt;
III. Make distances comparable by scaling by unit length of a city block&lt;br /&gt;
IV. Compare distances between scenarios for all points; compute proportion that have shorter path with new diagonal sidewalks&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I. Create hypothetical city&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I first created a hypothetical 100 unit diameter version of this city&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. I added residences at every point on a 100x100 grid and then removed those points that had a euclidean distance&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; greater than 50 units from the center.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(animatrixr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;radius &amp;lt;- 50
df_start &amp;lt;- crossing(x = -radius:radius, y = -radius:radius) %&amp;gt;% 
  #Removes points with euclidian distance from center &amp;gt; radius:
  filter(sqrt(x^2 + y^2) &amp;lt;= radius)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;II. Calculate Manhattan Distances&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For both scenarios, we need to calculate the &lt;a href=&#34;https://en.wikipedia.org/wiki/Taxicab_geometry&#34;&gt;Manhattan length&lt;/a&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; between the origin and every point. To calculate the Manhattan length on the new scenario, we first need to find what the residence’s coordinates would be in the new sidewalk grid. The new coordinate system could be thought of simply as a rotated and shrunken version of the existing grid&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;, which can be represented as applying the matrix transformation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ M = \left(\begin{array}{cc} 0.5 &amp;amp; -0.5\\0.5  &amp;amp; 0.5 \end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/gif_city_pretty_grids.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(See &lt;a href=&#34;#transform-city-pretty&#34;&gt;Transform city, pretty&lt;/a&gt; in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt; to view the code used to create the above visualization.)&lt;/p&gt;
&lt;p&gt;Our residences are not changing locations, they would just have different coordinates specific to the new sidewalks – hence we will actually apply the inverse&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; of this transformation to our starting coordinates. This will give us the position of our residences on the new (transformed) coordinate grid.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ M^{-1} = \left(\begin{array}{cc} 1 &amp;amp; 1\\-1  &amp;amp; 1 \end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_trans &amp;lt;- df_start %&amp;gt;% 
  mutate(x_trans = x,
         y_trans = y) %&amp;gt;% 
  # x_trans, y_trans represent the coordinates on the new plane
  transform_df_coords(x_trans, y_trans, m = matrix(c(1, -1, 1, 1), nrow = 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will then calculate the Manhattan lengths of the points on both the new and old coordinate systems – which (because we are comparing distance from the origin: 0,0) can be computed as: &lt;span class=&#34;math inline&#34;&gt;\(Manhattan\;Length = |x| + |y|\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_units &amp;lt;- df_trans %&amp;gt;% 
  mutate(a_units = abs(x) + abs(y),
         b_units = abs(x_trans) + abs(y_trans))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;IV: Multiply Manhattan lengths by length of a block:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The length of a block under the new and old scenarios are different (new diagonal sidewalks have shorter blocks), hence our current Manhattan lengths are not comparable. If we set the length of a single block on the original coordinate system as being 1 unit, then you can use the Pythagorean Theorem to find that the length of a block on the new sidewalks would be &lt;span class=&#34;math inline&#34;&gt;\(\frac{\sqrt{2}}{2}\)&lt;/span&gt;. We simply multiply our Manhattan lengths in each of our scenarios by their respective unit lengths (either 1 or ~0.7071).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_dists &amp;lt;- df_units %&amp;gt;% 
  mutate(a_dist = 1 * a_units,
         b_dist = (sqrt(2) / 2) * b_units)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The scaled distances can now be compared.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;V. Aggregate proportion difference:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, we compute the proportion that have a shorter distance under the new sidewalks compared to the old sidewalks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_dists %&amp;gt;% 
  summarise(prop_shorter = (sum(b_dist &amp;lt; a_dist)/ n()) %&amp;gt;% round(2)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;prop_shorter&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;Riddler express solution:&lt;/em&gt; new diagonal sidewalks would be faster for 50% of people.&lt;/p&gt;
&lt;p&gt;Let’s visualize which resident’s the new sidewalks would be faster for:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_dists %&amp;gt;% 
  mutate(diagonal_faster = b_dist &amp;lt; a_dist) %&amp;gt;% 
  ggplot(aes(x = x, y = y))+
  geom_point(aes(colour = diagonal_faster))+
  coord_fixed()+
  ggforce::theme_no_axes()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;riddler-classic&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Riddler classic&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The riddle:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From David Lewis comes an additional, original twist on Riddler City’s urban planning:&lt;/p&gt;
&lt;p&gt;The mayor ultimately decided not to pursue diagonal sidewalks, but the petitioners haven’t given up yet. One of them recently visited Barcelona and was inspired by its octagonal city blocks.&lt;/p&gt;
&lt;p&gt;Now, there’s a second petition on the mayor’s desk, asking that the grid layout of the city’s sidewalks be replaced with an octagonal pattern, represented by the thicker blue lines in the diagram below:
&lt;img src=&#34;https://fivethirtyeight.com/wp-content/uploads/2020/02/Screen-Shot-2020-02-11-at-10.03.57-PM.png?w=1150&#34; style=&#34;width:50.0%&#34; /&gt;
Under this second proposal, now what fraction of the employees would have a shorter walk home if the city replaced its traditional sidewalks with these new sidewalks?&lt;/p&gt;
&lt;p&gt;– &lt;a href=&#34;https://fivethirtyeight.com/contributors/zach-wissner-gross/&#34;&gt;Zach Wissner-Gross&lt;/a&gt;, &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-solve-this-rather-pedestrian-puzzle/&#34;&gt;“Can You Solve this Rather Pedestrian Puzzle,” FiveThirtyEight&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;My approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Barcelona distance is just a combination of the Manhattan lengths of both the original and diagonal sidewalk grids (though with the unit lengths scaled differently)&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. The unit lengths&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; for the horizontal and diagonal components will depend on what proportion&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt; of a side is horizontal vs diagonal (corresponding with the original vs transformed grid from the &lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt; solution)&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can define our relevant side lengths as a function of x:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/barcelona_dist.jpg&#34; style=&#34;width:50.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x : \frac{inverse\;of\;proportion\;horizontal}{2},\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[0 &amp;lt; x &amp;lt; 0.5\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[diagonal\;length = \sqrt{2}x\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[horizontal\;length = 1 - 2x\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I’ll start by setting x = 0.25.&lt;/em&gt; Hence the Manhattan length of our horizontal component will be scaled by &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{2}\)&lt;/span&gt;, and our diagonal component will be scaled by &lt;span class=&#34;math inline&#34;&gt;\(\frac{\sqrt{2}}{4}\)&lt;/span&gt;. After scaling our components, we simply add them together to get our Barcelona distance&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 0.25
side_length &amp;lt;- 1 - 2*x
side_length_trans &amp;lt;- sqrt(2)*x

df_dists_abc &amp;lt;- df_dists %&amp;gt;% 
  mutate(c_dist_a = a_units * side_length,
         c_dist_b = b_units * side_length_trans,
         c_dist = c_dist_a + c_dist_b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, for all points, we compare the travel distance on the new Barcelona grid compared to on the original horizontal grid and compute the percentage that have a shorter distance under the new sidewalks.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_dists_abc %&amp;gt;% 
  summarise(prop_shorter = (sum(c_dist &amp;lt; a_dist)/ n()) %&amp;gt;% round(2)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;prop_shorter&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In the case (when x is set to 0.25) we see the proportion that is closer to City Hall (i.e. the center of our city&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;) is again 50%.&lt;/p&gt;
&lt;p&gt;If we visualize in which locations the new Barcelona sidewalks have a shorter travel distance, we will see a similar result to that found in the &lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt; solution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_dists_abc %&amp;gt;% 
  mutate(barcelona_faster = c_dist &amp;lt; a_dist) %&amp;gt;% 
  ggplot(aes(x = x, y = y))+
  geom_point(aes(colour = barcelona_faster))+
  coord_fixed()+
  ggforce::theme_no_axes()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;We need to verify that ‘50% have a shorter walk’ is our solution regardless of what we set for x.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;To accomplish this, I wrote a function &lt;code&gt;summarise_proportion()&lt;/code&gt;, that will output the ‘Proportion Barcelona sidewalk distance is shorter’ across any given x between 0 and 0.5 (the possible values of x).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarise_proportion &amp;lt;- function(x, df_start = df_dists, out_data = FALSE){

  x &amp;lt;- 0.25
  side_length &amp;lt;- 1 - 2*x
  side_length_trans &amp;lt;- sqrt(2)*x
  
  df_dists_out &amp;lt;- df_dists %&amp;gt;% 
    mutate(c_dist_a = a_units * side_length,
           c_dist_b = b_units * side_length_trans,
           c_dist = c_dist_a + c_dist_b)
  
  if(out_data) return(df_dists_out)
  
  df_dists_out %&amp;gt;%
    summarise(prop_shorter = (sum(c_dist &amp;lt; a_dist)/ n())) %&amp;gt;%  
    pluck(&amp;quot;prop_shorter&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Specifically I evaluated this ‘proportion shorter’ for &lt;em&gt;x&lt;/em&gt; set to each of &lt;span class=&#34;math inline&#34;&gt;\(0.01, 0.05, 0.09, ... 0.49\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_vec &amp;lt;- seq(from = 0.01, to = 0.49, by = 0.04)

df_summary &amp;lt;- tibble(x = x_vec) %&amp;gt;% 
  mutate(prop_shorter = map_dbl(x, summarise_proportion, df_start = df_dists) %&amp;gt;% round(2))

df_summary %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;x&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;prop_shorter&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.01&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.05&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.09&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.13&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.17&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.21&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.33&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.37&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.41&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.45&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0.49&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For each of these, &lt;em&gt;the new ‘Barcelona grid’ is faster for 50% of people&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;time-to-center&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Time to center&lt;/h2&gt;
&lt;p&gt;Visualize the distance to the center based on where people are in the city for each of the potential city grids.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_dists_abc %&amp;gt;% 
  select(x, y, a_dist, b_dist, c_dist) %&amp;gt;% 
  pivot_longer(cols = c(a_dist, b_dist, c_dist), names_to = &amp;quot;grid&amp;quot;, values_to = &amp;quot;distance&amp;quot;) %&amp;gt;% 
  mutate(grid = fct_recode(grid, 
                           &amp;quot;rectangular&amp;quot; = &amp;quot;a_dist&amp;quot;,
                           &amp;quot;diagonal&amp;quot; = &amp;quot;b_dist&amp;quot;,
                           &amp;quot;barcelona.25&amp;quot; = &amp;quot;c_dist&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x = x, y = y, colour = distance))+
  geom_point()+
  facet_wrap(~grid)+
  coord_fixed()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This suggests that if the city were square shaped (rather than a circle) that the transformed (diagonal and Barcelona) sidewalks would have greater than 50% of the residents with a shorter travel distance to the center of the city.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;transform-grid-rotate-first&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transform grid, rotate first&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;add_transformation(
  m = matrix(c(0.5, 0.5,-0.5, 0.5), nrow = 2), 
  seq_fun = seq_matrix_rotate_first) %&amp;gt;% 
  animate_matrix()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/gif_rotate_shrink.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;transform-city-pretty&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transform city, pretty&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;start_grid &amp;lt;- animatrixr::construct_grid(-8:8, -8:8) %&amp;gt;% 
  mutate(index = row_number(),
         time = 1L)

end_grid &amp;lt;- animatrixr::transform_segment(start_grid,  m = matrix(c(0.5, 0.5,-0.5, 0.5), nrow = 2)) %&amp;gt;% 
  mutate(time = 2L)

house_points &amp;lt;- crossing(x = -3:3, y = -3:3) %&amp;gt;% 
  mutate(symbol = emo::ji(&amp;quot;house&amp;quot;))

city_hall &amp;lt;- tibble(x = 0, y = 0)

p_pretty &amp;lt;- bind_rows(start_grid, end_grid) %&amp;gt;% 
  ggplot()+
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend, group = index, colour = time))+
  geom_text(aes(x = x, y = y, label = symbol), data = house_points, size = 8)+
  geom_label(aes(x = x, y = y, label = &amp;quot;Riddler\nCity Hall&amp;quot;), data = city_hall, size = 8, color = &amp;quot;brown&amp;quot;)+
  scale_colour_gradient(low = &amp;quot;black&amp;quot;, high = &amp;quot;royalblue3&amp;quot;)+
  scale_x_continuous(breaks = -3L:3L, minor_breaks = NULL)+
  scale_y_continuous(breaks = -3L:3L, minor_breaks = NULL)+
  coord_fixed(xlim = c(-3, 3), ylim = c(-3, 3))+
  theme_minimal()+
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = &amp;quot;none&amp;quot;,
        panel.border = element_rect(colour = &amp;quot;black&amp;quot;, fill=NA, size=1))

p_pretty + 
  gganimate::transition_states(time)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-03-04-riddler-solutions-pedestrian-puzzles_files/gif_city_pretty_grids.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;And wrote a couple preliminary posts on animating matrix transformations that can be found &lt;a href=&#34;https://www.bryanshalloway.com/2020/02/20/visualizing-matrix-transformations-with-gganimate/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.bryanshalloway.com/2020/02/24/animatrixr-visualizing-matrix-transformations-pt-2/&#34;&gt;here&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Is large enough to get a reasonable approximation for the answer.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;I.e. straight line distance.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;The Manhattan Length is just the shortest number of city blocks between points.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;I highly recommend the Essence of Linear Algebra video series, particularly chapter 3 (on Matrix Transformations) and &lt;a href=&#34;https://www.youtube.com/watch?v=P2LTAUO1TdA&#34;&gt;13&lt;/a&gt; (on Change of basis).&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;In R, you can use the &lt;code&gt;solve()&lt;/code&gt; function to give you the inverse of a matrix.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;We have already done most of the computations we’ll need and can follow similar steps to those taken in the &lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt; solution.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;I.e. length of an individual city block, or in this case, component of a city block.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;In the diagram below, we will actually have it be a function of one-half of the inverse of the proportion – this is because there are two diagonals adjoining each horizontal component.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;This can also be thought of as the diagonal and the horizontal side lengths can be thought of as a function of the side-length, &lt;em&gt;x&lt;/em&gt;, of a triangle created by a diagonal.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Note that if we were to set x = 0, the distance from each location would be equivalent to the distances in our starting (horizontal) grid, and if we set x = 0.5, the distances would be equal to those in our transformed (diagonal) grid.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;Note that we are not taking into account the tiny differences that emerge regarding starting location for each resident (i.e. which point within a Barcelona square should they start). If we make the grid arbitrarily large, these differences become inconsequential – hence we can ignore them.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;The origin of our coordinate systems.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>animatrixr &amp; Visualizing Matrix Transformations pt. 2</title>
      <link>/2020/02/24/animatrixr-visualizing-matrix-transformations-pt-2/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/24/animatrixr-visualizing-matrix-transformations-pt-2/</guid>
      <description>


&lt;p&gt;This post is a continuation on my post from last week on &lt;a href=&#34;https://www.bryanshalloway.com/2020/02/20/visualizing-matrix-transformations-with-gganimate/&#34;&gt;Visualizing Matrix Transformations with gganimate&lt;/a&gt;. Both posts are largely inspired by &lt;a href=&#34;https://twitter.com/3blue1brown&#34;&gt;Grant Sanderson’s&lt;/a&gt; beautiful video series &lt;a href=&#34;https://www.youtube.com/watch?v=kYB8IZa5AuE&amp;amp;list=PL_w8oSr1JpVCZ5pKXHKz6PkjGCbPbSBYv&amp;amp;index=4&#34;&gt;The Essence of Linear Algebra&lt;/a&gt; and wanting to continue messing around with &lt;a href=&#34;https://github.com/thomasp85/gganimate&#34;&gt;Thomas Lin Peterson’s&lt;/a&gt; fantastic &lt;a href=&#34;https://github.com/thomasp85/gganimate&#34;&gt;gganimate&lt;/a&gt; package in R.&lt;/p&gt;
&lt;p&gt;As with the last post, I’ll describe trying to (very loosely) recreate a &lt;em&gt;small&lt;/em&gt; part of the visualizations showing the geometry of matrix multiplication and changing basis vectors (using &lt;code&gt;gganimate&lt;/code&gt; in R). (Once again, just in the 2x2 case.)&lt;/p&gt;
&lt;p&gt;If you are &lt;em&gt;really&lt;/em&gt; interested in building visualizations like the ones shown on 3Blue1Brown, you should check-out the associated &lt;a href=&#34;https://github.com/3b1b/manim&#34;&gt;manim&lt;/a&gt; project on github.&lt;/p&gt;
&lt;div id=&#34;topics-to-cover&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Topics to cover&lt;/h1&gt;
&lt;p&gt;I had two major sections in the Appendix of last week’s post:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;“Multiple matrix transformations”&lt;/li&gt;
&lt;li&gt;“Potential improvements” (where I mostly describe limitations around visualizing rotations)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This post expands on these topics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animatrixr-and-multiple-matrix-transformations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;code&gt;animatrixr&lt;/code&gt; and multiple matrix transformations&lt;/h1&gt;
&lt;p&gt;Sanderson discusses the value in sometimes decomposing a matrix transformation and thinking of its parts sequentially. I created a &lt;strong&gt;toy&lt;/strong&gt; package &lt;code&gt;animatrixr&lt;/code&gt; for building chained matrix transformations that can then be animated using &lt;code&gt;gganimate&lt;/code&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;animatrixr::add_transformation()&lt;/code&gt; lets you chain together matrix transformations with R’s pipe operator &lt;code&gt;%&amp;gt;%&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, let’s consider three matrix transformations: horizontal sheer –&amp;gt; vertical sheer –&amp;gt; reflection across x-axis:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)

if (!requireNamespace(&amp;quot;animatrixr&amp;quot;)) devtools::install_github(&amp;#39;brshallo/animatrixr&amp;#39;)
library(animatrixr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sheer_horizontal &amp;lt;- tribble(~ x, ~ y,
                      1, 0.5,
                      0, 1) %&amp;gt;%
  as.matrix()

sheer_vertical &amp;lt;- tribble(~ x, ~ y,
                      1, 0,
                      0.5, 1) %&amp;gt;%
  as.matrix()

reflect_x &amp;lt;- tribble(~ x, ~ y,
                      1, 0,
                      0, -1) %&amp;gt;%
  as.matrix() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s visualize the transformations being applied sequentially:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix(c(1,0,0,1), nrow = 2) %&amp;gt;% 
  add_transformation(sheer_horizontal) %&amp;gt;% 
  add_transformation(sheer_vertical) %&amp;gt;% 
  add_transformation(reflect_x, 
                     seq_fun = animatrixr::seq_matrix_l,
                     n_frames = 40) %&amp;gt;% 
  animate_matrix(datasaurus = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-animatrixr-visualizing-matrix-transformations-pt-2_files/figure-html/vsheer-hsheer-reflect-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;add_transformation()&lt;/code&gt; explicitly creates in-between frames for a given transformation. The &lt;code&gt;seq_fun&lt;/code&gt; argument allows you to define the interpolation method, for example whether the coordinates should (during the animation) follow a linear path (default) or the angle of a rotation.&lt;/p&gt;
&lt;p&gt;It would be nice to add-in functionality where the final transformation object could then be added to layers of a ggplot (though I’ve done nothing towards this except add an argument in &lt;code&gt;animatrixr::animate_matrix()&lt;/code&gt; for displaying the &lt;a href=&#34;https://github.com/lockedata/datasauRus&#34;&gt;datasauRus&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;(Warning: &lt;code&gt;animatrixr&lt;/code&gt; is severely limited, as discussed in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt; and in package documentation. However you can find it at the “brshallo/animatrixr” repo on &lt;a href=&#34;https://github.com/brshallo/animatrixr&#34;&gt;my github page&lt;/a&gt;.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-rotations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Visualizing rotations&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;seq_fun&lt;/code&gt; argument within &lt;code&gt;add_transformation()&lt;/code&gt; specifies frames in-between the start and end states after a matrix transformation. By default it uses &lt;code&gt;animatrixr::seq_matrix_l&lt;/code&gt; which changes in-between coordinates linearly (as does &lt;code&gt;gganimate&lt;/code&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Let’s look at a rotation where the in-between coordinates are interpolated linearly:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rotate_90 &amp;lt;- tribble(~ x, ~ y,
                        cos(pi / 2), -sin(pi / 2),
                        sin(pi / 2), cos(pi / 2)) %&amp;gt;%
  as.matrix()

matrix(c(1,0,0,1), nrow = 2) %&amp;gt;% 
  add_transformation(rotate_90) %&amp;gt;% 
  animate_matrix(datasaurus = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-animatrixr-visualizing-matrix-transformations-pt-2_files/figure-html/rotate-linear-1.gif&#34; width=&#34;71%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Linear interpolation makes the rotation transformation appear scrunched during the animation (from how we intuitively think of a rotation) as the coordinate points take a straight line path to their positions after applying the transformation&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To make the in-between coordinates instead follow the angle of rotation we could change the &lt;code&gt;seq_fun&lt;/code&gt; from &lt;code&gt;animatrixr::seq_matrix_l&lt;/code&gt; to &lt;code&gt;animatrixr::seq_matrix_lp&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;matrix(c(1,0,0,1), nrow = 2) %&amp;gt;% 
  add_transformation(rotate_90, seq_fun = animatrixr::seq_matrix_lp) %&amp;gt;% 
  animate_matrix(datasaurus = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-animatrixr-visualizing-matrix-transformations-pt-2_files/figure-html/rotate-polar-sheer-linear-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;During the rotation portion of the animation &lt;code&gt;gganimate&lt;/code&gt; is still tweening images linearly, however the frames &lt;code&gt;add_transformation()&lt;/code&gt; creates are now following along the angle of rotation of the transformation. Hence the animation ends-up approximating a curved path.&lt;/p&gt;
&lt;p&gt;However, &lt;code&gt;seq_matrix_lp()&lt;/code&gt; needs improvement and was just set-up to work for toy examples – it really only looks ‘right’ if doing rotations off of &lt;span class=&#34;math display&#34;&gt;\[ \left(\begin{array}{cc} 1 &amp;amp; 0\\0  &amp;amp; 1 \end{array}\right)\]&lt;/span&gt; See &lt;a href=&#34;#showing-rotations&#34;&gt;Showing rotations&lt;/a&gt; in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt; for additional detail on how this is set-up and the various limitations with &lt;code&gt;animatrixr&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Happy animatrixing!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# animatrixr::rotation_matrix() is helper function for creating matrix
# transformations of rotations
matrix(c(1,0,0,1), nrow = 2) %&amp;gt;% 
  add_transformation(animatrixr::rotation_matrix(pi / 2),
                     seq_fun = animatrixr::seq_matrix_lp) %&amp;gt;% 
  add_transformation(matrix(c(1, 0.5, 0, 1), nrow = 2)) %&amp;gt;% 
  add_transformation(matrix(c(1, 0, 0, -1), nrow = 2)) %&amp;gt;% 
  animate_matrix(datasaurus = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-animatrixr-visualizing-matrix-transformations-pt-2_files/figure-html/unnamed-chunk-1-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;using-animatrixr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using &lt;code&gt;animatrixr&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;This is a toy package (very hastily written). I have not put effort into thinking about making it usable for others. Also, some parts just don’t really work or aren’t set-up quite right… (as noted in the README and elsewhere in the package). But feel free to check-it out / improve it / make something better! Let me know if you do!&lt;/p&gt;
&lt;p&gt;This has been a fun dabble into thinking (at least surface level) about animation. Though I don’t have any plans to add onto this (or write any more posts on this topic). If I do add anything, it will most likely just be cleaning-up the decomposition methods in the &lt;code&gt;seq_matrix*()&lt;/code&gt; functions. But no plans&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;notes-on-seq-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notes on seq functions&lt;/h2&gt;
&lt;p&gt;Below are additional notes on the &lt;code&gt;animatrixr::seq_matrix*&lt;/code&gt; functions. They need some work, but here is a description of how they are currently set-up.&lt;/p&gt;
&lt;div id=&#34;showing-rotations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Showing rotations&lt;/h3&gt;
&lt;p&gt;To animate the rotation of a transformation, &lt;code&gt;add_transformation(m = matrix(c(0, 1, -1, 0), nrow = 2), seq_fun = seq_matrix_lp)&lt;/code&gt; explicitly creates in-between frames on the path the points would follow if they were instead following polar coordinates along the angle of rotation. In the next few sections I’ll discuss the process for doing this (again, this is not necessarily an ideal set-up).&lt;/p&gt;
&lt;p&gt;Given any 2x2 matrix:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \left(\begin{array}{cc} a &amp;amp; b\\ c &amp;amp; d \end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;you can use the equation &lt;code&gt;atan2(c, a)&lt;/code&gt; to extract the angle of rotation from the matrix&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; and then create a sequence from the starting angle of rotation to the final angle of rotation.&lt;/p&gt;
&lt;p&gt;For example, if my start angle is &lt;span class=&#34;math inline&#34;&gt;\(0^\circ\)&lt;/span&gt;, and final angle of rotation is at &lt;span class=&#34;math inline&#34;&gt;\(38^\circ\)&lt;/span&gt; and I have 20 frames, then my sequence would be:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[0^\circ, 2^\circ, ... 38^\circ\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;A rotation matrix is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \left(\begin{array}{cc} cos(\theta) &amp;amp; -sin(\theta)\\ sin(\theta) &amp;amp; cos(\theta) \end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Hence I can convert my sequence of angles into a sequence of matrices that define the rotations applied for each explicit in-between frame.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\left(\begin{array}{cc} cos(0^\circ) &amp;amp; -sin(0^\circ)\\ sin(0^\circ) &amp;amp; cos(0^\circ) \end{array}\right), 
\left(\begin{array}{cc} cos(2^\circ) &amp;amp; -sin(2^\circ)\\ sin(2^\circ) &amp;amp; cos(2^\circ) \end{array}\right)...
\left(\begin{array}{cc} cos(28^\circ) &amp;amp; -sin(28^\circ)\\ sin(28^\circ) &amp;amp; cos(28^\circ) \end{array}\right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seq_matrix_lp-applied-on-non-standard-unit-basis-vectors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;seq_matrix_lp&lt;/code&gt; applied on non-standard unit basis vectors&lt;/h3&gt;
&lt;p&gt;If you input a matrix transformation into &lt;code&gt;seq_matrix_lp&lt;/code&gt; that is not a pure rotation from the unit vectors it will decompose the matrix into a &lt;em&gt;rotation&lt;/em&gt; component and &lt;em&gt;other&lt;/em&gt; component&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;, the &lt;em&gt;other&lt;/em&gt; component creates a sequence of matrices that have the in-between frames interpolated linearly. The sequence of &lt;em&gt;rotation&lt;/em&gt; and &lt;em&gt;other&lt;/em&gt; matrices are then recomposed to provide the final sequence.&lt;/p&gt;
&lt;p&gt;This approach means that non-pure rotations on the unit vectors, etc. will not really look like rotations. I would need to factor in other components (e.g. scale) to improve this.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;show-rotation-first&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Show rotation first&lt;/h3&gt;
&lt;p&gt;Beyond &lt;code&gt;seq_matrip_l()&lt;/code&gt; and &lt;code&gt;seq_matrix_lp()&lt;/code&gt;, I made another seq_matrix* function: &lt;code&gt;seq_matrix_rotate_first&lt;/code&gt; which (like &lt;code&gt;seq_matrix_lp&lt;/code&gt;) also decomposes a matrix into rotation and other components. Rather than interpolating these separately and then recomposing them (as &lt;code&gt;seq_matrix_lp&lt;/code&gt; does) &lt;code&gt;seq_matrix_rotate_first&lt;/code&gt; works by interpolating them separately and then applying the decomposed sequences sequentially – so the entire rotation component of the transformation will be animated and then the ‘other’ component will be animated (this makes for twice as many frames when there is a ‘rotation’ and ‘other’ component in the transformation matrix).&lt;/p&gt;
&lt;p&gt;I.e. starting from our identity matrix and applying a single matrix transformation, it will automatically decompose this and animate the decomposed parts in two steps, &lt;span class=&#34;math inline&#34;&gt;\(I\)&lt;/span&gt; –&amp;gt; &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; and then from &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; –&amp;gt; &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;. Below is an example of the animation for the transformation matrix:
&lt;span class=&#34;math display&#34;&gt;\[ \left(\begin{array}{cc} 0 &amp;amp; -1\\1  &amp;amp; -0.5 \end{array}\right)\]&lt;/span&gt;
(which could be decomposed into a rotation and a sheer part).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;transformation_matrix &amp;lt;- sheer_vertical %*% animatrixr::rotation_matrix(pi/4)

matrix(c(1,0,0,1), nrow = 2) %&amp;gt;% 
  add_transformation(transformation_matrix, seq_fun = seq_matrix_rotate_first) %&amp;gt;% 
  animate_matrix(datasaurus = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-24-animatrixr-visualizing-matrix-transformations-pt-2_files/figure-html/rotate-sheer-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;There are (especially) a lot of problems with this function currently and I don’t recommend using it e.g.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;only works (at all correctly) if starting from standard unit vectors (hence cannot really be combined into a chain of matrix transformations)&lt;/li&gt;
&lt;li&gt;rotation component extracted will vary depending on what ‘other’ is within M
E.g. if M = {rotation}{vertical sheer} vs. M = {rotation}{horizontal sheer} – rotation component will look different&lt;/li&gt;
&lt;li&gt;I defaulted the amount of frames given to the rotation component to be the same as the amount of frames given to other component. If the size of the rotation is small relative to the other part of the transformation (or vice versa) the timing will feel slow/jumpy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Provides a cleaner approach for doing this compared to the clunky method I walked through in my post last week.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;All visualizations from last week used this linear interpolation method.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;I discuss this at more length in my previous post – see the sub-section in the “Appendix”, “Problem of squeezing during rotation”.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;However I also hadn’t planned on writing a follow-up post… so who knows…&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;See &lt;a href=&#34;https://computergraphics.stackexchange.com/questions/3932/animating-a-smooth-linear-transformation&#34;&gt;post&lt;/a&gt; referencing this.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;To find the ‘other’ component of a matrix transformation… say &lt;em&gt;M&lt;/em&gt; represents the overall matrix transformation, in &lt;a href=&#34;#showing-rotations&#34;&gt;Showing rotations&lt;/a&gt; I described how to calculate &lt;em&gt;R&lt;/em&gt; (the rotation component), hence to calculate &lt;em&gt;A&lt;/em&gt;, ‘other’, I do:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[AR = M\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[ARR^{-1} = MR^{-1}\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[A = MR^{-1}\]&lt;/span&gt;&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Matrix Transformations</title>
      <link>/2020/02/20/visualizing-matrix-transformations-with-gganimate/</link>
      <pubDate>Thu, 20 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/20/visualizing-matrix-transformations-with-gganimate/</guid>
      <description>


&lt;p&gt;I highly recommend the fantastic video series &lt;a href=&#34;https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&#34;&gt;Essence of Linear Algebra&lt;/a&gt; by &lt;a href=&#34;https://twitter.com/3blue1brown&#34;&gt;Grant Sanderson&lt;/a&gt;. In this post I’ll walk through how you can use &lt;code&gt;gganimate&lt;/code&gt; and the &lt;code&gt;tidyverse&lt;/code&gt; to (very loosely) recreate some of the visualizations shown in that series. Specifically those on matrix transformations and changing the basis vectors&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/kYB8IZa5AuE?start=234&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
This post is an offshoot of a &lt;a href=&#34;https://www.bryanshalloway.com/2020/03/04/riddler-solutions-pedestrian-puzzles/&#34;&gt;post of my solutions&lt;/a&gt; to this week’s &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-solve-this-rather-pedestrian-puzzle/&#34;&gt;FiveThirtyEight Riddler&lt;/a&gt;. To support my solution, I was trying to visualize matrix transformations. I reached-out to &lt;a href=&#34;https://twitter.com/thomasp85&#34;&gt;Thomas Lin Peterson&lt;/a&gt;:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
I do not. Would love to see it, though🙂
&lt;/p&gt;
— Thomas Lin Pedersen (&lt;span class=&#34;citation&#34;&gt;@thomasp85&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/thomasp85/status/1230171239077105666?ref_src=twsrc%5Etfw&#34;&gt;February 19, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;… figured I’d share what I’ve patched together so far 🎉 (will just be looking at transformations by 2x2 matrices).&lt;/p&gt;
&lt;p&gt;In this post (unlike in those previous) I’ve exposed most of the code directly in the blog, but the raw RMD file is also on my &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-02-20-visualizing-matrix-transformations-with-gganimate.Rmd&#34;&gt;github page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I also wrote a follow-up to this blog post that can be found &lt;a href=&#34;https://www.bryanshalloway.com/2020/02/24/animatrixr-visualizing-matrix-transformations-pt-2/&#34;&gt;here&lt;/a&gt;, which walks through &lt;a href=&#34;https://github.com/brshallo/animatrixr&#34;&gt;animatrixr&lt;/a&gt;: a rudimentary package I wrote for piping together matrix transformations for animations. This first post provides some documentation on some of the functions that ended-up within &lt;code&gt;animatrixr&lt;/code&gt;, but you might also just start directly on the follow-up post.&lt;/p&gt;
&lt;div id=&#34;quick-start&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quick start&lt;/h1&gt;
&lt;p&gt;I made a &lt;a href=&#34;https://gist.github.com/brshallo/6a125f9c96dac5445cebb97cc62bfc9c&#34;&gt;gist&lt;/a&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; containing the functions needed to produce a simple animation of a 2x2 matrix transformation. If you are reading this post with the sole goal of creating an animation like the one below&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, you can copy and run this code chunk to render a 2x2 matrix transformation gif (the input to argument &lt;code&gt;m&lt;/code&gt; can be any &lt;em&gt;2x2&lt;/em&gt; matrix of interest).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!requireNamespace(&amp;quot;devtools&amp;quot;)) install.packages(&amp;quot;devtools&amp;quot;)
devtools::source_gist(&amp;quot;https://gist.github.com/brshallo/6a125f9c96dac5445cebb97cc62bfc9c&amp;quot;)

animate_matrix_transformation(m = matrix(c(0.5, 0.5, 0.5, -0.25), nrow = 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/unnamed-chunk-13-1.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Over the next several sections I’ll walk through the thinking behind this code (culminating in the &lt;a href=&#34;#visualizations&#34;&gt;Visualizations&lt;/a&gt; section, where this animation will be shown again). Sections in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt; contain variations on this animation that add-on additional simple transformations and layers.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;helper-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Helper functions&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;construct_grid()&lt;/code&gt;: given vectors of x and y intercepts, return a dataframe with columns &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, &lt;code&gt;xend&lt;/code&gt;, &lt;code&gt;yend&lt;/code&gt; (meant for input into &lt;code&gt;geom_segment()&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;construct_grid &amp;lt;- function(xintercepts = -5:5, yintercepts = -5:5){
  bind_rows(
    crossing(x = xintercepts,
             y = min(yintercepts),
             yend = max(yintercepts)) %&amp;gt;%
      mutate(xend = x),
    crossing(y = yintercepts,
             x = min(xintercepts),
             xend = max(xintercepts)) %&amp;gt;%
      mutate(yend = y)
  ) %&amp;gt;% 
    select(x, y, xend, yend)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Use with &lt;code&gt;geom_segment()&lt;/code&gt; to make simple grids:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;construct_grid() %&amp;gt;% 
  ggplot(aes(x = x, y = y, xend = xend, yend = yend))+
  geom_segment()+
  coord_fixed()+
  ggforce::theme_no_axes()+
  theme(panel.border = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;transform_df_coords()&lt;/code&gt;: Given dataframe, column names of coordinates&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;, and a transformation matrix, return dataframe with transformed coordinates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;transform_df_coords &amp;lt;- function(df, ..., m = diag(length(df))){
  
  df_names &amp;lt;- names(df)
  
  df_coords &amp;lt;- df %&amp;gt;% 
    select(...)
  
  df_coords_names &amp;lt;- names(df_coords)
  
  df_matrix &amp;lt;- df_coords %&amp;gt;% 
    as.matrix() %&amp;gt;% 
    t()
  
  df_coords_new &amp;lt;- (m %*% df_matrix) %&amp;gt;% 
    t() %&amp;gt;% 
    as_tibble() %&amp;gt;% 
    set_names(df_coords_names)
  
  df_other &amp;lt;- df %&amp;gt;% 
    select(-one_of(df_coords_names))
  
  bind_cols(df_coords_new, df_other) %&amp;gt;% 
    select(df_names)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;transform_df_coords()&lt;/code&gt; is just matrix multiplication, but facilitates applying matrix transformations on a dataframe where each row (in specified columns) represents a vector / coordinate point&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example in&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{R}^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;transform_df_coords(tibble(x = 1:4, y = 1:4), x, y, m = matrix(1:4, nrow = 2)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;x&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Again, this is the same as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \left(\begin{array}{cc} 1 &amp;amp; 3\\ 2 &amp;amp; 4 \end{array}\right)
\left(\begin{array}{cc} 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 \\ 1 &amp;amp; 2 &amp;amp; 3 &amp;amp; 4 \end{array}\right) 
= \left(\begin{array}{cc} 4 &amp;amp; 8 &amp;amp; 12 &amp;amp; 16 \\ 6 &amp;amp; 12 &amp;amp; 18 &amp;amp; 24 \end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(Just with a ‘tidy’ dataframe as output.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Also works with more dimensions, see example in&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\mathbb{R}^3\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;transform_df_coords(tibble(x = 1:5, y = 1:5, z = 1:5), x, y, z, m = matrix(1:9, nrow = 3)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;x&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;y&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;z&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;36&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;45&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;54&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;48&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;60&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;60&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;75&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;90&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;However for our visualizations, we only care about examples in 2 dimensions (when we are applying a 2x2 matrix transformation).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;construct-objects-for-graph&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Construct objects for graph&lt;/h1&gt;
&lt;p&gt;For a simple animation I will build dataframes that contain the coordinates for the following objects&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a &lt;em&gt;starting grid&lt;/em&gt; and a &lt;em&gt;transformed grid&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;a &lt;em&gt;starting basis vector&lt;/em&gt; and a &lt;em&gt;transformed basis vector&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To play nicely with &lt;code&gt;gganimate&lt;/code&gt; the start and transformed objects need to have additional properties&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a field that groups like objects across the animation (e.g. &lt;code&gt;id&lt;/code&gt; column)&lt;/li&gt;
&lt;li&gt;a field that designates transitions between &lt;em&gt;start&lt;/em&gt; and &lt;em&gt;transformed&lt;/em&gt; states (e.g. &lt;code&gt;time&lt;/code&gt; column)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For my example I will be applying the following matrix transformation to our basis vectors&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.
&lt;span class=&#34;math display&#34;&gt;\[ \left(\begin{array}{cc} 0.5 &amp;amp; 0.5\\ 0.5 &amp;amp; -0.25 \end{array}\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Define transformation matrix:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# same as above examples using `matrix()` but I find inputting into tribble more
# intuitive for 2x2 matrix
transformation_matrix &amp;lt;- tribble(~ x, ~ y,
                                 0.5, 0.5,
                                 0.5, -0.25) %&amp;gt;% 
  as.matrix()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Construct grids:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_start &amp;lt;- construct_grid() %&amp;gt;% 
  mutate(id = row_number())

grid_trans &amp;lt;- grid_start %&amp;gt;% 
  # need to `transform_df_coords()` twice as each segment is made up of 2 points
  transform_df_coords(x, y, m = transformation_matrix) %&amp;gt;% 
  transform_df_coords(xend, yend, m = transformation_matrix)

grid_all &amp;lt;- bind_rows(
  mutate(grid_start, time = 1),
  mutate(grid_trans, time = 2)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Construct basis vectors:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;basis_start &amp;lt;- tibble(
  x = c(0, 0),
  y = c(0, 0),
  xend = c(1, 0),
  yend = c(0, 1),
  # `vec` is unnecessary, will just use to differentiate colors
  vec = c(&amp;quot;i&amp;quot;, &amp;quot;j&amp;quot;)
) %&amp;gt;% 
  mutate(id = nrow(grid_start) + row_number())

basis_trans &amp;lt;- basis_start %&amp;gt;% 
  transform_df_coords(x, y, m = transformation_matrix) %&amp;gt;% 
  transform_df_coords(xend, yend, m = transformation_matrix)

basis_all &amp;lt;- bind_rows(
  mutate(basis_start, time = 1),
  mutate(basis_trans, time = 2)
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;build-visualization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Build visualization&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Define breaks in grid:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# If you just want to use the starting grid for the breaks, could do
x_breaks &amp;lt;- unique(grid_start$x)
y_breaks &amp;lt;- unique(grid_start$y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Define visualization:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(aes(x = x, y = y, group = id), data = grid_all)+
  geom_segment(aes(xend = xend, yend = yend))+
  geom_segment(aes(xend = xend, yend = yend, colour = vec), data = basis_all, arrow = arrow(length = unit(0.02, &amp;quot;npc&amp;quot;)), size = 1.2)+
  scale_x_continuous(breaks = x_breaks, minor_breaks = NULL)+
  scale_y_continuous(breaks = y_breaks, minor_breaks = NULL)+
  coord_fixed()+
  theme_minimal()+
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;visualizations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizations&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Static image:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Animation&lt;/em&gt;&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + gganimate::transition_states(time, wrap = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-14-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;And there it is. To view a different matrix transformation, simply change the &lt;code&gt;transformation_matrix&lt;/code&gt; defined above and re-run the code chunks&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt; or see the &lt;a href=&#34;#quick-start&#34;&gt;Quick start&lt;/a&gt; section.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;p&gt;The code used to construct images within the appendix is very similar to code already shown&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;on-changes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;On changes&lt;/h2&gt;
&lt;p&gt;In the few days after sharing this post on 2020-02-20, I made several changes to the images and notes (especially those within the appendix) that I think better clarified points or corrected mistakes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-matrix-transformations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Multiple matrix transformations&lt;/h2&gt;
&lt;p&gt;I love how the “Essence of Linear Algebra” series explains how matrix transformations can be thought-of / broken-down sequentially. The same visualization can (kind-of) be set-up here – you just need to add-in an additional layer.&lt;/p&gt;
&lt;p&gt;E.g. say, we want to apply a &lt;em&gt;rotation&lt;/em&gt; and then a &lt;em&gt;sheer&lt;/em&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rotate_trans &amp;lt;- tribble(~ x, ~ y,
                        cos(pi / 2), -sin(pi / 2),
                        sin(pi / 2), cos(pi / 2)) %&amp;gt;%
  as.matrix()

sheer_trans &amp;lt;- tribble(~ x, ~ y,
                      1, 0,
                      0.5, 1) %&amp;gt;%
  as.matrix() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{bmatrix}
1 &amp;amp; 0\\
0.5 &amp;amp; 1 \\
\end{bmatrix}
\begin{bmatrix}
0 &amp;amp; -1\\
1 &amp;amp; 0 \\
\end{bmatrix}X\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I say &lt;em&gt;kind-of&lt;/em&gt; animate these because &lt;code&gt;gganimate&lt;/code&gt; transforms coordinates linearly, hence while a transformation may result in a rotation, the in-between states (where &lt;code&gt;gganimate&lt;/code&gt; fills in the gaps) will not look like a pure rotation. See &lt;a href=&#34;#potential-improvements&#34;&gt;Potential improvements&lt;/a&gt; for additional notes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Construct grids:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grid_start &amp;lt;- construct_grid() %&amp;gt;% 
  mutate(id = row_number())

grid_trans &amp;lt;- grid_start %&amp;gt;% 
  # need to `transform_df_coords()` twice as each segment is made up of 2 points
  transform_df_coords(x, y, m = rotate_trans) %&amp;gt;% 
  transform_df_coords(xend, yend, m = rotate_trans)

grid_trans2 &amp;lt;- grid_trans %&amp;gt;% 
  # need to `transform_df_coords()` twice as each segment is made up of 2 points
  transform_df_coords(x, y, m = sheer_trans) %&amp;gt;% 
  transform_df_coords(xend, yend, m = sheer_trans)

grid_all &amp;lt;- bind_rows(
  mutate(grid_start, time = 1),
  mutate(grid_trans, time = 2),
  mutate(grid_trans2, time = 3)
) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Basis vectors:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;basis_start &amp;lt;- tibble(
  x = c(0, 0),
  y = c(0, 0),
  xend = c(1, 0),
  yend = c(0, 1),
  # `vec` is unnecessary, will just use to differentiate colors
  vec = c(&amp;quot;i&amp;quot;, &amp;quot;j&amp;quot;)
) %&amp;gt;% 
  mutate(id = nrow(grid_start) + row_number())

basis_trans &amp;lt;- basis_start %&amp;gt;% 
  # need to `transform_df_coords()` twice as each segment is made up of 2 points
  transform_df_coords(x, y, m = rotate_trans) %&amp;gt;% 
  transform_df_coords(xend, yend, m = rotate_trans)

basis_trans2 &amp;lt;- basis_trans %&amp;gt;% 
  # need to `transform_df_coords()` twice as each segment is made up of 2 points
  transform_df_coords(x, y, m = sheer_trans) %&amp;gt;% 
  transform_df_coords(xend, yend, m = sheer_trans)

basis_all &amp;lt;- bind_rows(
  mutate(basis_start, time = 1),
  mutate(basis_trans, time = 2),
  mutate(basis_trans2, time = 3)
) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Define visualization:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_mult &amp;lt;- ggplot(aes(x = x, y = y, group = id), data = grid_all)+
  geom_segment(aes(xend = xend, yend = yend))+
  geom_segment(aes(xend = xend, yend = yend, colour = vec), data = basis_all, arrow = arrow(length = unit(0.02, &amp;quot;npc&amp;quot;)), size = 1.2)+
  scale_x_continuous(breaks = x_breaks, minor_breaks = NULL)+
  scale_y_continuous(breaks = y_breaks, minor_breaks = NULL)+
  coord_fixed()+
  theme_minimal()+
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = &amp;quot;none&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Static image:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_mult &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Animation:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_mult + 
  gganimate::transition_states(time, wrap = FALSE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-20-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Notice that we see the transformations done sequentially. We could also have just inputted the single (simplified) matrix transformation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{bmatrix}
-0.5 &amp;amp; -1\\
1 &amp;amp; 0 \\
\end{bmatrix}
X\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But thinking of the matrix transformations separately can be helpful!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;potential-improvements&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Potential improvements&lt;/h2&gt;
&lt;p&gt;I have no (current) plans of fleshing this out further. (Though I think a ggplot extension – e.g. &lt;code&gt;ggbasis&lt;/code&gt;, &lt;code&gt;gglineartrans&lt;/code&gt; – or something could be cool.) In this section I’ll give a few notes regarding short-term things I’d change or fix-up (if I were to keep working on this – maybe I’ll get to a couple of these). Really I should dive into &lt;code&gt;tweenr&lt;/code&gt; and &lt;code&gt;transformr&lt;/code&gt; packages and associated concepts to get these worked out further.&lt;/p&gt;
&lt;div id=&#34;problem-of-squeezing-during-rotation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Problem of squeezing during rotation&lt;/h3&gt;
&lt;p&gt;You might notice that something about the rotation transformation looks a little off. During the animation, the grid becomes temporarily squished in at some points. We can better see this by placing a circle on the interior of our grid and looking at the rotation of the exterior segments. The exterior segments of the grid &lt;em&gt;should&lt;/em&gt; remain tangent to our circle at all points.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;circle_df &amp;lt;- tibble(x0 = 0, y0 = 0, r = 5)

p_rotation &amp;lt;- ggplot(aes(), data = filter(grid_all, time &amp;lt;= 2))+
  geom_segment(aes(x = x, y = y, group = id, xend = xend, yend = yend))+
  geom_segment(aes(x = x, y = y, group = id, xend = xend, yend = yend, colour = vec), arrow = arrow(length = unit(0.02, &amp;quot;npc&amp;quot;)), size = 1.2, data = filter(basis_all, time &amp;lt;= 2 ))+
  scale_x_continuous(breaks = x_breaks, minor_breaks = NULL)+
  scale_y_continuous(breaks = y_breaks, minor_breaks = NULL)+
  coord_fixed()+
  ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = 5), data = circle_df)+
  theme_minimal()+
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)

p_rotation + gganimate::transition_states(time, wrap = FALSE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-21-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;However we can see this doesn’t happen (the grid scrunches up and the exterior segments cut into the circle). The reason this occurs is that during the animation the coordinates follow a straight line path to their new location as explained:&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
The problem is that coords are tweened linearly which doesn&#39;t match a rotation where the tweening should be done on the radians (or, better, tween the transformation matrix instead). There is no support for this in gganimate yet because I haven&#39;t figured out the right interface
&lt;/p&gt;
— Thomas Lin Pedersen (&lt;span class=&#34;citation&#34;&gt;@thomasp85&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/thomasp85/status/1230773860321988608?ref_src=twsrc%5Etfw&#34;&gt;February 21, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Transformations that you &lt;em&gt;could&lt;/em&gt; conceptualize of as rotations will be animated as linear changes to coordinates. As a more extreme example, see animation of a matrix transformation for a &lt;span class=&#34;math inline&#34;&gt;\(180^\circ\)&lt;/span&gt; rotation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;animate_matrix_transformation(m = matrix(c(-1, 0, 0, 1), nrow = 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/transform_180degrees.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;One fix (irrespective of tweening method in &lt;code&gt;gganimate&lt;/code&gt;) could be to set specific coordinates at each frame (so that the lack of a true rotation wouldn’t be noticable)&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;problem-of-jittery-points-during-rotation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Problem of jittery points during rotation&lt;/h3&gt;
&lt;p&gt;Beyond the squishing, it appears coordinate points (added via &lt;code&gt;geom_point()&lt;/code&gt;) also look a little jittery during rotations.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;For example:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;points_start &amp;lt;- crossing(x = c(-3.5:3.5), y = c(-3.5:3.5)) %&amp;gt;% 
  mutate(id = nrow(grid_start) + nrow(basis_start) + row_number())
 
points_trans &amp;lt;- points_start %&amp;gt;% 
  transform_df_coords(x, y, m = rotate_trans)

points_all &amp;lt;- bind_rows(
  mutate(points_start, time = 1),
  mutate(points_trans, time = 2))

p_points &amp;lt;- p +
  geom_point(data = points_all, colour = &amp;quot;royalblue3&amp;quot;)

p_points + gganimate::transition_states(time, wrap = FALSE)

# maybe just my eyes... maybe need to increase framerate... or something

p_points &amp;lt;- p_rotation +
  geom_point(aes(x, y), data = points_all, colour = &amp;quot;royalblue3&amp;quot;)

p_points + gganimate::transition_states(time, wrap = FALSE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-20-visualizing-matrix-transformations-with-gganimate_files/figure-html/unnamed-chunk-23-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;miscellaneous-notes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Miscellaneous notes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I could not figure out how to add &lt;a href=&#34;https://ggplot2.tidyverse.org/reference/geom_polygon.html&#34;&gt;multiple polygons&lt;/a&gt; via &lt;code&gt;geom_polygon()&lt;/code&gt; in a way that kept smooth transitions&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;. Would likely need to explore &lt;code&gt;tweenr&lt;/code&gt;, &lt;code&gt;transformr&lt;/code&gt;….&lt;/li&gt;
&lt;li&gt;Would be nice to add &lt;code&gt;title&lt;/code&gt; of image as the matrix transformation being conducted&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;May be better to render to video (rather than gif) so could pause to view&lt;/li&gt;
&lt;li&gt;In general, could make more elegant / sophisticated… especially regarding how transformations are applied across layers
&lt;ul&gt;
&lt;li&gt;Would be nice if was set-up to apply the transformations across all (or specified layers).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;note-on-scales&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Note on scales&lt;/h2&gt;
&lt;p&gt;May want to make breaks extend across entire range (rather than just over x, y ranges of &lt;code&gt;grid_start&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Expand breaks in scales:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_breaks &amp;lt;-
  seq(
    from = 
      floor(min(c(grid_all$x, grid_all$xend))), 
    to = 
      ceiling(max(c(grid_all$x, grid_all$xend))), 
    by = 1)

y_breaks &amp;lt;-
  seq(
    from = 
      floor(min(c(grid_all$y, grid_all$yend))), 
    to = 
      ceiling(max(c(grid_all$y, grid_all$yend))), 
    by = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Which are shown throughout the series and most notably in chapters 3 and 13.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;See section [Problems and potential improvements] for notes on a couple potential updates I’ll make… not positive I’ll keep the gist code updated.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;And may not care about understanding how to do multiple transformations, adding additional layers, etc.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;/ vectors&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;I’m guessing there is a better / more elegant function already out there for ‘tidy matrix multiplication’ or something… but couldn’t immediately think of anything.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;You could add additional objects to the image – just need to ensure you create &lt;em&gt;start&lt;/em&gt; and &lt;em&gt;transformed&lt;/em&gt; versions of each object.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Creating these is not needed if you just wanted to create static images for the below examples.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;No real reason for choosing this transformation, just thought it looked cool.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;If wrap = TRUE (default) the reverse looping of the image is inaccurate as the transformation back to the original basis actually represents a transformation by the inverse of the &lt;code&gt;transformation matrix&lt;/code&gt;. Though leaving it in would look cooler.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;Could functionalize more… or make a shiny app, or do more with, see [Problems and potential improvements] for notes…&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Can largely skim over&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;Though this gets into decomposing the rotation, etc. components of the matrix transformation of interest for each frame.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Seems issue has to do with &lt;code&gt;group&lt;/code&gt; needing to apply both to the polygon at a given time as well as points on the polygon across time.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;Would require latex title which I don’t know if is supported by &lt;code&gt;gganimate&lt;/code&gt;&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Riddler Solutions: Palindrome Dates &amp; Ambiguous Absolute Value Bars</title>
      <link>/2020/02/13/fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/13/fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/str_view/str_view.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/str_view-binding/str_view.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#riddler-classic&#34;&gt;Riddler Classic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#on-duplicates&#34;&gt;On duplicates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#more-than-9-numbers&#34;&gt;More than 9 numbers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#define-more-rules&#34;&gt;Define more rules&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-gif&#34;&gt;Creating gif&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;This post contains solutions to FiveThirtyEight’s two riddles released 2020-02-07, &lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt; and &lt;a href=&#34;#riddler-classic&#34;&gt;Riddler Classic&lt;/a&gt;. Code for figures and solutions can be found on &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-02-13-fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs.Rmd&#34;&gt;my github page&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;riddler-express&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Riddler Express&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The riddle:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From James Anderson comes a palindromic puzzle of calendars:&lt;/p&gt;
&lt;p&gt;This past Sunday was Groundhog Day. Also, there was a football game. But to top it all off, the date, 02/02/2020, was palindromic, meaning it reads the same forwards and backwards (if you ignore the slashes).&lt;/p&gt;
&lt;p&gt;If we write out dates in the American format of MM/DD/YYYY (i.e., the two digits of the month, followed by the two digits of the day, followed by the four digits of the year), how many more palindromic dates will there be this century?&lt;/p&gt;
&lt;p&gt;– &lt;a href=&#34;https://fivethirtyeight.com/contributors/zach-wissner-gross/&#34;&gt;Zach Wissner-Gross&lt;/a&gt;, &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-roll-the-perfect-bowl/&#34;&gt;“How Many More Palindrome Dates Will You See,” FiveThirtyEight&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;My approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I took a simple brute-force approach. Within a dataframe and using a little code from R’s &lt;code&gt;tidyverse&lt;/code&gt; I…&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;created a column&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; containing each date from now until the end of the century&lt;/li&gt;
&lt;li&gt;created another column that contains the reverse of this&lt;/li&gt;
&lt;li&gt;filtered to only rows where the columns equal the same value&lt;/li&gt;
&lt;li&gt;counted the number of rows&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;dates&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;dates_rev&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;12022021&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;12022021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;03022030&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;03022030&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;04022040&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;04022040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;05022050&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;05022050&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;06022060&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;06022060&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;07022070&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;07022070&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;08022080&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;08022080&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;09022090&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;09022090&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Which shows there will be eight more pallindromic dates in the century – one in each decade remaining.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;riddler-classic&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Riddler Classic&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The riddle:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
Also on Super Bowl Sunday, math professor Jim Propp made a rather interesting observation:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
I told my kid (who’d asked about absolute value signs) “They’re just like parentheses so there’s never any ambiguity,” but then I realized that things are more complicated; for instance |-1|-2|-3| could be 5 or -5. Has anyone encountered ambiguities like this in the wild?
&lt;/p&gt;
— James Propp (&lt;span class=&#34;citation&#34;&gt;@JimPropp&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/JimPropp/status/1224177172362989571?ref_src=twsrc%5Etfw&#34;&gt;February 3, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;At first glance, this might look like one of those annoying memes about order of operations that goes viral every few years — but it’s not.&lt;/p&gt;
&lt;p&gt;When you write lengthy mathematical expressions using parentheses, it’s always clear which “open” parenthesis corresponds to which “close” parenthesis. For example, in the expression (1+2(3−4)+5), the closing parenthesis after the 4 pairs with the opening parenthesis before the 3, and not with the opening parenthesis before the 1.&lt;/p&gt;
&lt;p&gt;But pairings of other mathematical symbols can be more ambiguous. Take the absolute value symbols in Jim’s example, which are vertical bars, regardless of whether they mark the opening or closing of the absolute value. As Jim points out, |−1|−2|−3| has two possible interpretations:&lt;/p&gt;
&lt;p&gt;The two left bars are a pair and the two right bars are a pair. In this case, we have 1−2·3 = 1−6 = −5.
The two outer bars are a pair and the two inner bars are a pair. In this case, we have |−1·2−3| = |−2−3| = |−5| = 5.
Of course, if we gave each pair of bars a different height (as is done in mathematical typesetting), this wouldn’t be an issue. But for the purposes of this problem, assume the bars are indistinguishable.&lt;/p&gt;
&lt;p&gt;How many different values can the expression |−1|−2|−3|−4|−5|−6|−7|−8|−9| have?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;– &lt;a href=&#34;https://fivethirtyeight.com/contributors/zach-wissner-gross/&#34;&gt;Zach Wissner-Gross&lt;/a&gt;, &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-roll-the-perfect-bowl/&#34;&gt;“How Many More Palindrome Dates Will You See,” FiveThirtyEight&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;My approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The question is how many ways can you interpret the expression above. As hinted at by the author, the ambiguity in the expression becomes resolved based on where the parentheses are placed. Hence the question is how many different ways can we arrange the parentheses?&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-02-13-fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs_files/solutions_cropped.gif&#34; alt=&#34;Potential parentheses placements&#34; style=&#34;width:100.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Potential parentheses placements&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Constraints on placing parentheses:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parentheses form pairs, hence there must be an equal numbers of left-closed and right-closed parentheses, i.e. &lt;code&gt;)&lt;/code&gt; and &lt;code&gt;(&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;We need to avoid adding meaningless parentheses (that don’t lessen ambiguity). Hence like those on the left of this expression should not count as placing a parentheses:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;|(-1)|(-2)|(-3)| &lt;span class=&#34;math inline&#34;&gt;\(\Leftrightarrow\)&lt;/span&gt; |-1|-2|-3|&lt;/p&gt;
&lt;p&gt;Hence, we will say…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A bar can only have a single parentheses placed next to it (either a right or left closed)&lt;/li&gt;
&lt;li&gt;Right-closed will be placed to the left of a bar and left closed to the right of a bar, i.e. &lt;code&gt;|)&lt;/code&gt; and &lt;code&gt;(|&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;We can ignore the left and right most bars and say that a left-closed parenthese has to go on the left, and a right closed parentheses on the right, hence we can start the problem like “(|-1|-2|-3|)”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With these rules we can tackle the first part of the problem and think of each interior bar as representing a place-holder, the collection of which must be filled by an equal number of &lt;code&gt;)&lt;/code&gt; and &lt;code&gt;(&lt;/code&gt; .&lt;/p&gt;
&lt;p&gt;(|−1 _ −2 _ −3 _ −4 _ −5 _ −6 _ −7 _ −8 _−9|)&lt;/p&gt;
&lt;p&gt;This can be represented as a combinatorics&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; problem that can be represented by &lt;span class=&#34;math inline&#34;&gt;\(6 \choose 3\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We could use the &lt;code&gt;combn()&lt;/code&gt; function in R to generate all these combinations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;However&lt;/strong&gt;, there is a problem; some of the combinations created could result in configurations with open parentheses. For example, even on a shorter version of this problem, the rules above would not safeguard from configurations such as:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-1|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-2|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-3&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-4&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-5|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;that go against the rules of parentheses.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;You might take one of these approaches:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plug all combinations into a calculator and throw-out those that return an error&lt;/li&gt;
&lt;li&gt;define additional rules about the configuration of parentheses that will filter out those configurations, like the one above, that would break (more effort)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I ended-up doing it both ways (was a good way to verify my work). See &lt;a href=&#34;#define-more-rules&#34;&gt;Define more rules&lt;/a&gt; in the &lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt; if you want to see how you might take the latter approach. For now, I’ll go the easy route and start computing our expressions.&lt;/p&gt;
&lt;p&gt;One thing I needed to do was make it so our mathematical expressions, i.e.:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-1&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-2&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-3&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-4&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-5|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-6|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-7|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-8|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-9|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-1&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-2&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-3&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-4|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-5&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;|-6|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-7|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-8|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-9|&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;...&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Could be represented as meaningful expressions within the R programming language, i.e.:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-3&#34; style=&#34;width:960px;height:100%;&#34; class=&#34;str_view html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-3&#34;&gt;{&#34;x&#34;:{&#34;html&#34;:&#34;&lt;ul&gt;\n  &lt;li&gt;abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-1*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-2*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-3*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-4*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-5&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-6&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-7&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-8&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-9&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-1*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-2*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-3*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-4&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-5*abs&lt;span class=&#39;match&#39;&gt;(&lt;\/span&gt;-6&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-7&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-8&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;-9&lt;span class=&#39;match&#39;&gt;)&lt;\/span&gt;&lt;\/li&gt;\n  &lt;li&gt;...&lt;\/li&gt;\n&lt;\/ul&gt;&#34;},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;I made an equation &lt;code&gt;create_solve_expr_df()&lt;/code&gt; that creates the expressions and computes the solutions. See the &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-02-13-fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs.Rmd&#34;&gt;raw Rmd file&lt;/a&gt; on my github to see my code&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After creating all possible configurations, I need to actually compute each viable expression to check if any of the configurations resulted in duplicate solutions.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Number of different configurations of parentheses:&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solution_9 %&amp;gt;% 
  nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 42&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;There are 42 individual configurations.&lt;/strong&gt; However we need to check if all of the evaluated solutions are unique.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solution_9 %&amp;gt;% 
  distinct(evaluated) %&amp;gt;% 
  nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 39&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Given these particular inputs, there are only 39 unique solutions&lt;/em&gt;, meaning that three configurations of parentheses led to duplicate solutions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;div id=&#34;on-duplicates&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;On duplicates&lt;/h2&gt;
&lt;p&gt;You might wonder if a different set of inputs to the expression &lt;span class=&#34;math inline&#34;&gt;\(|x_1|x_2|x_3|...|x_9|\)&lt;/span&gt;&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; would lead to 39 unique solutions, or if there would be 42 unique solutions – one for each configuration. (I.e. whether the duplicates were specific to the integer inputs -1, -2, -3, -4, -5, -6, -7, -8, -9 into the expression, or would have occurred regardless of input).&lt;/p&gt;
&lt;p&gt;To verify that you could in fact get 42 unique solutions, I passed in random negative numbers with decimals to see if the function would output unique values for all configurations, or if there would again be duplicates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
solution_rand9 &amp;lt;- create_solve_expr_df(-runif(9))

solution_rand9 %&amp;gt;% 
  nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 42&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 42&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This led to an equal number of expressions and unique solutions – no duplicates. Hence the fact there were duplicates in our problem was specific to the inputs of -1 to -9 not something that would result when inputting any 9 numbers into this expression. I also found this to be the case on longer expressions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;more-than-9-numbers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More than 9 numbers&lt;/h2&gt;
&lt;p&gt;With the above set-up you could calculate the number of configurations for any length of input. Though I found that the computational time required increases quickly (once I started getting into problems into the 20’s things take a long-time to process). See below for a chart of unique solutions from 1 to 15&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-13-fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;define-more-rules&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Define more rules&lt;/h2&gt;
&lt;p&gt;We could define a few more rules about the configuration of our parentheses.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Counting from left to right, the number of &lt;code&gt;)&lt;/code&gt; should never exceed the number of &lt;code&gt;(&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Counting from right to left, the number of &lt;code&gt;(&lt;/code&gt; should never exceed the number of &lt;code&gt;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I couldn’t immediately think of a clean way of representing this using combinatorics, so instead decided to run a simulation on our existing subset of combinations from &lt;span class=&#34;math inline&#34;&gt;\(6 \choose 3\)&lt;/span&gt; that would filter out examples that break the above rules.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-02-13-fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs.Rmd&#34;&gt;My set-up&lt;/a&gt; took inspiration from David Robinson’s approach to a different &lt;a href=&#34;https://www.youtube.com/watch?v=TDzd73z8thU&#34;&gt;FiveThirtyEight “Riddler” problem&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   num_possible_combinations
##                       &amp;lt;int&amp;gt;
## 1                        42&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Gives the number of meaningful configurations of parentheses
&lt;ul&gt;
&lt;li&gt;Would still need to go and evaluate all of these for the given inputs (-1 to -9)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-gif&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating gif&lt;/h2&gt;
&lt;p&gt;I used &lt;code&gt;gganimate&lt;/code&gt; to create the gif of the different parentheses combinations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

set.seed(1234)
p &amp;lt;- solution_9 %&amp;gt;% 
  mutate(comb_index = row_number()) %&amp;gt;% 
  sample_n(42) %&amp;gt;% 
  select(comb_index, equation) %&amp;gt;% 
  ggplot()+
  coord_cartesian(xlim = c(-.050, 0.050), ylim = c(-0.1, 0.1))+
  geom_text(aes(x = 0, y = 0, label = equation), size = 6)+
  ggforce::theme_no_axes()+
  theme(legend.position = &amp;quot;none&amp;quot;, panel.border = element_blank())

p + transition_states(comb_index)
gganimate::anim_save(here::here(&amp;quot;static/post/2020-02-13-fivethirtyeightriddlersolutions-palindrome-debts-and-ambiguous-absolut-value-signs_files/solutions.gif&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;vector&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;khanacademy.org&#34;&gt;Khan Academy&lt;/a&gt; if you want to brush up on your combinatorics skills.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;The code isn’t &lt;em&gt;the most&lt;/em&gt; attractive. The dataframe set-up could be cleaner. Also I’d like to go back and rewrite the expression part of this using &lt;code&gt;rlang&lt;/code&gt; and some of the cool things you can do with manipulating environments and expressions in R… but alas… hacked this solution together by just stitching together text…&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Note that &lt;span class=&#34;math inline&#34;&gt;\(x_n &amp;lt; 0\)&lt;/span&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Note also that this problem requires that there be an odd number of inputs and that they all be negative.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Riddler Solutions: Perfect Bowl &amp; Magnetic Volume</title>
      <link>/2020/02/06/maximizing-magnetic-volume-the-perfect-bowl/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/02/06/maximizing-magnetic-volume-the-perfect-bowl/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#riddler-classic&#34;&gt;Riddler Classic&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#area-of-the-base-of-the-pyramid&#34;&gt;Area of the base of the pyramid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#height-of-the-pyramid&#34;&gt;Height of the pyramid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#encode-functions-and-calculate-volumes&#34;&gt;Encode functions and calculate volumes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;This post contains solutions to FiveThirtyEight’s two riddles released 2020-01-31, &lt;a href=&#34;#riddler-express&#34;&gt;Riddler Express&lt;/a&gt; and &lt;a href=&#34;#riddler-classic&#34;&gt;Riddler Classic&lt;/a&gt;. Code for figures and solutions can be found on my &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl.Rmd&#34;&gt;github page&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;riddler-express&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Riddler Express&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The riddle:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
At the recent World Indoor Bowls Championships in Great Yarmouth, England, one of the rolls by Nick Brett went viral. Here it is in all its glory:
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
12/10 on the mindblowing scale 🤯 &lt;a href=&#34;https://twitter.com/hashtag/SCtop10?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#SCtop10&lt;/a&gt;&lt;br&gt;&lt;br&gt;(via &lt;a href=&#34;https://twitter.com/BBCSport?ref_src=twsrc%5Etfw&#34;&gt;&lt;span class=&#34;citation&#34;&gt;@BBCSport&lt;/span&gt;&lt;/a&gt;) &lt;a href=&#34;https://t.co/6pN6ybzVel&#34;&gt;pic.twitter.com/6pN6ybzVel&lt;/a&gt;
&lt;/p&gt;
— SportsCenter (&lt;span class=&#34;citation&#34;&gt;@SportsCenter&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/SportsCenter/status/1220355057503363072?ref_src=twsrc%5Etfw&#34;&gt;January 23, 2020&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;In order for Nick’s green bowl to split the two red bowls, he needed expert precision in both the speed of the roll and its final angle of approach.&lt;/p&gt;
&lt;p&gt;Suppose you were standing in Nick’s shoes, and you wanted to split two of your opponent’s bowls. Let’s simplify the math a little, and say that each bowl is a sphere with a radius of 1. Let’s further suppose that your opponent’s two red bowls are separated by a distance of 3 — that is, the centers of the red bowls are separated by a distance of 5. Define ɸ as the angle between the path your bowl is on and the line connecting your opponent’s bowls.
For example, here’s how you could split your opponent’s bowls when ɸ is 75°:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://fivethirtyeight.com/wp-content/uploads/2020/01/bowls.gif&#34; /&gt;&lt;/p&gt;
&lt;p&gt;– &lt;a href=&#34;https://fivethirtyeight.com/contributors/zach-wissner-gross/&#34;&gt;Zach Wissner-Gross&lt;/a&gt;, &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-roll-the-perfect-bowl/&#34;&gt;&#34;Can You Roll The Perfect Bowl? FiveThirtyEight&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;My Approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Sketched-out:&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/bowl_calc.jpg&#34; alt=&#34;My drawings are rotated 90° clockwise from the problem description (does not affect solution)&#34; style=&#34;width:58.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;My drawings are rotated 90° clockwise from the problem description (does not affect solution)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Walked through:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I.&lt;/strong&gt; The minimum angle will be one where the green bowl touches points on both red bowls – this creates two tangents that you can think of as forming the track the green bowl travels down. Given the distance between the centers of the red bowls is 5 units, the distance between a green and a red bowl&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; will be half this, 2.5 units. Also, the lines tangent to a red bowl and the green bowl will pass a point halfway between this at 1.25 units from the center of a red circle&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;II.&lt;/strong&gt; Create the following three lines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Connect the centers of the red circles&lt;/li&gt;
&lt;li&gt;The line tangent to both a red circle and the green circle&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The line perpendicular to the tangent point on the red circle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Connecting these lines will create a right triangle with side length of 1 and hypotenuse of 1.25.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;III.&lt;/strong&gt; If you remember the &lt;em&gt;soh cah toa&lt;/em&gt; rules from trigonometry, you can use the identity &lt;span class=&#34;math inline&#34;&gt;\(sin(\phi) = \frac{opposite}{hypotenuse} \longrightarrow \phi = arcsin(\frac{1}{1.25})\)&lt;/span&gt; and compute the minimum angle is ~53.13°.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;What the path of the perfect bowl would look like:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/figure-html/bowl-perfect-path-figure-1.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;riddler-classic&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Riddler Classic&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The riddle:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From Robert Berger comes a question of maximizing magnetic volume:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Robert’s daughter has a set of Magna-Tiles, which, as their name implies, are tiles with magnets on the edges that can be used to build various polygons and polyhedra. Some of the tiles are identical isosceles triangles with one 30 degree angle and two 75 degree angles. If you were to arrange 12 of these tiles with their 30 degree angles in the center, they would lay flat and form a regular dodecagon. If you were to put fewer (between three and 11) of those tiles together in a similar way, they would form a pyramid whose base is a regular polygon. Robert has graciously provided a photo of the resulting pyramids when three and 11 tiles are used:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://fivethirtyeight.com/wp-content/uploads/2020/01/pyramids.png&#34; style=&#34;width:58.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;– &lt;a href=&#34;https://fivethirtyeight.com/contributors/zach-wissner-gross/&#34;&gt;Zach Wissner-Gross&lt;/a&gt;, &lt;a href=&#34;https://fivethirtyeight.com/features/can-you-roll-the-perfect-bowl/&#34;&gt;&#34;Can You Roll The Perfect Bowl? FiveThirtyEight&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;My Approach:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Magna-Tiles will form regular pyramids. The question is which &lt;em&gt;n-sided&lt;/em&gt; pyramid will have the greatest volume. &lt;span class=&#34;math display&#34;&gt;\[(Volume\;of\;a\;pyramid) = \frac{1}{3}(area\;of\;base)(height\;of\;pyramid)\]&lt;/span&gt; Hence we need to first calculate the &lt;a href=&#34;#area-of-the-base-of-the-pyramid&#34;&gt;Area of the base of the pyramid&lt;/a&gt; and the &lt;a href=&#34;#height-of-the-pyramid&#34;&gt;Height of the pyramid&lt;/a&gt;. I’ll set-up a way of calculating these as a function of the number of (75°-75°-30°) Magna-Tiles.&lt;/p&gt;
&lt;div id=&#34;area-of-the-base-of-the-pyramid&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Area of the base of the pyramid&lt;/h2&gt;
&lt;p&gt;The side length of the base of our pyramid will be the length of the shortest side of a Magna-Tile. We weren’t told the lengths of the sides of the Magna-Tiles but they don’t matter for this problem&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. To keep things simple, I’ll say the two congruent sides of the Magna-Tiles are equal to 1 unit.&lt;/p&gt;
&lt;p&gt;Drawing a line perpendicular to the base splits our Magna-Tile into two congruent triangles. Given the trigonometric identity that &lt;span class=&#34;math inline&#34;&gt;\(sin(\theta) = \frac{opposite}{hypotenuse}\)&lt;/span&gt; and that the hypotenuse of each triangle was set at 1 unit, we can calculate the length of the base of the Magna-Tile is &lt;em&gt;2sin(15°).&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/base_length.jpg&#34; alt=&#34;Base polygon side length&#34; style=&#34;width:58.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Base polygon side length&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I used &lt;em&gt;Math Open Reference&lt;/em&gt; to find an equation for &lt;a href=&#34;https://www.mathopenref.com/polygonregulararea.html&#34;&gt;area of a regular polygon&lt;/a&gt; as a function of side length and number of sides: &lt;span class=&#34;math display&#34;&gt;\[(area\;of\;regular\;polygon)\;=\;\frac{(side\;length)^{2}(number\;of\;sides)}{4tan(\frac{180^{\circ}}{number\;of\;sides})}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You can replace &lt;em&gt;(side length)&lt;/em&gt; in this equation with &lt;em&gt;2sin(15°)&lt;/em&gt; (calculated above),
making area a function of &lt;em&gt;only&lt;/em&gt; the number of sides on our pyramid (i.e. the number of Magna-Tiles).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;height-of-the-pyramid&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Height of the pyramid&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Sketched out:&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/height_calc.jpg&#34; alt=&#34;Finding pyramid height&#34; style=&#34;width:80.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Finding pyramid height&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Walked through:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The highest point of the pyramid will rest over the center of the base polygon. You can imagine a right triangle on the interior of a regular n-sided pyramid with its three line segments corresponding with:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I.&lt;/strong&gt; the length of a Magna-Tile (over its line of symmetry)&lt;br /&gt;
&lt;strong&gt;II.&lt;/strong&gt; an apothem of the pyramid’s base (an apothem is just a line segment from the center of a regular polygon to the middle of any side)&lt;br /&gt;
&lt;strong&gt;III.&lt;/strong&gt; the pyramid’s height&lt;/p&gt;
&lt;p&gt;Calculating &lt;strong&gt;I&lt;/strong&gt; &amp;amp; &lt;strong&gt;II&lt;/strong&gt; will enable us to use the Pythagorean Theorem to calculate the &lt;strong&gt;pyramid height&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I.&lt;/strong&gt; Length of a Magna-Tile (over its line of symmetry)&lt;/p&gt;
&lt;p&gt;Using the trigonometric rule that &lt;span class=&#34;math inline&#34;&gt;\(cos(\theta) = \frac{adjacent}{hypotenuse}\)&lt;/span&gt; reveals the length of a Magna-Tile as equal to &lt;em&gt;cos(15°)&lt;/em&gt; – remember we are treating the longest sides of the Magna-Tile as equal to 1 unit&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/mag_length.jpg&#34; alt=&#34;Magna-Tile length (over its line of symmetry)&#34; width=&#34;200&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Magna-Tile length (over its line of symmetry)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;II.&lt;/strong&gt; I used Math Open Reference to find the equation for &lt;a href=&#34;https://www.mathopenref.com/apothem.html&#34;&gt;apothem length&lt;/a&gt; as a function of number and length of sides in a regular polygon. &lt;span class=&#34;math display&#34;&gt;\[apothem\;length = \frac{side\;length}{2tan(\frac{180^{\circ}}{number\;of\;sides})}\]&lt;/span&gt; You can replace &lt;em&gt;side length&lt;/em&gt; in this equation with &lt;em&gt;2sin(15°)&lt;/em&gt; (calculated above), making apothem length a function of &lt;em&gt;only&lt;/em&gt; the number of sides on our pyramid (i.e. the number of Magna-Tiles).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;III.&lt;/strong&gt; Parts &lt;strong&gt;I&lt;/strong&gt; and &lt;strong&gt;II&lt;/strong&gt; represent two sides of a right triangle. To find the third side (corresponding with &lt;em&gt;pyramid height&lt;/em&gt;) simply use the Pythagorean theorem: &lt;span class=&#34;math display&#34;&gt;\[pyramid\;height = \sqrt{(MagnaTile\;length)^{2} - (apothem\;length)^{2}}\]&lt;/span&gt;
Fill in the values for &lt;em&gt;(Magna-Tile length)&lt;/em&gt; and &lt;em&gt;(apothem length)&lt;/em&gt; (as described in &lt;strong&gt;I&lt;/strong&gt; &amp;amp; &lt;strong&gt;II&lt;/strong&gt;) and you’ll see pyramid height is now represented as a function of &lt;em&gt;only&lt;/em&gt; number of sides (i.e. number of Magna-Tiles).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/height_calc.jpg&#34; alt=&#34;Finding pyramid height&#34; style=&#34;width:80.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Finding pyramid height&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;encode-functions-and-calculate-volumes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Encode functions and calculate volumes&lt;/h2&gt;
&lt;p&gt;I used &lt;a href=&#34;https://github.com/brshallo/brshallo/blob/master/content/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl.Rmd&#34;&gt;R to encode&lt;/a&gt; these functions&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; and calculate the volumes for pyramids built from 2 to 12 Magna-Tiles&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/figure-html/volumes-graph-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Volume increases up until 10 Magna-Tiles and then decreases at 11&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Bonus plot showing number of tiles (and size of pyramid base) vs pyramid height.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-02-06-maximizing-magnetic-volume-the-perfect-bowl_files/figure-html/heights-and-apothem-graph-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;When passing the line between the centers of the red circles.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;When passing the line between the centers of the red circles.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Could do for either or both circles and would get same solution as below steps will form congruent triangles – but following these steps using the top red circle more closely follows the story of the problem.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;As the pyramids created will be similar so each pyramid would scale proportionally to one another.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;In this case the longest sides are each a hypotenuse.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;In the code I use pi / 12 radians, which is equivalent to 15° used throughout the descriptions.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;2 and 12 Magna-Tiles represent flat structures ad therefore no volume.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;At 12 the structure is flat so no longer has volume.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Iceland Day 6: Perlan &amp; Departure</title>
      <link>/2020/01/01/iceland-day-6-perlan-departure/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/01/iceland-day-6-perlan-departure/</guid>
      <description>


&lt;p&gt;I did my best to convince Britney and my parents that we should start the morning with a ‘polar bear plunge’ in the ocean but was unsuccessful in convincing anyone (including myself) to participate. We slept in and had a relaxing morning before leaving the Airbnb at around 12PM.&lt;/p&gt;
&lt;p&gt;We headed to the Perlan, where we’d had dinner a few nights prior and which also served as the city’s science center&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. We watched an aurora show in the planetarium, trekked through an artificial glacial ice cave&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, walked around the city observation deck and perused various exhibits that showcased information on Icelandic geology and local flora and fauna. I fiercely negotiated with dad to let us stay as late as possible (our flight was at 5PM).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/U7aHuTI.jpg&#34; alt=&#34;Before the show started, the planetarium gave everyone a chance to flash selfies with the auroral backdrop overhead&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Before the show started, the planetarium gave everyone a chance to flash selfies with the auroral backdrop overhead&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/YcrIT62.jpg&#34; alt=&#34;Ice throne in the ice cave&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Ice throne in the ice cave&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/zUDm4Bc.jpg&#34; alt=&#34;Climbing the interior sides of an artificial ice cave&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Climbing the interior sides of an artificial ice cave&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After seeing the exhibits we raced back to the city center so that I could get one of the famous Icelandic hot dogs from Baejarins Beztu Pylsur&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. Dad was tense while driving – he likes to get to the airport several hours before his flight. Once I had a full belly I was able to stop teasing him about his “obsession with the airport lounge” and we eventually stopped trying to press each other’s buttons.&lt;/p&gt;
&lt;p&gt;It was light outside. I enjoyed gazing at the volcanic wasteland by the airport (something we couldn’t see in the darkness of our arrival flight). As our departure approached a vaporous haze slowly filled the air. The volcanic scenes faded into a misty canvased backdrop on which I played out memories from the week. When the airplane took-off it was too foggy to catch a final glimpse of the city, or to give a farewell – I guess we will have to come back.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Britney packed-up the car this time (rather than me), so we were no longer threatened by our bags tumbling all over us at any bump or sharp turn.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;As a result of the misadventures on Day 3, we’d had to miss an ice cave hike we’d planned, so the Perlan’s artificial ice cave provided a conciliation.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;It was near the Parliament building where our tour on day one had started.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Iceland Day 5: Blue Lagoon &amp; New Year’s Eve</title>
      <link>/2019/12/31/iceland-day-5-blue-lagoon-new-year-s-eve/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/31/iceland-day-5-blue-lagoon-new-year-s-eve/</guid>
      <description>


&lt;p&gt;We were out the door by 7:45AM and headed for the Blue Lagoon (where my parents had offered to treat us for the day). The regular Blue Lagoon pool had sold-out of tickets. Instead, we were ‘forced’ to get tickets to the Blue Lagoon &lt;em&gt;Spa Retreat&lt;/em&gt; – setting the stage for the most luxurious four hours of my life.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/KYJLPDA.jpg&#34; alt=&#34;Changing room in the Blue Lagoon Spa Retreat&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Changing room in the Blue Lagoon Spa Retreat&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In addition to access to the main lagoon, the retreat included four secluded winding pools that were perfect for laying back and slowly floating down. Everything was open and empty, it felt as though you were laying back in the mouth of your own personal volcano. There were also saunas, steam rooms, self-service salt scrubs, fire pits, even an on-demand photographer for goodness sake!&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/Nz7NQQq.jpg&#34; alt=&#34;Part of the winding pools in the Blue Lagoon Spa Retreat&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Part of the winding pools in the Blue Lagoon Spa Retreat&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;My parents also gave Britney and I their water massages because they said they simply “Wanted to spend the whole time together.” This may sound cute but was &lt;em&gt;actually&lt;/em&gt; just bad decision making.&lt;/p&gt;
&lt;p&gt;The water massage starts when “Chad” – muscle bound in a tight black nylon tank-top – invites you to lay onto a foam bed floating on the water. At first you may feel up-tight, but in his powerful arms and instructions to “make your limbs like wet spaghetti” you surrender yourself. Chad covers you with a warm water-soaked blanket and then cradles you while massaging every part. Floating there and safe in his arms you will never get so close to returning to the womb.&lt;/p&gt;
&lt;p&gt;We spent ~4 hours at the blue lagoon, drinking, eating, soaking, and &lt;em&gt;relaxing.&lt;/em&gt; When we got back to the Airbnb, Britney laid back for a nap and fell asleep with a slight upturned smile that was a picture of serenity.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/p5Px2tU.jpg&#34; alt=&#34;Leaving the Blue Lagoon&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Leaving the Blue Lagoon&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I took this time to continue my wanderings through Reykjavik. I stopped for some local Rhubarb flavored ice cream&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, then picked-up black volcanic table salt for my parents&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; and mushroom hot cocoa mix for Britney&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. I stepped into a clothing store (that was in view of the Christmas Cat) and purchased a locally woven wool scarf-blanket on behalf of my mom (which she gave to Britney to serve as a warm memento of the trip). I continued on my way, stopping at important sites across the city.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/nitD2KY.jpg&#34; alt=&#34;The “Voyager” statue behind me commemorates the Viking explorers and freedom&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;The “Voyager” statue behind me commemorates the Viking explorers and freedom&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Before returning to the apartment I went by the Hallgrimskirkja church courtyard and scoped out ideal spots for fireworks viewing. Iceland’s New Year’s celebration features one of the most impressive fireworks displays in all the world. Each resident spends several paychecks on fireworks (the selling of which is used to raise funds for public services) which are then set-off with increasing frequency leading up to midnight&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For dinner, dad, Britney, and I went down to an Italian place on Reykjavik harbor named Caruso&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;. Dad and Britney ordered pasta while I ate lamb. Once again, everything was delicious. Dad told stories about the history of lean-agile software development; I mostly looked out the window and enjoyed the water.&lt;/p&gt;
&lt;p&gt;We drove back to the Airbnb and laid on the bed for a few minutes. Britney and I were starting to feel worn down&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;. We eventually assembled ourselves and headed for the outskirts of Reykjavik to attend a traditional New Year’s bonfire event&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We could see the fire at a distance from our approach; the flaming orange stack stood over two stories high. Britney had me give her a piggyback ride across the wet grass; I sloshed us over to the encirclement. We arrived just as the locals were singing a final Icelandic song and throwing the last few planks of wood onto the blaze.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/B3RhKj5.jpg&#34; alt=&#34;New Year’s Eve bonfire at Geirsnef park&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;New Year’s Eve bonfire at Geirsnef park&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The sounds of the crackling wood were mixed in with amicable banter between us and a German couple with whom we compared itineraries. The park gave an expansive view of the city, which was starting to come alive with fireworks. Flashes in the distance left sparkling plumes that alighted over the massive conflagration before us. I sipped a poorly concocted mushroom cocoa &amp;amp; coconut vodka mix from a thermos and basked in the heat.&lt;/p&gt;
&lt;p&gt;I asked a local if there was any hidden meaning in the bonfire. I posited (paraphrasing here), “Is the destruction in the flames symbolic of the transformation that comes with a New Year? The fiery brilliance a celebration of the volcanic beauty of the country?” He assured me there was not any special significance and that in Iceland (like many places) they simply liked to make big fires at parties.&lt;/p&gt;
&lt;p&gt;We headed back to the Airbnb. Britney started to pack our stuff-up. I sat on the balcony and watched the fireworks sparkle across the city. At 11PM the fireworks paused as 90% of Icelandic citizens went inside to watch an annual cultural comedy sketch-show. Britney and I pulled-up an English subtitled version of the 2018-2019 episode. We found most of the bits funny and prided ourselves on how &lt;em&gt;earnestly&lt;/em&gt; we felt we were appreciating the local culture&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These fond feelings soon soured though when we realized that, if we’d left 5 minutes earlier, we could have beaten the locals out and made it to a prime location in front of Hallgrimskirkja church&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. Instead we got caught in the deluge of people reclaiming their spots and had to settle at the edge of the courtyard, pressed against the buildings. We still had a great view but I was jealous of my parents who had left only minutes before us and were now seated at the &lt;em&gt;exact&lt;/em&gt; location I had picked-out&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The fireworks started to pick-up again. Explosions came in different colors from all directions. The show felt layered, distant rockets from disparate launch sites cascaded across the sky. Smoke clouded the landscape and captured the light making each new flash brighter than the one previous.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/gD8ObcwygPw&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Britney and I went back to the apartment around 12:30AM. Britney went to sleep early&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;, I stayed up watching the fireworks from our balcony.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/u8OiLoBV3uw&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Dad texted me the bar where he and mom were. He misspelled things terribly but I eventually figured it out and headed down to meet them. Mom didn’t know dad had texted me so was overcome with excitement at the seemingly serendipitous event of me ending up at the same bar as them (an idea I didn’t spoil until the next morning). She’d made friends with a Swedish couple. They exchanged numbers and plans to visit each other in their respective countries&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I drank hot cocoa and Moscow Mules and told stories about my wonderful bride-to-be. The Swedish woman told me tales from her trip. She showed me a picture of her and her husband in front of a beautiful aurora but explained that she actually hadn’t seen it with her naked eyes. Their ‘aurora guides’ had needed to use a high-exposure cameras to pick-up the light&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt;. She described the whole ‘aurora hunting’ tour as a ploy only good for capturing instagramable photos. I felt proud of the few wispy seconds Britney and I had caught the night before on our drive back from Diamond Beach.&lt;/p&gt;
&lt;p&gt;My parents thanked me for compelling them to stay up to watch the fireworks for the New Year’s Eve celebrations. They staid out while I went back in. I laid down next to Britney. Fireworks pounded at the windows but I had no trouble sleeping.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Iceland is famous for their unique flavors of ice cream served year round.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;One of dishes at the Blue Lagoon had featured this volcanic salt prominently and my parents love fancy salts.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Which she ended-up not liking.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;I asked several vendors where I might be able to purchase fireworks for myself but was out of luck as they weren’t for sale to tourists in the city at this point. Apparently the fireworks were sold at schools or fire stations in public fundraising events held outside of downtown in the weeks prior – my lack of success in this venture was probably a good thing.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Mom stayed back and took a nap so that she’d have the energy to stay-up for the fireworks.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;Likely in part due to our frigid evening in the car the other night&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;One of several that are held all around the city.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;I forget where we found a version of the show with English subtitles.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;That I’d picked-out during my daytime wanderings.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;I climbed-up a few feet on some iron pipes on the building to give us a better view. This was largely unnecessary as the fireworks exploded overhead, so your height relative to the crowd did not particularly matter.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;She was fighting off a little bit of a head-cold – likely brought on by the frigid night in the car earlier in the trip.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;Mom is the kind of person that makes friends in every room she enters&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;The guides had called them ‘ghost auroras’.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Iceland Day 4: Southeast Coast &amp; Diamond Beach</title>
      <link>/2019/12/30/iceland-day-4-southeast-coast-diamond-beach/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/30/iceland-day-4-southeast-coast-diamond-beach/</guid>
      <description>


&lt;p&gt;Britney and I awoke several times in the night to the frigid cold. We would run across the street to a patch of trees where we could relieve ourselves and get away from the streetlights. I looked up to the stars and the clear night sky clinging faintly to a hope that whatever damage might be done to the car, it was all part of a plan for us to be at this exact point. For what? – maybe to see a brilliant aurora. “What’s an engine compared to a bucket-list experience?” I’d try to convince myself. The stars were beautiful but there were no dancing lights this night to ease my conscience.&lt;/p&gt;
&lt;p&gt;In order to fall back asleep I had to put my head completely under the blankets and make my breath into a mini-heater (we didn’t turn the car on out of fear of damaging the engine). This made me claustrophobic and mildly concerned about CO2 poisoning but was better than letting the icy air get my face. I finally got some sleep. (When we eventually got the car working we had to scrape the ice off both the outside as well as the inside of the car.)&lt;/p&gt;
&lt;p&gt;I got-up a little before 9AM and tried calling ‘Mr. Kristy’. It didn’t connect, I had the wrong number. I put my boots on and ran down the street to a rental car company that was just opening. The manager there pointed me to a car repair shop two stores over. At the shop they mentioned a Mr. Kristy – I cheered (Kristy it seemed specialized in fixing this issue for Nissan’s – which he apparently did a dozen times a day in the summer months). They called him, he said he’d be there in ten minutes.&lt;/p&gt;
&lt;p&gt;I ran back to the car. In 30 minutes, we were fixed-up with no damage to the engine, the correct gas in the car, and a fair fee paid. PRAISE!&lt;/p&gt;
&lt;p&gt;We adjusted our plans so that we’d get to Diamond Beach around sunset and then would drive back to Reykjavik at night (and hunt for auroras). On the way to Diamond Beach we stopped at various stunning water falls along the coast.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/Li9tx68.jpg&#34; alt=&#34;Seljalandsfoss falls&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Seljalandsfoss falls&lt;/p&gt;
&lt;/div&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/6ie3-znWsVM&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;At the top of Skogafoss Falls were thousands of bird nests&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/D__9kYs9Hug&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Our 4-hour drive took us over a diversity of landscapes that included rocky deserts, cliff faces with frozen rivers, and multi-mile wide beaches formed from glacial movements. It was a dazzling drive.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/yYMQUUQ.jpg&#34; alt=&#34;One of dozens of small frozen waterfalls we drove past&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;One of dozens of small frozen waterfalls we drove past&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The first black sand beach we stopped at was Reynisfjara. Reynisfjara has a pedestaled cliff face that you can easily climb-up and overlook the crashing waves from the North Atlantic ocean.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/MjtnDIn.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/hXXBdMu.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At the edge of the ocean are the remains of ancient basalt rock columns. Icelandic legend has it they were formed by trolls dragging a ship towards land who were stopped in their tracks and turned to stone by the dawning sun.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/2JQKvoK.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At the far side of the beach is a shallow cavern of glistening jagged rocks. A light drip of water was falling from overhead.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/x7ZVW3g3snE&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;On the way to Diamond Beach our longest stop was a hike we took up Skaftafell falls. The waterfall inspired the design of the famous Hallgrimskirkja church near our apartment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/jGtK66T.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We finished our hike and raced to Diamond Beach where we caught the last glimmers of daylight. The ‘diamonds’ come from nearby glacial runoff that gets polished in the ocean and then washes up here as tremendous shimmering blocks of ice that blanket the black pebble beach&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/5q2wSlM.jpg&#34; alt=&#34;Arriving at Diamond Beach&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Arriving at Diamond Beach&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/VgP05YA.jpg&#34; alt=&#34;On one knee giving Britney this 10,000 carat rock&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;On one knee giving Britney this 10,000 carat rock&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/sKHn2a5.jpg&#34; alt=&#34;Submarine shaped ice&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Submarine shaped ice&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/ZDCH5fN.jpg&#34; alt=&#34;Dolphin shaped ice&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Dolphin shaped ice&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I laid there for a while. High tide started to come in and the approaching sound of massive ice blocks tumbling in the waves alerted me that it was time to head back. Britney took a nap in the car. I started us back West.&lt;/p&gt;
&lt;p&gt;The return trip was more direct, we made just two quick stops. One in the town of Hof to see a church that looked as though it grew from the earth and belonged in The Shire. Another was an unsuccessful search for a geologic site we’d skipped over in our rush to get to Diamond Beach before sundown&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The sky was clear now. We drove for long stretches with the windows rolled down peering at the unfiltered stars. Three hours into the drive Britney noticed a faint greenish-gray fluttering in the sky. We gasped and shouted excited confirmations to each other of what we were seeing. It was wispier than clouds but moved like liquid in the sky. In just a few seconds it dissolved into the blackness of the night. That ghostly image was the only glimpse of an aurora we caught on the trip. We should have pulled over at that spot as the sky soon filled with clouds and our hunting was over.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;We’d see these same birds and nesting behaviors on the cliffs of the black sand beach at Reynisfjara.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;A few miles beyond this spot would have taken us to the opening of Eyjafjallajökull which erupted in 2010 causing havoc in Iceland and Western Europe.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;At local foodtrucks in a campsite down the road we picked-up a lobster roll, lobster bisque (Britney’s third on the trip so far), fried cod and fries, then headed back to Diamond Beach.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;When we stopped to search, we did see a cloistered group of people in minivans that seemed surprised at us stopping near them. At first we thought maybe they were star gazing but it seemed they were meeting for some other purpose we could not divine. We continued on our way.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Iceland Day 3: Thingvellier &amp; Disaster</title>
      <link>/2019/12/29/iceland-day-3-thingvellier-disaster/</link>
      <pubDate>Sun, 29 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/29/iceland-day-3-thingvellier-disaster/</guid>
      <description>


&lt;p&gt;We slept in a little later this morning (930AM), had Skyr parfaits with mom and dad for breakfast and more croissants from Brauð &amp;amp; Co. We drove back to the UNESCO World heritage site, Thingvellier, that we’d attempted to visit the morning before. We arrived close to sunrise (there was no creepy white pickup truck in the parking lot this time).&lt;/p&gt;
&lt;p&gt;The drive out was beautiful and easy. The browning grass and gnarled branches by the road seemed almost a pastoral desert (except for all the wetness). The dim sunlight softened the jagged lines of volcanoes that could now be seen in the distance. The foreign space we had driven through in fear and darkness 26 hours prior now felt almost inviting.&lt;/p&gt;
&lt;p&gt;Thingvellier is important for many reasons, most of which have to do with different kinds of &lt;em&gt;meetings&lt;/em&gt;. It is where the North American and Eurasian plates meet to create stunning crevices and rock formations. It’s where ancient Icelandic village leaders met for inter-tribal gatherings and formed some of the earliest representative(-ish) government structures in Europe. It is where Iceland’s independence was signed after the second World War. Thingvellier’s stunning beauty makes it unsurprising that the site has served as a significant location across much of Iceland’s history.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/IMWiLed.jpg&#34; alt=&#34;Where American and Eurasian continental plates meet&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Where American and Eurasian continental plates meet&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;With all this significance around me I was floored… several times… &lt;em&gt;literally&lt;/em&gt; – the icy rocks contributed but so did my getting distracted by the stunning views at every step.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/IjAMOnS.jpg&#34; alt=&#34;Britney had spiked crampons and was sure-footed, I mostly struggled on behind her.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Britney had spiked crampons and was sure-footed, I mostly struggled on behind her.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/QEO1VgY.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/RjHIkAO.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Much of the snow was paved off the main path and pushed into mounds against the rock formations.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/Ics51i8.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At higher points the snow piled up to 20 meters over the trail. We took these as an opportunity to go sledding.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/_D5lehIvB68&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;We also explored Thingvellier’s many small rivers and lowlands. When the wind settled the water would become as clear as glass. Some places were filled with coins and wishes people had thrown in&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/3yHTaZG.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The drive back after sunset was equally stunning. We met my parents for 530PM reservations at Perlan (“The Pearl”) for dinner. The restaurant was encased in a glass dome and rotated to give a slowly moving &lt;span class=&#34;math inline&#34;&gt;\(360^{\circ}\)&lt;/span&gt; view overlooking the city. It was a nice family dinner, complete with competitions over who could calculate the speed of rotation of the building first&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/BQLf0YW.jpg&#34; alt=&#34;Dinner at Perlan&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Dinner at Perlan&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After dinner we packed-up for an overnight trip down Iceland’s southeast coast. We planned for a five hour aurora hunt &amp;amp; drive towards black sand Diamond Beach, where we planned to camp for the night in the SUV.&lt;/p&gt;
&lt;p&gt;Outside the city, we stopped for gas. Britney was getting extreme cravings for pizza and had the Subway worker do their best to construct a veggie pizza for her&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. I was hyper-focused on using the green pump to fill the car with (as the Nissan X-trail was a diesel rather than petrol vehicle).&lt;/p&gt;
&lt;p&gt;We resumed our drive and Britney remarked that her dad had almost gotten her a diesel Volkswagen Bug when she was in college but had been nervous about someone borrowing it and filling it with the wrong type of gas. I noted that if you had stickers on the fuel cap and relevant locations in the car (as our rental did) that I thought it would be &lt;em&gt;pretty difficult&lt;/em&gt; to make such a mistake. Britney disagreed and we started to debate the topic. In the middle of me making a snide remark, the car started to hiccup. I slowed down but it kept lurching. We were over an hour from Reykjavik.&lt;/p&gt;
&lt;p&gt;I pulled into the gas station of a tiny town and got out to look at the fuel pumps. A sinking feeling ran over me as I noticed that petrol was &lt;em&gt;green&lt;/em&gt; and diesel was black (reverse of the colors in the USA). We called the gas station and had them look up the order associated with my credit card, which confirmed my mistake.&lt;/p&gt;
&lt;p&gt;I spent the next hour reading worst-case scenarios on the damage I might have caused the engine&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. We looked-up numbers for the rental car company and emergency car repair, most of which didn’t answer and none of which could help us. A taxi pulled-in behind us to fill-up. I approached him and explained our situation. He called someone on our behalf. A ‘Mr. Kristy’ answered who indicated he could come by in the morning. The cabby gave me the number and I told ‘Mr. Kristy’ I would give him a call if we weren’t able to fix it before then.&lt;/p&gt;
&lt;p&gt;After struggling through options for another hour we decided to call it quits, get some sleep, and start afresh in the morning. Through all of this Britney was as magnanimous as any person you have ever met.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Though signs discouraged doing such.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Britney and I continued to order seafood. Though for my starter I had goose soup. We should be eating more goose in America. Whatever happened to a Christmas goose? Bring it back!&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Despite them being out of mini-pizzas, flatbread, mozzarella, and several other key ingredients.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;And feeling more idiotic than I’ve ever felt in my life.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Iceland Day 2: Golden Circle &amp; Snowmobiling</title>
      <link>/2019/12/28/iceland-day-2-golden-circle-snowmobiling/</link>
      <pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/28/iceland-day-2-golden-circle-snowmobiling/</guid>
      <description>


&lt;p&gt;I grabbed an assortment of croissants from Brauð &amp;amp; Co, half a block from our apartment. We were on the road headed East by 7:05AM.&lt;/p&gt;
&lt;p&gt;The morning was strikingly dark. Clouds obscured any starlight. A soft rain made everything reflective. Faint glimpses of small trees and twisted wooden branches looked like alien figures on the side of the road. I drove nervously, stooping over the wheel like my dad had the morning before. Leaving Reykjavik, I sped through a robotic speedometer that flashed as I passed it – the light surprised me and caused me to drive exceedingly slow for the next hour&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We arrived at the UNESCO World Heritage Site, Thingvellier, at 8:10AM. There was a white pickup truck driving in loops at the far side of the parking lot, otherwise it was empty. I left the keys in the car and stepped out to explore. It was still pitch-black but the rain had stopped and, other than the pickup in the distance, the lot was silent. Britney and I felt as if we were in the beginnings of a horror movie (but did not mention this to one another until later). I walked towards the nearest building. A motion sensor clicked and automated lights flickered on. It was a water closet. I edged towards the next building, the Information Center, which noted that the park didn’t open until 9:00AM. I peered inside at maps and museum placards before wandering around to the side. I turned on my phone’s camera light but it was too dark to pick-up a trail. I looked back and saw the white pickup had parked &lt;em&gt;not quite far enough away&lt;/em&gt; from where Britney sat in our SUV. I hurried back. We buckled-up and continued on our way to Gulfoss Falls, the meeting point for our 10AM Snowmobile-Glacier tour.&lt;/p&gt;
&lt;p&gt;On the drive we saw mysterious orange hazy lights illuminating the clouds. The colors were too static to be auroras; the sky wasn’t clear enough anyways. There also weren’t any cities out this far that could explain them. We went on several detours trying to identify their source. These took us down dirt roads and across small one-lane bridges. Eventually we had to turn back towards Gullfoss Falls without an answer. The off-roading helped my confidence though and for the rest of the trip (across black lava cracked landscapes, icy winds, …) I felt comfortable behind the wheel.&lt;/p&gt;
&lt;p&gt;We arrived at Gulfoss Falls at 9:30AM&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. We waited in the car with the heat on. Other tourists slowly filled-up the lot around us (I kept an eye-out for the white pick-up but never saw it). Our bus pulled-up; “Mountaineers of Iceland” was printed on the side in lavish maroon letters that reminded you this was a staged attraction. However the tremendous wheels of the vehicle, almost twice the diameter of those on our Nissan X-trail, still made us excited as we imagined the fissures of ice and mud it was designed to take us over. We crowded into the bus carrying a pack of snacks and big smiles.&lt;/p&gt;
&lt;p&gt;The sun rose, the ascent up the glacier was our first view of Iceland’s remarkable natural volcanic beauty. Each new mountain seemed larger and icier than the one before. As we traversed Langjokull glacier the temperate rainy climate turned into a foggy snow flurry. We were dropped-off at a large wooden barracks that had several feet of snow piled against it. We ran into the warm interior, changed into jumpsuits, and put on scratched-up motorbike helmets with thick front visors.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/pJUIcb4.jpg&#34; alt=&#34;Our jumpsuits&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Our jumpsuits&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From there another truck (with even larger wheels!) picked us up. Fifteen bumpy minutes later we were dropped off in front of rows of snowmobiles and a half dozen guides. We approached a woman in her early 20’s of Southeast Asian descent who wore a white and blue stitched beanie and carried a somewhat aloof though friendly demeanor&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/rUyAWAT.jpg&#34; alt=&#34;Britney on our snowmobile&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Britney on our snowmobile&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;She showed us the key parts of the snowmobile, the correct distance to follow at, and what to do if we got lost or fell off. Britney and I took the third vehicle in line (behind the guide and an unassuming older-middle aged woman). I drove for the first stretch with Britney behind me. The guide explained that you could either hold onto your partner or onto the bars on the side. She warned that if you held onto your partner you’d both be going down together. Britney chose the bars, which proved to be a good decision&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The tour started fast and stayed that way. Visibility was bad and made worse by the thick visor that fogged-up with each breath (which came quicker as we sped along and I became increasingly fatigued). Turning was a sheer act of will that required lurching your bodyweight from one side of the vehicle to the other. This was made more difficult by me frequently losing sight of the path, getting off the main trail, and needing to push through thick patches of snow to get back on track.&lt;/p&gt;
&lt;p&gt;I strained to keep the dim taillights of the lead snowmobiles in front of me. In the gaps between flurries I’d put my visor-up and squint through the blistering wind, doing my best to keep sight of them. Pride and fear kept us from falling behind. Grace kept us from falling off. The only real breaks came from snowmobilers behind us who tipped over or got left behind and who we had to circle back for.&lt;/p&gt;
&lt;p&gt;After 30 thrilling, grueling, awesome minutes, we got to a rest spot. The guide was pleased and said we were one of the fastest tours she’d had&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;. Britney and I shared a congratulatory kiss before splaying our exhausted selves out in the snow, a sad excuse for snow angels.&lt;/p&gt;
&lt;p&gt;We drank water, snacked, built a snowman, and got in a half-hearted snowball fight with the tour guides before hopping back on our snowmobile. This time with Britney in front.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://i.imgur.com/yTgpSWq.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The ride back was equally gripping&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;. We again had a few near falls but made-it. After the tour we chatted with the middle-aged woman who had been immediately in front of us. She was from the Northeast United States and visiting the country with her daughter&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;. We learned she was an expert alpine skier (which helped explain why she was such a badass snowmobiler). We changed out of our jumpsuits and took the scenic ride back to our cars&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We walked to an overlook of Gulfoss Falls&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. It was so windy and cold we only stayed for a few minutes.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/Y4O832o.jpg&#34; alt=&#34;Gulfoss falls&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Gulfoss falls&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Next stop was Geyser (the &lt;em&gt;OG&lt;/em&gt; of geysers, as in the &lt;em&gt;original geyser&lt;/em&gt; that all other geysers are named after). Geyser is no longer active, but several other geysers at the site are. Some barely more than gurgle, others, like Strokkur, go off every 8 minutes and can have eruptions as tall as 40 meters.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/5VMjtS_U9wU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/wXvQgZ8.jpg&#34; alt=&#34;bubbling geysers&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;bubbling geysers&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For dinner, we went across the street to Geyser hotel. I was a bit of a nuisance to get us a table by the window where we could watch eruptions while we ate. At one point two geysers went off back-to-back, making a double geyser&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After a relaxed dinner we drove 35 minutes southwest to Secret Lagoon (a small hot springs). It was dark again and the mysterious orange lights returned. We tracked one down and learned they were greenhouses that stayed artificially lit through Iceland’s long nights&lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;. Secret Lagoon was next to a greenhouse and colored the hot spring’s steam in a smokey fire orange&lt;a href=&#34;#fn12&#34; class=&#34;footnote-ref&#34; id=&#34;fnref12&#34;&gt;&lt;sup&gt;12&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The lagoon is the oldest operating public pool in the nation. It is not fancy (almost the anti-Blue Lagoon) but provided a perfectly subdued end to our day. We grabbed a few floaties&lt;a href=&#34;#fn13&#34; class=&#34;footnote-ref&#34; id=&#34;fnref13&#34;&gt;&lt;sup&gt;13&lt;/sup&gt;&lt;/a&gt; and spent the next few hours drifting through the hot water.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/uMXkC2izpSY&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;Hot springs have their temperatures regulated. However even relatively small ones are so big that it’s impossible to keep the temperature constant. This pool in particular featured patches of cool spots as well as searing hot spots. It became a game to dodge the extreme parts and find the most amenable areas to float in. We took turns with one person laying back on floaties and the other person dragging them on a tour around the pool&lt;a href=&#34;#fn14&#34; class=&#34;footnote-ref&#34; id=&#34;fnref14&#34;&gt;&lt;sup&gt;14&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;We eventually realized it was perhaps the only speedometer in the country.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;I walked around in the parking lot a little bit – I could hear Gulfoss Falls in the distance, but it was still dark and hard to find my way around.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Almost all Icelandic natives are white, and I wondered if she was visiting from New Zealand or Australia and was working here for the winter (as is common in sky resorts in eastern Washington) but I couldn’t quite place her accent.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Driving the snowmobile proved utterly draining. If she’d held onto me (as I’d encouraged) I’m sure we’d have ended-up in the snow.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;And that we’d gone 50, 60 kms, when 30’s was more typical.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;Years of jetskiing behind my older brothers in the North Carolina isles had made me attuned to leaning with Britney’s turns.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Who had been a few vehicles behind us and was one of the individuals that had fallen off.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;Which Britney slept through.&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;When we’d arrived in the morning it had been too dark to see the falls, there was just the sound of pounding water in the distance. Being able to now &lt;em&gt;see&lt;/em&gt; it was an absolute delight.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;If you like double rainbows, you would love double geysers.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;Because of all the geothermal activity in Iceland, energy is VERY cheap, so greenhouses make more economic sense and are the only way to grow fresh produce on the rocky, bracken island&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn12&#34;&gt;&lt;p&gt;To ‘prepare’ for our float we first pulled into a parking spot that was shaded from the greenhouse lights and took a 40 minute nap.&lt;a href=&#34;#fnref12&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn13&#34;&gt;&lt;p&gt;Which rested by the dozens all around the rim of the pool.&lt;a href=&#34;#fnref13&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn14&#34;&gt;&lt;p&gt;By “taking turns” I mean that Britney spent most of the time laying back on the floaties while I pulled her around the springs&lt;a href=&#34;#fnref14&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Iceland Day 1: Landing &amp; City Tour</title>
      <link>/2019/12/27/iceland-day-1-landing-city-tour/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/12/27/iceland-day-1-landing-city-tour/</guid>
      <description>


&lt;p&gt;My parents, Britney and I landed in Reykjavik at 630AM. We’d taken an eight-and-a-half-hour overnight flight from Seattle. It was dark when we stepped off the plane and would remain dark until 11AM (in wintertime Iceland only gets 4-6 hours of sunlight a day).&lt;/p&gt;
&lt;p&gt;I packed the bags into haphazard piles that poured over the rear storage area of our rented Nissan X-trail. The air was a cold mix of rain and mist. Dad struggled with the defroster and drove with a frenetic nervousness that was magnified by a lack of sleep, food, or familiarity with his surroundings. The first jerky turn launched a carry-on into Britney’s chest. For the remainder of the drive I strained to hold the luggage in place while everyone, except dad and I, caught up on rest.&lt;/p&gt;
&lt;p&gt;It was too dark to see the landscape. The first interesting ‘sights’ were the abundant (though not ostentatious) Christmas decorations. We passed a complex of three 15 story apartment buildings where every room facing the highway had a Christmas tree with lights on in the window.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/sEjzjnh.jpg&#34; alt=&#34;Picture was taken later but shows the consistency of Christmas decorations in apartment windows&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Picture was taken later but shows the consistency of Christmas decorations in apartment windows&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After a few missed turns we eventually made it to our apartment building. Britney and my Airbnb had a cute living room and a full (though miniaturized) kitchen. The bedroom was spacious (when there’s scarcity Britney tends to spread out and take over whatever space is nominally mine – be it on the floor, the bathroom counter, the couch, …). We were on the top story. Our ceilings sloped inwards accommodating the building’s roof&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. The apartment was formed into a sort of trapezoidagon that forced us to duck at the edges of the rooms – if we weren’t tourists this would have been annoying but for us it added a perfect dash of charm. We had a balcony that faced the North end of the city and the ocean. Stepping outside you could see the spotlight from the Imagine Peace Tower (in honor of John Lennon) shining into the clouds from a nearby island&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. Through the south window the top edge of the Hallgrimskirkja church (just a block away) peaked-out over the buildings.&lt;/p&gt;
&lt;p&gt;My parents’ room was four floors below in the relatively spacious basement. Mom took a nap while dad, Britney, and I wandered the streets for food. It was still early, most places were closed but we eventually stumbled into a boutique hotel’s breakfast buffet. I had 5 carrot-beat shots, 4 cups of Skyr (Icelandic yogurt) parfaits, and an array of fermented cod (some of which I loved, some of which I &lt;em&gt;really&lt;/em&gt; did not) and smoked salmon.&lt;/p&gt;
&lt;p&gt;Britney and I planned on a 12PM “free” (tip based) walking tour but took a nap that lasted until 12:15PM so ended-up at the 2pm tour. It was still wet outside when we left. The wind and rain at times reminded us of that from our respective hometowns: it could be temperate, polite but almost passive aggressive, like in Seattle; at other times it whipped at your face and made you beg for mercy, as in Chicago.&lt;/p&gt;
&lt;p&gt;On our walk to the Althingi Parliament House (the tour meeting point) we passed a 20-foot black metal feline structure with piercing red eyes and great yellow teeth. It looked as though it had been born in Hell and sprang from one of Iceland’s many volcanoes. From our guide we learned that it was a sculpture of the ‘Christmas Cat’ who, legend has it, would devour people that didn’t get new clothes for the holidays&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. The Christmas Cat also worked as an agent of the giantess Gryla, an Icelandic (and murderous) version of Santa Claus, who snatched bad little children up to a cave and cooked them into a stew. Throughout the trip, whenever I got on Britney’s nerves she’d threaten she was going to call Gryla to come and get me.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/KTSCV07.jpg&#34; alt=&#34;The Christmas Cat and I&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;The Christmas Cat and I&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Our guide Arik&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; was good humored and welcomed the many questions I peppered him with throughout the tour. He also wore an oversized thick yellow jacket, similar to one I’d brought for the trip, which provided an immediate source of kinship between us&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/07U5IhQ.jpg&#34; alt=&#34;Rainbow street, in the distance you can see Hallgrimskirkja church&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Rainbow street, in the distance you can see Hallgrimskirkja church&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In back of the parliament building and just in front of Tjornin Lake was a statue of a man in a suit walking with a cube of stone over his head (get it?), named “Monument to the Unknown Bureaucrat”&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;. I asked Arik about politics in Iceland, and if people were frustrated with their leaders in the same way citizens in other (larger) nations tend to be. He explained that with a population of less than 400,000 people&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; they have more direct access to politicians but contended there are still many of the same frustrations and a similarly wide range of ideologies. He also noted a greater concern with nepotism… I argued it was an issue in American politics as well.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://i.imgur.com/tm76mFe.jpg&#34; alt=&#34;Monument to the Unknown Bureaucrat (i.e. blockhead)&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Monument to the Unknown Bureaucrat (i.e. blockhead)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We ended the tour at the beautiful City Theatre of Reykjavik. As parting gifts Arik gave us chunks of licorice from local vendors and provided some closing notes about the country and its people&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt;. I thought about continuing to chat with Arik and seeing if I might be able to get us invited to a local Icelandic house party&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;. However I started to get shy and all I could muster were a few increasingly random questions. I left a good tip and stepped away awkwardly.&lt;/p&gt;
&lt;p&gt;That evening Britney and I went to an excellent seafood restaurant, Messin. We ordered Arctic salmon and Arctic char. Britney also got lobster soup as a starter (the first of five she would order over the course of the trip!). Everything was fantastic&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt; &lt;a href=&#34;#fn11&#34; class=&#34;footnote-ref&#34; id=&#34;fnref11&#34;&gt;&lt;sup&gt;11&lt;/sup&gt;&lt;/a&gt;. After dinner we got our day pack ready for the following morning and called it an early night.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;In a suburban American home it might have been an attic&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The monument was erected by Yoko Ono. She chose Iceland because of its clean air. ~80% of the country’s energy comes from water &amp;amp; geothermal energy rather than coal or other sources. Also it’s a country the size of England but a population of only ~360,000, so not too many people to pollute it.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Naturally, the sculpture was located in the main shopping center, doing its best to compel consumerism.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;“Arik”s difficult to pronounce Icelandic name served as his opening joke to the mostly foreigners in the group.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;This jacket had earned me the nickname ‘big-bird’ from a former roommate – it had come from the way I looked when downhill skiing and my tendency to almost flail my arms when going too fast around a turn or over a mogul.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;Which provides a picture of Icelandic wit.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;The relative smallness of the parliament building, and all other national buildings reminds you just how small Iceland is. This made their qualifying for the world-cup and showing-up at the world stage in other competitions that much more impressive to me.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;For example that they don’t pass familial names down between successive generations (their last names come directly from their parents first name).&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;Preferably for over New Year’s Eve.&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;The salmon even rivaled the fantastic Pacific salmon I grew-up eating in Seattle.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn11&#34;&gt;&lt;p&gt;The portions were also pretty big.&lt;a href=&#34;#fnref11&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>